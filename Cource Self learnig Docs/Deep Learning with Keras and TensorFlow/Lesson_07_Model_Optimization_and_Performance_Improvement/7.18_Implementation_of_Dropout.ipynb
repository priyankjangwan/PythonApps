{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X4LOpuPqoKJ"
   },
   "source": [
    "# __Dropout Regularization__\n",
    "\n",
    "Dropout is a technique where:\n",
    "\n",
    "- Randomly selected neurons are ignored during training. They are 'dropped out' randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass, and any weight updates are not applied to the neuron on the backward pass.\n",
    "\n",
    "\n",
    "- If neurons are randomly dropped out of the network during training, other neurons will have to step in and handle the representation required to make predictions for the missing neurons. This is believed to result in multiple independent internal representations being learned by the network.\n",
    "\n",
    "- The effect is that the network becomes less sensitive to the specific weights of neurons. This, in turn, results in a network that is capable of better generalization and is less likely to overfit the training data.\n",
    "\n",
    "Let's understand how it works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmVB_n8GR4wD"
   },
   "source": [
    "## Steps to be followed:\n",
    "1. Import the required libraries\n",
    "2. Read a CSV file into a DataFrame\n",
    "3. Create dummies\n",
    "4. Standardize and prepare data for modeling\n",
    "5. Perform K-fold cross-validation and model training\n",
    "6. Final accuracy calculation on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XoOcXJ0qoKM"
   },
   "source": [
    "### Step 1: Import the required libraries\n",
    "\n",
    "- Import libraries for data preprocessing, including z-score standardization using **scipy.stats.zscore** and data manipulation using **pandas**. It also imports libraries for model evaluation, such as metrics from **sklearn** and train-test splitting from **sklearn.model_selection**.\n",
    "- Import the necessary components from TensorFlow Keras (**Sequential** and **Dense**) to build a neural network model. These components allow for the creation of a sequential model with dense layers and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow==2.17.0 in ./.local/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: scikeras==0.13.0 in ./.local/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: keras==3.2.0 in ./.local/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.local/lib/python3.10/site-packages (from tensorflow==2.17.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.17.0) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (14.0.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.17.0) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (2.28.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.local/lib/python3.10/site-packages (from tensorflow==2.17.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in ./.local/lib/python3.10/site-packages (from tensorflow==2.17.0) (2.17.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (0.26.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.17.0) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in ./.local/lib/python3.10/site-packages (from scikeras==0.13.0) (1.5.2)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/site-packages (from keras==3.2.0) (13.5.3)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/site-packages (from keras==3.2.0) (0.0.7)\n",
      "Requirement already satisfied: optree in ./.local/lib/python3.10/site-packages (from keras==3.2.0) (0.13.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.17.0) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2022.6.15)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras==0.13.0) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras==0.13.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=1.4.2->scikeras==0.13.0) (3.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (2.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich->keras==3.2.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich->keras==3.2.0) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras==3.2.0) (0.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.0 scikeras==0.13.0 keras==3.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable oneDNN optimizations to avoid potential minor numerical differences caused by floating-point round-off errors.\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VdUY7abFqoKO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeKij9Zzs3SU"
   },
   "source": [
    "### Step 2: Read a CSV file into a DataFrame\n",
    "- Read a CSV file from a given URL and stores it in a Pandas DataFrame by using **na_values** to replace specified values with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OKmLCf6hqoKP"
   },
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1719212066840,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "qgM45IbLqoKP",
    "outputId": "c4cc0496-702f-4ed8-f2d9-7868055e8cc0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>crime</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vv</td>\n",
       "      <td>c</td>\n",
       "      <td>50876.0</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>35</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>kd</td>\n",
       "      <td>c</td>\n",
       "      <td>60369.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>59</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>0.400809</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pe</td>\n",
       "      <td>c</td>\n",
       "      <td>55126.0</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>6</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.207723</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>51690.0</td>\n",
       "      <td>15.808333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>16</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.361216</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>28347.0</td>\n",
       "      <td>40.941667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>20</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id job area   income     aspect  subscriptions  dist_healthy  save_rate  \\\n",
       "0   1  vv    c  50876.0  13.100000              1      9.017895         35   \n",
       "1   2  kd    c  60369.0  18.625000              2      7.766643         59   \n",
       "2   3  pe    c  55126.0  34.766667              1      3.632069          6   \n",
       "3   4  11    c  51690.0  15.808333              1      5.372942         16   \n",
       "4   5  kl    d  28347.0  40.941667              3      3.822477         20   \n",
       "\n",
       "   dist_unhealthy  age  pop_dense  retail_dense     crime product  \n",
       "0       11.738935   49   0.885827      0.492126  0.071100       b  \n",
       "1        6.805396   51   0.874016      0.342520  0.400809       c  \n",
       "2       13.671772   44   0.944882      0.724409  0.207723       b  \n",
       "3        4.333286   50   0.889764      0.444882  0.361216       b  \n",
       "4        5.967121   38   0.744094      0.661417  0.068033       a  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYT-VXxJthjR"
   },
   "source": [
    "**Observation**\n",
    "- The output appears to be a tabular representation of a dataset with various columns.\n",
    "- Each row represents a sample or instance, while each column represents a different attribute or feature of that instance.\n",
    "- The columns contain information such as the `ID, job, area, income, aspect, subscriptions, dist_healthy, save_rate, dist_unhealthy, age, pop_dense, retail_dense, crime, and product`.\n",
    "- The values in the columns represent specific measurements or categories related to each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1719215334263,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "bxhRk9Dgq1UQ",
    "outputId": "30e8e20e-7718-4576-efe0-fc2d18e75e09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "job                0\n",
       "area               0\n",
       "income            59\n",
       "aspect             0\n",
       "subscriptions      0\n",
       "dist_healthy       0\n",
       "save_rate          0\n",
       "dist_unhealthy     0\n",
       "age                0\n",
       "pop_dense          0\n",
       "retail_dense       0\n",
       "crime              0\n",
       "product            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHvmTecaE3p-"
   },
   "source": [
    "#### Create dummy variables\n",
    "\n",
    "- Use the **pd.get_dummies()** function to convert categorical columns **'job'** and **'area'** into dummy variables, which represent the presence or absence of each category as binary values.\n",
    "\n",
    "- Drop the original categorical columns **'job'** and **'area'** from the DataFrame using the **df.drop()** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Omob067kCwj7"
   },
   "outputs": [],
   "source": [
    "# Convert categorical columns to dummy variables\n",
    "categorical_cols = ['job', 'area']\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1719215346499,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "Br11zGI3Fa9V",
    "outputId": "cd2acda1-def5-46c9-b793-598c9a09311c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'income', 'aspect', 'subscriptions', 'dist_healthy', 'save_rate',\n",
       "       'dist_unhealthy', 'age', 'pop_dense', 'retail_dense', 'crime',\n",
       "       'product', 'job_al', 'job_am', 'job_ax', 'job_bf', 'job_by', 'job_cv',\n",
       "       'job_de', 'job_dz', 'job_e2', 'job_f8', 'job_gj', 'job_gv', 'job_kd',\n",
       "       'job_ke', 'job_kl', 'job_kp', 'job_ks', 'job_kw', 'job_mm', 'job_nb',\n",
       "       'job_nn', 'job_ob', 'job_pe', 'job_po', 'job_pq', 'job_pz', 'job_qp',\n",
       "       'job_qw', 'job_rn', 'job_sa', 'job_vv', 'job_zz', 'area_b', 'area_c',\n",
       "       'area_d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-IA2g40LGE4z"
   },
   "outputs": [],
   "source": [
    "# Convert all boolean columns to numeric (integer) format\n",
    "boolean_columns = df.select_dtypes(include=['bool']).columns\n",
    "df[boolean_columns] = df[boolean_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1719213465270,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "kfZZkfkJG4xA",
    "outputId": "d872e9f3-eb8b-4cfb-af97-3a3aa75f64ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>...</th>\n",
       "      <th>job_pz</th>\n",
       "      <th>job_qp</th>\n",
       "      <th>job_qw</th>\n",
       "      <th>job_rn</th>\n",
       "      <th>job_sa</th>\n",
       "      <th>job_vv</th>\n",
       "      <th>job_zz</th>\n",
       "      <th>area_b</th>\n",
       "      <th>area_c</th>\n",
       "      <th>area_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50876.0</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>35</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60369.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>59</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>55126.0</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>6</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>51690.0</td>\n",
       "      <td>15.808333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>16</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>28347.0</td>\n",
       "      <td>40.941667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>20</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   income     aspect  subscriptions  dist_healthy  save_rate  \\\n",
       "0   1  50876.0  13.100000              1      9.017895         35   \n",
       "1   2  60369.0  18.625000              2      7.766643         59   \n",
       "2   3  55126.0  34.766667              1      3.632069          6   \n",
       "3   4  51690.0  15.808333              1      5.372942         16   \n",
       "4   5  28347.0  40.941667              3      3.822477         20   \n",
       "\n",
       "   dist_unhealthy  age  pop_dense  retail_dense  ...  job_pz job_qp  job_qw  \\\n",
       "0       11.738935   49   0.885827      0.492126  ...       0      0       0   \n",
       "1        6.805396   51   0.874016      0.342520  ...       0      0       0   \n",
       "2       13.671772   44   0.944882      0.724409  ...       0      0       0   \n",
       "3        4.333286   50   0.889764      0.444882  ...       0      0       0   \n",
       "4        5.967121   38   0.744094      0.661417  ...       0      0       0   \n",
       "\n",
       "   job_rn  job_sa  job_vv  job_zz  area_b  area_c  area_d  \n",
       "0       0       0       1       0       0       1       0  \n",
       "1       0       0       0       0       0       1       0  \n",
       "2       0       0       0       0       0       1       0  \n",
       "3       0       0       0       0       0       1       0  \n",
       "4       0       0       0       0       0       0       1  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HtO5-TBDjsR"
   },
   "source": [
    "#### Train and Test split:\n",
    "\n",
    "`product` column is the target variable. `id` column is removed since it doesn't add value to the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OaqcPQtHqoKQ"
   },
   "outputs": [],
   "source": [
    "# Split the data into features and targets before any preprocessing\n",
    "x_columns = df.columns.drop(['product', 'id'])\n",
    "y = pd.get_dummies(df['product']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[x_columns], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceje-8BhVWlc"
   },
   "source": [
    "### Step 4: Standardize and prepare data for modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FnYtRHSvqoKQ"
   },
   "outputs": [],
   "source": [
    "# Apply imputation to numeric columns in train and use the same transformer for test\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Standardize the numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q70MjRl2y01_"
   },
   "source": [
    "### Step 5: Perform K-fold cross-validation and model training\n",
    "- Train a model using K-fold cross-validation with 5 folds.\n",
    "- The model consists of a sequential neural network with two hidden layers, using ReLU activation for the first hidden layer and L1 regularization for the second hidden layer.\n",
    "- Dropout is applied to the first hidden layer to prevent overfitting.\n",
    "- The model is trained using the Adam optimizer and categorical cross-entropy loss function.\n",
    "- The accuracy of each fold is calculated and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45169,
     "status": "ok",
     "timestamp": 1719214754215,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "l2ubrMhsJZ9L",
    "outputId": "15dac34d-fb50-41d4-a52e-857e877e3f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[train_idx] shape: (1280, 45)\n",
      "y_train[train_idx] shape: (1280, 7)\n",
      "X_train[test_idx] shape: (320, 45)\n",
      "y_train[test_idx] shape: (320, 7)\n",
      "\n",
      "Fold #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-11-06 09:49:23.458663: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n",
      "Accuracy for fold 1: 0.7188\n",
      "X_train[train_idx] shape: (1280, 45)\n",
      "y_train[train_idx] shape: (1280, 7)\n",
      "X_train[test_idx] shape: (320, 45)\n",
      "y_train[test_idx] shape: (320, 7)\n",
      "\n",
      "Fold #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step\n",
      "Accuracy for fold 2: 0.7469\n",
      "X_train[train_idx] shape: (1280, 45)\n",
      "y_train[train_idx] shape: (1280, 7)\n",
      "X_train[test_idx] shape: (320, 45)\n",
      "y_train[test_idx] shape: (320, 7)\n",
      "\n",
      "Fold #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step\n",
      "Accuracy for fold 3: 0.6750\n",
      "X_train[train_idx] shape: (1280, 45)\n",
      "y_train[train_idx] shape: (1280, 7)\n",
      "X_train[test_idx] shape: (320, 45)\n",
      "y_train[test_idx] shape: (320, 7)\n",
      "\n",
      "Fold #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step\n",
      "Accuracy for fold 4: 0.7375\n",
      "X_train[train_idx] shape: (1280, 45)\n",
      "y_train[train_idx] shape: (1280, 7)\n",
      "X_train[test_idx] shape: (320, 45)\n",
      "y_train[test_idx] shape: (320, 7)\n",
      "\n",
      "Fold #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Set up K-fold cross-validation\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train_sc), 1):\n",
    "\n",
    "    print(\"X_train[train_idx] shape:\", X_train_sc[train_idx].shape)\n",
    "    print(\"y_train[train_idx] shape:\", y_train[train_idx].shape)\n",
    "    print(\"X_train[test_idx] shape:\", X_train_sc[test_idx].shape)\n",
    "    print(\"y_train[test_idx] shape:\", y_train[test_idx].shape)\n",
    "    print()\n",
    "\n",
    "\n",
    "    print(f\"Fold #{fold}\")\n",
    "    model = Sequential([\n",
    "        Dense(50, input_dim=X_train_sc.shape[1], activation='relu'),\n",
    "        Dropout(0.5),  # Dropout to prevent overfitting\n",
    "        Dense(25, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    # Train the model on the fold\n",
    "    # Convert NumPy arrays to TensorFlow Tensors with float32 data type directly using appropriate indexes\n",
    "    model.fit(tf.convert_to_tensor(X_train_sc[train_idx], dtype=tf.float32),\n",
    "              tf.convert_to_tensor(y_train[train_idx], dtype=tf.float32),\n",
    "              validation_data=(tf.convert_to_tensor(X_train_sc[test_idx], dtype=tf.float32),\n",
    "                               tf.convert_to_tensor(y_train[test_idx], dtype=tf.float32)),\n",
    "              epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate the model on the fold's test data\n",
    "    predictions = model.predict(tf.convert_to_tensor(X_train_sc[test_idx], dtype=tf.float32))\n",
    "    score = metrics.accuracy_score(np.argmax(y_train[test_idx], axis=1), np.argmax(predictions, axis=1))\n",
    "    print(f\"Accuracy for fold {fold}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqaJM7COzpSm"
   },
   "source": [
    "**Observation**\n",
    "- The output shows the accuracy scores for each fold of the cross-validation process:\n",
    "\n",
    "  - Fold scores: The output displays the fold number (for example, Fold #1) and the corresponding accuracy score (for example, 0.71) for each fold. The accuracy score represents the proportion of correctly predicted labels to the total number of labels in the test set. Higher accuracy scores indicate better performance of the model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eB61-VRSz0J7"
   },
   "source": [
    "### Step 6: Final accuracy calculation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1719214289445,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "CCDMfFPeKAbD",
    "outputId": "38d3eb8a-74b0-4fa4-eafe-807d5a51c1fa"
   },
   "outputs": [],
   "source": [
    "# Final evaluation on the standardized test set\n",
    "final_predictions = model.predict(tf.convert_to_tensor(X_test_sc, dtype=tf.float32)) # Convert X_test_sc to a Tensor\n",
    "final_score = metrics.accuracy_score(np.argmax(y_test, axis=1), np.argmax(final_predictions, axis=1))\n",
    "print(f\"Final accuracy on test set: {final_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isI6yXg001L2"
   },
   "source": [
    "\n",
    "**Observation**\n",
    "- The final accuracy score achieved by the model is 0.69."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
