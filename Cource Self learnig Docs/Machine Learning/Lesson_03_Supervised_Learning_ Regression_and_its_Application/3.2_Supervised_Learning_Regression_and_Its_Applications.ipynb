{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8rpG8NMu2QX"
   },
   "source": [
    "# __Supervised Learning: Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrvcgs4Kpr_f"
   },
   "source": [
    "## __Agenda__ ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrZj2xArpxs_"
   },
   "source": [
    "* Types of Regression\n",
    "    * Linear Regression\n",
    "      * Simple Linear Regression\n",
    "        - Train-Test Split\n",
    "      * Multiple Linear Regression\n",
    "        - Overfitting and Underfitting\n",
    "    * Non-Linear Regression\n",
    "      * Polynomial Regression\n",
    "* Model Evaluation and Validation\n",
    "    * Cross-Validation Techniques\n",
    "    * Performance Metrics for Regression\n",
    "      * Mean Squared Error (MSE)\n",
    "      * Root Mean Squared Error (RMSE)\n",
    "      * Mean Absolute Error (MAE)\n",
    "      * R-Squared\n",
    "* Regularization Techniques\n",
    "    * Lasso Regression\n",
    "    * Ridge Regression\n",
    "    * ElasticNet Regression\n",
    "* Hyperparameter Tuning\n",
    "    * GridSearchCV\n",
    "    * RandomSearchCV\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dOwMIwnxCuE"
   },
   "source": [
    "## __3.2 Regression__ ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iG5J00qnxCuL"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/updated/Lesson_04/Linear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNcWn8pnxCuL"
   },
   "source": [
    "### __3.2.1 Application of Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ8J6l8XxCuM"
   },
   "source": [
    "1. Oil and Gas Industry: Various types of data are collected in the oil and gas industry from the surface and subsurface to understand production and sale processes. Linear and non-linear regression models forecast global oil production.\n",
    "\n",
    "2. Marketing: In marketing, linear regression helps analyze the effectiveness of advertising campaigns, predict sales based on marketing spend, and segment customers based on demographic data.\n",
    "\n",
    "3. Retail: Linear regression is utilized in retail for demand forecasting, inventory management, pricing optimization, and customer analytics.\n",
    "\n",
    "4. Healthcare: Linear regression is applied in healthcare for predicting patient outcomes, analyzing the relationship between medical variables and disease progression, and planning healthcare resources.\n",
    "\n",
    "5. Real Estate: In the real estate industry, linear regression predicts property prices based on factors such as location, size, amenities, and economic indicators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OclNYtApxCuM"
   },
   "source": [
    "## __3.3 Types of Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDdoTnFUxCuM"
   },
   "source": [
    "Regression types can be classified into two categories: linear and non-linear.\n",
    "\n",
    "**Linear Regression**\n",
    "\n",
    "Definition: Linear regression finds a straight-line relationship between the dependent variable and one or more independent variables.\n",
    "\n",
    "**Non-Linear Regression**\n",
    "\n",
    "Definition: Non-linear regression finds a relationship between the dependent variable and independent variables using a curve or a more complex shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gq-cNc9TxCuM"
   },
   "source": [
    "## __3.4 Linear Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mQlwgg7xCuM"
   },
   "source": [
    "**Linear Regression** refers to a supervised learning algorithm used to predict a continuous target variable by modeling its relationship with one or more independent variables through a linear equation.\n",
    "\n",
    "- It predicts a continuous dependent variable based on one or more independent variables.\n",
    "- It uses the least squares criterion to estimate the coefficients of the regression equation..\n",
    "- It can be applied only if there is a linear relationship between the variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IDEA58hxCuM"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/updated/Lesson_04/Linear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrfQU36GxCuM"
   },
   "source": [
    "In this case, the dependent variable is continuous, and the independent variables can be either continuous or discrete.\n",
    "The relationship between a dependent variable (y) and one or more independent variables (x) is established using a best-fit straight line, also known as the regression line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hsjn4ZijxCuM"
   },
   "source": [
    "There are two types of linear regression:\n",
    "- Simple linear regression\n",
    "- Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKqNNd45xCuN"
   },
   "source": [
    "### __3.4.1 Simple Linear Regression__ ###\n",
    "\n",
    "**Simple Linear Regression**\n",
    "\n",
    "Definition: Simple linear regression models the relationship between one independent variable and the dependent variable as a straight line.\n",
    "\n",
    "The equation for Simple Linear Regression is:\n",
    "\n",
    " $$ y = \\beta_0 + \\beta_1x $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y$ is the dependent variable\n",
    "- $x$ is the independent variable\n",
    "- $β_0$ is the intercept\n",
    "- $β_1$ is the slope\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUKTxNJFxCuN"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson04_Regression/updates/Simple_linear_regression.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQxt4DIXxCuN"
   },
   "source": [
    "### __3.4.2 Multiple Linear Regression__ ###\n",
    "\n",
    "**Multiple Linear Regression**\n",
    "\n",
    "Definition: Multiple linear regression models the relationship between two or more independent variables/predictors/features and the dependent variable as a straight line.\n",
    "\n",
    "The equation for Multiple Linear Regression:\n",
    "\n",
    " $$ {y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_nx_ n $$\n",
    "\n",
    "- $ x_1, x_2, \\ldots, x_n $ are the predictor variables,\n",
    "- $ \\beta_1, \\beta_2, \\ldots, \\beta_n $ are the coefficients for each predictor.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQDyWrnIxCuN"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson04_Regression/updates/multiple_linear_regression.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0CnFsDRxCuN"
   },
   "source": [
    "### Let us see how to fit the linear regression model on a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83q2GoXDxCuN"
   },
   "source": [
    "#### Step 1: Import the Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6zYV1X8KxCuN"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KZ9yV0AxCuN"
   },
   "source": [
    "- Read the dataset `tvmarketing.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5iU8Un8KxCuN"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"tvmarketing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeAp94wVxCuN"
   },
   "source": [
    "The following command provides details about the dataset that was imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQXFyJ4oxCuO",
    "outputId": "7b5241ce-99c8-4029-962a-1489e83684d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   TV      200 non-null    float64\n",
      " 1   Sales   200 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 3.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the DataFrame, including the column names, non-null count, and data types\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaC8SfjMxCuO"
   },
   "source": [
    "__Observation:__\n",
    "- There are no null objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrcSS1SxxCuO"
   },
   "source": [
    "**Train and test the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0SQ38HlxCuO"
   },
   "source": [
    "#### Step 2: Fit the Linear Regression Model\n",
    "\n",
    "- Now, let's define the features and the target variables.\n",
    "- Here, X is assigned to all the rows in the first column of the dataset.\n",
    "\n",
    "- y is assigned to all the rows of the second column of the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oRN77NIvxCuO"
   },
   "outputs": [],
   "source": [
    "# Extract the feature(s) from the DataFrame\n",
    "X=data.iloc[:,0:1].values\n",
    "# Extract the target variable from the DataFrame\n",
    "y=data.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j94Nhic-xCuO"
   },
   "source": [
    "**Perform train-test split**\n",
    "\n",
    "Train-test split is a technique in machine learning used to evaluate a model's performance by dividing the data into two parts: a training set and a test set. The model is trained on the training set, learning patterns and parameters, and then evaluated on the test set to see how well it generalizes to new, unseen data.\n",
    "\n",
    "**Note:** This train-test data split will be used for other implementations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "szcjEq2txCuP"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function from sklearn's model_selection module\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwjQmbhvwZeV"
   },
   "source": [
    "Allowed inputs in `train_test_split()` are lists, numpy arrays, scipy-sparse matrices or pandas dataframes. In this implementation X and y will be passed as arrays of corresponding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vGbMpQEKxCuQ"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nfWvM75wZeV"
   },
   "source": [
    "This code splits the dataset (X, y) into a training set (70%) and a test set (30%).\n",
    "\n",
    "As you may have noticed, we’ve been setting the random_state parameter in our examples. This parameter is the seed used by the random number generator. Setting a seed ensures that the splits you generate are reproducible. If you don’t set a seed, you might get different splits every time you run the code, which can make your results hard to replicate.\n",
    "it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiMTqbA9xCuQ"
   },
   "source": [
    "- First, let us see if linear regression works on this data.\n",
    "- From **sklearn.linear_model**, import the linear regression function.\n",
    "- Assign **LinearRegression()** to the variable **lin_reg**.\n",
    "- Next, fit the data on the training data `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "V3qDSEw4xCuQ",
    "outputId": "cd73484e-271d-4ce0-b5e1-35159b5069a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LinearRegression class from scikit-learn's linear_model module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Create an instance of the LinearRegression class\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIiOm4jaxCuR"
   },
   "source": [
    "**Observation**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDz2w77vxCuR"
   },
   "source": [
    "- Fit the linear regression model to the given dataset.\n",
    "- Visualize the fitted data using a scatter plot.\n",
    "- Define a function named **viz_linear** to display the X_test and y_test values as green points on a graph, and illustrate the fitted regression line in blue.\n",
    "- Provide the appropriate X and y axis labels along with a suitable title for the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KU2dxXvSxCuR"
   },
   "outputs": [],
   "source": [
    "def viz_linear():\n",
    "    plt.scatter(X_test, y_test, color='green')  # X_test should represent TV expenses\n",
    "    plt.plot(X_train, lin_reg.predict(X_train), color='blue')  # X_train is TV expenses, predicted values are Sales\n",
    "    plt.title('Linear Regression Model (Test set)')\n",
    "    plt.xlabel('TV')  # Independent variable (TV)\n",
    "    plt.ylabel('Sales')  # Dependent variable (Sales)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNspT54VxCuR"
   },
   "source": [
    "- Call the following function to create the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "kaNi45k3xCuR",
    "outputId": "aad71b6b-5ff5-4c8f-e61f-ca078e0a317e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz_linear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o9yL1A8xCuR"
   },
   "source": [
    "__Observation:__\n",
    "- The plot shows a positive linear relationship between Sales and TV, where the blue regression line indicates the model's predictions. The green data points are generally close to the line, suggesting the model fits the data reasonably well, though some variability exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TROsyMOvxCuR"
   },
   "source": [
    "### Overfitting and Underfitting\n",
    "\n",
    "When developing machine learning models, achieving the right balance between complexity and simplicity is crucial. This balance is covered in the concepts of overfitting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmaRaeVhwZeZ"
   },
   "source": [
    "**Overfitting**\n",
    "\n",
    "- Overfitting occurs when a model learns the noise and details in the training data too well to the extent that it negatively impacts its performance on new unseen data.\n",
    "- Sign: High accuracy on training data but poor accuracy on test data.\n",
    "- Cause: Model is too complex (too many parameters).\n",
    "\n",
    "**Underfitting**\n",
    "- Underfitting happens when a model is too simple to capture the underlying pattern of the data.\n",
    "- Sign: Poor accuracy on both training and test data.\n",
    "- Cause: Model is too simple (too few parameters).\n",
    "  \n",
    "**Bias-Variance Tradeoff**\n",
    "- Bias: Error due to overly simplistic assumptions in the learning algorithm. High bias can cause underfitting.\n",
    "- Variance: Error due to excessive complexity in the learning algorithm. High variance can cause overfitting.\n",
    "\n",
    "**Tradeoff**\n",
    "- Low Bias & High Variance: Model fits the training data very well but may fail to generalize (overfitting).\n",
    "- High Bias & Low Variance: Model does not fit the training data well and misses the underlying trend (underfitting).\n",
    "- Optimal Tradeoff: Finding a balance where the model performs well on both training and test data, minimizing overall error.\n",
    "  \n",
    "Understanding and managing the bias-variance tradeoff is key to building models that generalize well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "proeQqkz1Ruq"
   },
   "source": [
    "**Let's look at how to check for overfitting or underfitting of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSS8pcnVRKcx",
    "outputId": "86f94afc-3b17-4722-fe6a-86d9f9ba3206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Mean Squared Error: 11.189103289351676\n",
      "Test Set Mean Squared Error: 8.970991242413614\n",
      "Training Set R² Score: 0.5736021199591975\n",
      "Test Set R² Score: 0.6714477229302764\n",
      "------------------------------------------\n",
      "Model may be underfitting, consider increasing model complexity.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for performance metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predicting for the training set\n",
    "y_train_pred = lin_reg.predict(X_train)\n",
    "\n",
    "# Predicting for the test set\n",
    "y_test_pred = lin_reg.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Training Set Mean Squared Error:\", mse_train)\n",
    "print(\"Test Set Mean Squared Error:\", mse_test)\n",
    "print(\"Training Set R² Score:\", r2_train)\n",
    "print(\"Test Set R² Score:\", r2_test)\n",
    "print(\"------------------------------------------\")\n",
    "# Check for overfitting or underfitting\n",
    "if mse_train < mse_test or r2_train > r2_test:\n",
    "    if abs(r2_train - r2_test) > 0.1:\n",
    "        print(\"Model may be overfitting to the training data.\")\n",
    "    else:\n",
    "        print(\"Model performs reasonably well but check for slight overfitting.\")\n",
    "elif mse_train > mse_test and r2_train < r2_test:\n",
    "    print(\"Model may be underfitting, consider increasing model complexity.\")\n",
    "else:\n",
    "    print(\"Model has a balanced fit on both training and testing datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6N8N6040zURj"
   },
   "source": [
    "**Observation**\n",
    "\n",
    " Mean Squared Error (MSE) and R-squared (R²) values are calculated for both training and test datasets.\n",
    "\n",
    " - MSE measures the average of the squares of the errors, that is, the average squared difference between the estimated values and the actual value.\n",
    " - R² provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model\n",
    "\n",
    "Overfitting: The model performs well on the training data but poorly on the test data (higher R² on training or lower MSE on training compared to testing).\n",
    "\n",
    "Underfitting: The model performs poorly on both training and test data, or better on the test data compared to the training data, which could suggest that the model is too simple.\n",
    "\n",
    "We'll discuss more about MSE, R² and various other performance metrices, further in the lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWwi08i0xCuS"
   },
   "source": [
    "## __3.6 Non-linear Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZKRnKq_xCuS"
   },
   "source": [
    "### __3.6.1 Polynomial Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjq3Bc_8xCuS"
   },
   "source": [
    "**Polynomial Regression** is a subset of linear regression that includes polynomial terms.\n",
    "The relationship between an independent variable (x) and a dependent variable (y) is modeled as an nth-degree polynomial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6tR57ZOxCuS"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/updated/Lesson_04/Polynomial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiRBPynpxCuS"
   },
   "source": [
    "- Polynomial regression is also called as the special case of multiple linear regression. Some polynomial terms are added to the multiple linear regression equation to convert into polynomial regression.\n",
    "- It is a linear model with some modifications made to increase its accuracy.\n",
    "- The dataset used in polynomial regression for training is non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQHi9YvxxCuS"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson04_Regression/updates/linear__regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIq_xS19xCuS"
   },
   "source": [
    "- From the above figure, it is seen that the straight line is unable to capture the patterns in the given data.\n",
    "- To achieve a higher-order equation that captures complex data patterns, the powers of the original features can be added as new features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFiWscBjxCuT"
   },
   "source": [
    "The following graph is the result after applying polynomial regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQv-V_SzxCuT"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson04_Regression/updates/polynomial__regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-lXDdjNxCuT"
   },
   "source": [
    "- It provides the best approximation of the relationship between a dependent and an independent variable.\n",
    "- It captures most data points and decreases the error between the actual and the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3u5dFFtixCuT"
   },
   "source": [
    "### Let us see how to fit polynomial regression on a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZNnJhC6xCuT"
   },
   "source": [
    "\n",
    "- First, import the relevant libraries.\n",
    "- Next, assign the **PolynomialFeatures** of degree 4 to the variable **poly_features**.\n",
    "- Fit the values of X_test and X_train  and assign them to the variable **X_test_poly** and **X_train_poly**.\n",
    "- Finally, get the linear regression function and assign it to the variable **pol_features**.\n",
    "- Dataset used for this exercise is `tvmarketing.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_xSmJ4xDxCuT"
   },
   "outputs": [],
   "source": [
    "# Import the PolynomialFeatures class from scikit-learn's preprocessing module\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6fQilsexCuU"
   },
   "source": [
    "- Perform train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xdi9cO-0xCuU"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLDVaHgVxCuU"
   },
   "source": [
    "Fit the X_train_poly and y_train in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "9FXh8_PvxCuU",
    "outputId": "bb16d860-bc2d-4039-acd2-f9d6905cda1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=4)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSZr2x0-wZee"
   },
   "source": [
    "1. **Create Polynomial Features:** The PolynomialFeatures transformer is configured to generate polynomial features up to the 4th degree.\n",
    "\n",
    "2. **Transform Training Data:** fit_transform is used on X_train to generate a new feature set that includes polynomial features and interactions.\n",
    "\n",
    "3. **Transform Test Data:** transform (corrected from fit_transform) is used on X_test to apply the same transformation derived from X_train.\n",
    "\n",
    "4. **Train the Model:** The linear regression model is trained using the transformed training data (X_train_poly) and the target values (y_train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2yDDA-fxCuV"
   },
   "source": [
    "__Observation:__\n",
    "- You have fitted the polynomial regression on the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWEGTSvIxCuV"
   },
   "source": [
    "Predict the values using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SM7YtyAtxCuV"
   },
   "outputs": [],
   "source": [
    "# Predict on the testing set\n",
    "y_train_pred = poly_model.predict(X_train_poly)\n",
    "y_test_pred = poly_model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxyoWTbIxCuV"
   },
   "source": [
    "- Create a variable **X_range** to create a continuous range of values for the independent variable (X) that spans from the minimum to the maximum values found in both the training and test datasets. This range is used to generate smooth predictions for plotting the polynomial regression curve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zuEdLmXRxCuV"
   },
   "outputs": [],
   "source": [
    "X_range = np.arange(min(np.min(X_train), np.min(X_test)), max(np.max(X_train), np.max(X_test)), 0.1)\n",
    "X_range = X_range.reshape((len(X_range), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "D6H93lr6xCuV",
    "outputId": "dee31807-9127-4a68-e52a-44a96286e2d1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0yElEQVR4nO3dfbxVc97/8ddbTndESkMkqYgiScRgyJBhRnKvXwbXIGY0zFzMuL1czR0Gc7nGRWMyw8SkCWk6ZEZE5L5SKtJUSkVIo5RTOZ0+vz++36PdaZ9z9jnt+/15Ph77cfZea+21PmutfT577e/63sjMcM45Vzq2y3UAzjnnsssTv3POlRhP/M45V2I88TvnXInxxO+ccyXGE79zzpUYT/w5JmmxpBNyHUciSf+QdGGKy+Zd/Okiaa2kzvm6/Vwce0nHSJqXzW1mm6ROkkzS9vF1yv8PhcITf5rEf8J18Z/1E0l/kbRjruNqDDM72cxGbut64jH4Kh6Tf0t6VtL+6YgxG8xsRzN7Px+2H4/lrxuzHkk3xHOwVtJ6SVUJr99pYExTzKxbA7ffMWF7a2NS/TLh9TEN26PUvvTifi+K21gmaUxDtwNb/j9IukjSy41ZTz7xxJ9ep5rZjkBvoA9wU47jyQe3x2OyJ/Ah8Od0b6D6yswlZ2a3xC+RHYHLgdeqX5tZj+rlFKQ9J5jZkoTtVV8MHZwwbUq6txmv0L8PnBC32QeYlO7tFCpP/BlgZh8C/wAOBJA0QNI7klZJmizpgJrvkbS7pApJbROm9Za0QlJZ9ZWGpDslfR6vZE5OWHYPSeXxynqBpEsT5g2T9Jikv0paI2m2pP0kXS/pU0lLJfVPWH6ypEvi8y6Snpe0UtJnkkZJat2IY7IOeBToVSPmsXEfF0m6MmFeC0kj477OlfRzScsS5i+WdK2kWcCXkraXdISkV+NxflvScQnLXyTp/bj/iyQNjtO7SnpR0uq4f2MS3mOSusbnO0t6KMb6gaSbqpNkfecmkaT/kPRkwuv5kh5LeL1UUq/E7UsaAgwGfh6vXp9MWGUvSbNi/GMkNW/IeYnn+jeSXgEqgM4xxrnxWL0v6bKE5Y9Lch6uaWwMkprF47ZE4ZfyfZJaxHm7Snoqns9/S5oiaTtJDwMdgSfj8fh5klUfBjxjZgsBzOxjMxtRY79vlfSmpC8kjZfUpo5jdInC/+19wJFxu6tS3c+8Y2b+SMMDWEy4ugDYC3gH+BWwH/AlcCJQBvwcWAA0TfK+p4EfJqzzLuD/4vOLgErgUqAJ8EPgI0Bx/kvAcKA5IbmuAI6P84YB64GTgO2Bh4BFwI0xpkuBRQnbnQxcEp93jbE3A9rF7fxvsv1Ockz+Avw6Pt8BeBh4O77eDpgO3Aw0BToD7wMnxfm3AS8CuwAdgFnAshrbnRmPdQvCL4qVwClx3SfG1+3itr8AusX3tgd6xOej43HYLh67oxO2YUDX+PwhYDzQCugE/Au4OJVzU+OYdAZWxe3tAXxQvV9x3ufAdkm2//WxrHEM3ozraQPMBS6v53N6EfByjXO9BOgRPxtlwHeBLoCAYwlfCL3j8sclOQ8NjSFxv+4CyuN7WwFPArfGebcSEm1ZfBzD5s/7Ymr53MX55wP/Bn5GuNpvUmP+ZMIv0APj52Ms8Nc4r1OMcfsk/w9bHL9CfeQ8gGJ5xA/i2vhP/QEhCbcA/gt4NGG57eIH7riE91Un/nOBV+LzJsDHwOHx9UXAgoT1tIwfzt0Jya8KaJUw/1bgL/H5MODZhHmnxlibxNet4rpax9dff9CT7OdAYEaN/a4r8a+Px2QT4cumZ5zXF1hSY/nrgQfj86+/BOLrS9g64fwg4fW1wMM11vcMcGH8x14FnAm0qLHMQ8AIoEOS+I3wxdcE+AronjDvMmByfeemluOylFAceF7c9pvA/sB/AOU1t59wLJMl/vMTXt8O3FfP5/Qitk78v6znPX8HrorPj0tyHhoaQ/VxFeGiqEvCvCOJFyHALwlftl1r+X+rNfHHZQYDz8VtrASurbHftyW87h7PcRNKIPF7UU96DTSz1ma2t5n9yELxRvVVHQBmtonwj79nkvePB7pL2odwxbrazN5MmP9xwnoq4tMd4zb+bWZrEpb9oMY2Pkl4vg74zMyqEl5Xr2sLknaT9DdJH0r6AvgrsGst+5/MnWbWmvDPtA6ovjG4N7BH/Bm/Kv5svgHYLc7fg3CcqiU+TzZtb+DsGus7GmhvZl8SvlQvB5ZLmqDNN5l/TkhAbyoUx/0gyXZ2JVxxfpAwrebxre3cJPMiIYF+Kz6fTLiyPja+boiPE55X1LHNumxxbCWdLOn1WLyyivArqq5znjQGhdow1TdwByd5XzvCl+T0hHP2zzgd4A7Cr+OJscjpuobslJmNMrMTgNaEc/8rSSclLJK43x8QznFDPtsFyxN/5n1ESEpAuIFGuEL/sOaCZraeUA5+PuHG1MMN2EYbSa0SpnVMto1GuIVw9XOQme0UY1NDV2JmS4CrgN/HMtylhCu71gmPVmZ2SnzLckIRT7W9kq024flSwhV/4vp2MLPb4vafMbMTCcU87wH3x+kfm9mlZrYH4Sp+eHW5foLPCEU5eydM25bjW534j4nPX6T+xJ/JbnS/XrekZoRijzuB3eKX9tM07pyfbJtv4I5KsshnhIuBHgnnbGeLN4DNbI2ZXW1mnYEBwH9K+nbNmFOIo9LMHiMUFx6YMCvxM9WRcI4/q291qW43n3niz7xHge9K+rakMuBqYAPwai3LP0T4OTmAFBO/mS2N67tVUnNJPYGLCVfn26oVoVhotaQ9CWWmjWJmzxK+pIYQijfWKNygbSGpiaQDJR0WF38UuF7SLnG7Q+tZ/V+BUyWdFNfVPN6I7BB/tZwmaQfCsV9LKHpC0tmSqr9gPif8Y2+qEXdVjOc3klpJ2hv4Txp/fF8E+hGKnZYBU4DvAG2BGbW85xPCPYBMa0q4n7MC2BhvUvev+y2NE3/93g/cJekbAJL2rL4ql/S9eHNbwGpCcWb1uanzeCjccP9uPF/bxf3oAbyRsNj5krpLakkoVno84VdwbT4BOkhq2vA9zh+e+DPMzOYRrpL/j3A1cSqh2udXtSz/CuHD/ZaZfZBsmVoMIhSnfASMA/7bzJ7bhtCr/YJQHr0amAA8sY3ru4NQvLI98D3CjehFhGPzJ2DnuNwvgWVx3nPA44SknVT88juNUFy0gvAL4GeEz/h2hET9EeGG37GEG7AQan+8IWkt4SbjVZa87v6PCWXF7wMvA48ADzRw36tj/Rfhy2dKfP1FXO8rdSSePxOKAVdJ+ntjtptibGuAKwlfdJ8D/49wXDLlWkJxzuuxKPE5NhcH7htfrwVeA4ab2Qtx3q3ATfF4XJNkvV8QPgtLCPd3bidUnEisg/8w4d7Jx4Qb+1dSv+cJFTc+llTfr4O8VX2H3OURSc8Dj5jZn3IdS76Q9EPgPDM7NtexuMInaTKhFk9J/o/5FX+eiUUdvYFGtTIsFpLaSzoq/kzvRigiG5fruJwrBt7iMY9IGkmoLnlVjRo6pagp8EdgH8JP9b8Rqsg657aRF/U451yJ8aIe55wrMQVR1LPrrrtap06dch2Gc84VlOnTp39mZu1qTi+IxN+pUyemTZuW6zCcc66gSEpaJdyLepxzrsR44nfOuRLjid8550pMQZTxJ1NZWcmyZctYv359rkMpWc2bN6dDhw6UlZXlOhTnXAMUbOJftmwZrVq1olOnToQ+nFw2mRkrV65k2bJl7LPPPrkOxznXAAVb1LN+/Xratm3rST9HJNG2bVv/xeVcASrYxA940s8xP/7ONV75vHKGPj2U8nmZ7Pw0uYJO/M45V4jK55UzaOwg7p16L4PGDsp68vfE30grV66kV69e9OrVi913350999zz69dffZW0q/0tTJ48mVdf3TwWy3333cdDDz2UltiOO+44unXrRs+ePdl///0ZOnQoq1atqvd9t9xyS1q275yr28SFE6moDCN0VlRWMHHhxKxu3xN/I7Vt25aZM2cyc+ZMLr/8cn76059+/bpp0/oH56mZ+C+//HIuuOCCtMU3atQoZs2axaxZs2jWrBmnnXZave/xxO9cdvTv0p+WZS0BaFnWkv5dMjLIWa088afR9OnTOfbYYzn00EM56aSTWL58OQB333033bt3p2fPnpx33nksXryY++67j7vuuotevXoxZcoUhg0bxp133gmEK/Zrr72Www8/nP32248pU6YAUFFRwTnnnEP37t05/fTT6du3b71dWTRt2pTbb7+dJUuW8PbbbwMwcOBADj30UHr06MGIESMAuO6661i3bh29evVi8ODBtS7nnNt2A7oNYPSZo7nisCsYfeZoBnQbkNXtF2x1zsYon1fOxIUT6d+lf9oPtJnx4x//mPHjx9OuXTvGjBnDjTfeyAMPPMBtt93GokWLaNasGatWraJ169Zcfvnl7LjjjlxzTRg1btKkSVusb+PGjbz55ps8/fTT/OIXv+C5555j+PDh7LLLLrz77rvMmTOHXr16pRRbkyZNOPjgg3nvvfc4+OCDeeCBB2jTpg3r1q3jsMMO48wzz+S2227jnnvuYebMmV+/L9lybdu2Tdchc66kDeg2IOsJv1rJJP7qmykVlRU8OPPBtH/LbtiwgTlz5nDiiScCUFVVRfv27QHo2bMngwcPZuDAgQwcODCl9Z1xxhkAHHrooSxevBiAl19+mauuugqAAw88kJ49e6YcX+K4C3fffTfjxoXBrJYuXcr8+fOTJvRUl3POFZaSSfzJbqakM/GbGT169OC1117bat6ECRN46aWXePLJJ/nNb37D7Nmz611fs2bNgHC1vnHjxm2KraqqitmzZ3PAAQcwefJknnvuOV577TVatmzJcccdl7QufqrLOee2TSZLImpTMmX8mb6Z0qxZM1asWPF14q+srOSdd95h06ZNLF26lH79+vHb3/6W1atXs3btWlq1asWaNQ0bXfGoo47i0UcfBeDdd99N6QuksrKS66+/nr322ouePXuyevVqdtllF1q2bMl7773H66+//vWyZWVlVFZWAtS5nHMuPXJVrTNjiV/SXpJekPSupHckXRWnD5P0oaSZ8XFKpmJIlOmbKdtttx2PP/441157LQcffDC9evXi1VdfpaqqivPPP5+DDjqIQw45hCuvvJLWrVtz6qmnMm7cuK9v7qbiRz/6EStWrKB79+7cdNNN9OjRg5133jnpsoMHD6Znz54ceOCBfPnll4wfPx6A73znO2zcuJEDDjiA6667jiOOOOLr9wwZMuTrYqm6lnPOpUeuqnVmbMxdSe2B9mb2lqRWwHTCQOLnAGvN7M5U19WnTx+rWXtl7ty5HHDAAWmMOP9VVVVRWVlJ8+bNWbhwISeccALz5s1LqfpoppTieXAuXRLvPbYsa5n2i1JJ082sT83pGSvjN7PlwPL4fI2kucCemdpeKaioqKBfv35UVlZiZgwfPjynSd85t22qSyKyXcaflZu7kjoBhwBvAEcBQyVdAEwDrjazz5O8ZwgwBKBjx47ZCDPvtWrVyoegdK7I5KJaZ8Zv7kraERgL/MTMvgD+AHQBehF+Efwu2fvMbISZ9TGzPu3abTVWcPUyGYnZpcaPv3OFKaOJX1IZIemPMrMnAMzsEzOrMrNNwP3A4Y1Zd/PmzVm5cqUnnxyp7o+/efPmuQ7FOddAGSvqUeiz98/AXDP7n4Tp7WP5P8DpwJzGrL9Dhw4sW7aMFStWbHuwrlGqR+ByzhWWTJbxHwV8H5gtaWacdgMwSFIvwIDFwGWNWXlZWZmP/OScS5tcNKTKlUzW6nkZSDZSx9OZ2qZzzjVGprt0yTcl03LXOedqk+v+8bPNE79zruTlun/8bCuZTtqcc3UrpTLumnLVkCpXMtZlQzol67LBOZc+me46wOVGbV02eFGPc67kyrhLnSd+51zJlXGXOi/jd86VXBl3qfPE75wDcjsGrMsuL+pxzrkS44nfOedKjCd+55wrMZ74nXP1Kp9XztCnh2ZtMHCXWZ74nXN1qm7cde/Uexk0dpAn/yLgid85Vydv3FV8PPE75+rkjbuKj9fjd87VyRt3FR9P/M65ennjruLiRT3OOVdiPPE75wqSVzFtPE/8zrmC41VMt40nfudcwfEqptvGE79zruB4FdNt47V6nHMFx6uYbhtP/M65guRVTBvPi3qcc67EeOJ3zrkS44nfOedKjCd+55wrMZ74nXOuxHjid865EuOJ3znnSkzGEr+kvSS9IOldSe9IuipObyPpWUnz499dMhWDc865rWXyin8jcLWZdQeOAK6Q1B24DphkZvsCk+Jr55xzWZKxxG9my83srfh8DTAX2BM4DRgZFxsJDMxUDM4557aWlTJ+SZ2AQ4A3gN3MbHmc9TGwWy3vGSJpmqRpK1asyEaYzjlXEupN/ArOl3RzfN1R0uGpbkDSjsBY4Cdm9kXiPDMzwJK9z8xGmFkfM+vTrl27VDfnnHOuHqlc8Q8HjgQGxddrgHtTWbmkMkLSH2VmT8TJn0hqH+e3Bz5tUMTOOee2SSq9c/Y1s96SZgCY2eeSmtb3JkkC/gzMNbP/SZhVDlwI3Bb/jm942M45VwRWrYIPP9z8+OijLZ9//DGMGgXf+lZaN5tK4q+U1IRYJCOpHbAphfcdBXwfmC1pZpx2AyHhPyrpYuAD4JyGBu2ccwWhqgqWLYP334eFC7d8vP9+SPw1tWkDe+4ZHgceCDvvnPawUkn8dwPjgG9I+g1wFnBTfW8ys5cB1TL72ylH6Jxz+e6rr2DBAnj33S0f8+aFedW23x46dYIuXeCII8LzDh02J/o99oAWLTIebr2J38xGSZpOSNYCBprZ3IxH5pxz+cYMli6FGTNg5kyYPTsk+PnzYePGsIwEnTtD9+5w8snQtWtI9J07w157QZMmOd0FqCPxS2qT8PJTYHTiPDP7dyYDc865nKqqClfsM2ZsTvQzZsC/Y+qTYN99oUcPOOOMkOi7d4du3bJy1b4t6rrin04o109WXGNA54xE5Jxz2WYGH3wAb7yx+TFjBqxbF+Y3bQoHHRQS/CGHhEfPnrDDDrmNu5FqTfxmtk82A3HOuaz54guYOnXLRP/JJ2Fe8+bQuzcMGRL+HnII7L8/lJXlNuY0SmmwdUlnAEcTrvSnmNnfMxmUc86l1QcfwJQp4fHKK6Fc3mLb0f32g/79oW/fcMO1Z8+iSvLJ1Jv4JQ0HurK5jP9ySSea2RUZjcw55xrDDObO3Zzop0yBJUvCvJ12gm9+E84+OyT5ww4L1SdLTCpX/McDB8TuFZA0Engno1E551yqqqpCefxLL21O9CtXhnm77QbHHANXXx0aQR10UF7Uqsm1VBL/AqAjobEVwF5xmnPOZZ8ZvPMOPP88TJoEL74Iq1eHeV26wKmnhmR/zDGhKqVqa05UuuqqzvkkoUy/FTBX0pvxdV/gzeyE55xzhFau1Yn++efh09jFV5cucM450K8fHHtsaADl6lXXFf+dWYvCOecSLV8eEnz1Y/HiML19+3Aj9vjjw2PvvXMaZqGqqzrni9kMxDlXwtavD2XzzzwTHnPmhOm77BKu5n/2s5Dou3Xzops0SKVWzxHA/wEHAE2BJsCXZrZThmNzzhUrM3jvvc2J/sUXQ2Oppk3DTdgLLoBvfxt69YLtsjJeVElJ5ebuPcB5wGNAH+ACYL9MBuWcK0KrVoUy+n/+EyZO3FzFsls3uPRSOOmkUE5foK1hC0lKDbjMbIGkJmZWBTwY++a/PrOhOecKWlUVTJu2+ar+jTfCtJ12ghNOgBtvDMk+j8vpy+eVM3HhRPp36c+AbgNyHU7apJL4K+LAKzMl3Q4sJ0tj9TrnCsznn4ckP2FCuLL/7LNQJt+nD1x/fUj0ffsWRMvY8nnlDBo7iIrKCh6c+SCjzxxdNMk/lcT/fUK5/lDgp4R6/GdmMijnXIEwC90fTJgATz0Fr74arurbtg1dEp9yCpx4Iuy6a64jbbCJCydSUVkBQEVlBRMXTiydxG9m1Q231gG/yGw4zrm8t24dvPBCSPYTJoR+cIClnXdl3aVnsN8FP4XDDy/4FrL9u/TnwZkPUlFZQcuylvTv0j/XIaVNXQ24HjWzcyTNJg67mMjMemY0Mudc/li6dHOinzQpJP+WLeGEE3j7B9/lrC8fYEHLz2hZNoHRbc5nQIEnfYAB3QYw+szRJVfGf1X8+71sBOKcyyMbN8Lrr29O9rNnh+mdO8Mll8B3vxtq4DRvzv1PD2XB1PVA8RWJDOg2oGj2JVFdDbiWx0HW/2Jm/bIYk3Muy8rnlTN5zlMM+rANh01fHpL9ypVhjNijj4Y77oDvfS9pA6piLhIpVnWW8ZtZlaRNknY2s9XZCso5lyUffcTb9/+KZo+M4NaFm2hWBV/t3IqmAwaGzs7694edd65zFcVcJFKsUqnVsxaYLelZ4MvqiWZ2Zcaics5lhlkotikvh/HjYdo0DgZ22AXuORzKu8HBZ5zP3acOb9Bqi7VIpFilkvifiA/nXCGqrAz94IwfHxL+4sWhuKZvX7jlFp7v2YpTZ/6cio3raFnWkqv3+06uI3YZlkp1zpHZCMQ5l0arV4cGVOXl8PTTobuE5s1Dnfobbwzl9bvvDoSRlkZ37ehFNWmWz61+ZbZVTc0tF5D2BW4FugPNq6ebWefMhrZZnz59bNq0adnanHOFackSePLJcGU/eXK40m/XLiT5004L3SR4PzhZkdjqt2VZy5y1+pU03cz61JyeSlHPg8B/A3cB/YD/wLtscC73zGDWLBg3LlzZz5gRpnfrBj/9KQwYEMaVLYI69YUm31v9ppL4W5jZJEmKrXiHSZoO3Jzh2JxzNVVVwWuvhWQ/bhwsWhTK6486Cm6/PST7bt1yHWXJy/cqrqkk/g2StgPmSxoKfAjsmNmwnHNf++qrMArVuHHw97+HYQebNg1FNzfcEJL9N76R9K35XM5czPK9imutZfySdjezjyUdBswFWgO/AnYC7jCz17MVpJfxu5Kzdi384x8h2U+YAF98ATvuGDo9O+OM0AHaTnWPhZQv5cwudxpTxj9T0hxgNDDfzJYRyvedc5nw2Wfh5uwTT8Czz8KGDaFXy7PPhtNPDyNSNW9e/3qifC9ndrlTV+LfEziBMPrWLZJeJ3wJjDezddkIzrmit3Tp5vL6l16CTZugY0e4/PJwZX/UUY2+OZvv5cwud+qtzgkQB2I5mfAl0A+YZGaD63nPA4QO3j41swPjtGHApcCKuNgNZvZ0fdv3oh7XEHlfrj137uZkX/257tEjXNWffjocckjaBhTP+2PhMqq2op6UEn9cwb7AIOB8YK2Z9a5n+W8Runt4qEbiX2tmdzYkeE/8LlV5Wa5tFhL8E0+EZD9vXpjet+/mZL+fD2Pt0q9R9fgl7UW4yh8E7EAo6hlgZu/Vt0Eze0lSp8aF61zj5E259qZNoVvjxx+HsWND46omTaBfP7jyytCgas89G7RKv3p36VLXQCyvEsr5HwUuNbPpadrmUEkXANOAq83s81q2PwQYAtCxY8c0bdoVu5yWa1dVwSuvbE72H30Uql327w+/+EWodtmmTaNWXczjv7rsq+uK/zpgiqVaFpSaPxCqhFr8+zvgB8kWNLMRwAgIRT1pjMHVohiuKLNef3rjRnjxxZDsn3gi1LFv3jxUtzzrrNBdQj3VLlORN79kXFGoayCWl9K9MTP7pPq5pPuBp9K9Ddc4xXRFmfEugqsbVI0dG8rsV64MwxB+97sh2Z9ySqhzn0ZeQ8elUyotd9NGUnszWx5fng7Myeb2Xe38irIe69eHuvVjx4ZO0FatglatwmAlZ50FJ50Ukn+G5HtLUFdY6k38kvYxs0X1TUvyvtHAccCukpYROno7TlIvQlHPYuCyxoXt0s2vKJNYty50bfz446Fh1Zo10Lp1KKs/66zQxXEDGlRtKx/sxKVLKt0yv1Wz6masInRoRiNL4NU5s6MYyvi32bp1oauEMWNCVwlffhluyJ5+ekj2xx8fbtg6VwAaXJ1T0v5AD2BnSWckzNqJhH75XfEo2SvKDRtg4sSQ7MePD/3k7LorDB4cuks49lgoK8t1lM6lTV1FPd0ILW9bA6cmTF9DaH3rXOGqrIRJk0KyHzcujFi1yy5w7rnh0a8fbJ/VW2DOZU1dtXrGA+MlHWlmr2UxJucyo7rq5ZgxoerlypWhquXAgSHZn3CCF+O4kpDKJc0CSTcAnRKXN7Ok9e9d/iupsvxNm+Dll0Oyf/zxUM9+hx3CDdpzzw21cbJ4g9a5fJBK4h8PTAGeA6oyG47LtGKqr18rM3jjDfjb3+Cxx0IL2hYtQj37c88N9ewzWPXSuXyXSuJvaWbXZjwSlxVFXV9/7lwYNQoeeSQMSdisWWhBe845ob59mhtVOVeoUhk0/SlJp2Q8EpcV/bv0p2VZuNotivr6H34Iv/sd9O4N3bvDrbdC167w4IPwySfhxu2gQZ70nUuQSj3+NYSeOb+KDwFmZtveAUmKvB5/ehV8Gf+qVaEF7SOPwAsvgBmfH9iVSUfuTqvvX8xJx1yU6whdhhX8ZzhLtrk//lzyxO9Yvx6efjoU5UyYEOred+0Kgwcz6YjdGPDWNfnVB7/LmLwccyFP1Zb46y3qUXC+pP+Kr/eSdHgmgnRuC5s2weTJcMklsPvucOaZoYbOZZeFm7f/+hcMG8a4Te9sdd+iPuXzyhn69FDK55VneCcyr5j2JRXJ7lO5hkmljH84cCTw/+LrtcC9GYvIuQUL4OaboXPn0JBqzJgwcMkzz4Qy/d//Hg4//OvhCRt636L6ivHeqfcyaOyggk6YxbQvqSq6+1Q5kEqtnr5m1lvSDAAz+zyOwetc+qxeHapejhwZruql0AnaLbeEBlZ1VL9saM+VxVSzqZj2JVXeU+m2SyXxV0pqQuhRE0ntgE0ZjcplTF7dFKuqCt0mjBwZWtKuXw/77x9q5px/PnTokPKqGtLPUL71RLot5yTf9iVbSrZfqTRJpVbPYOBcoDcwEjgLuMnMHst8eIHf3E2PvLkp9t57Idk//HAoumndOlS5vPDCLYpwMilfvgDTcU7yZV9c/mnUYOsAZjZK0nTg24SqnAPNbG4GYnQZltNigbVrQ1n9n/4UBiFv0gS+8x24667QuCrL3SbkyxVjOs5JvuyLKxy13tyV1Kb6AXwKjAYeAT6J01yByfpNMTN4800YMgTatw+1c1avhjvugGXL4KmnQrfHJdxXjt+odLlQa1GPpEWEcn0BHYHP4/PWwBIz2ydLMXpRTxplpVjg88/hr38NV/ezZoUbs+eeGxL/kUdmpSinkHhRjcuURjfgioOijzOzp+PrkwnFPVkbNtETfwEwg5degvvvD71gbtgAhx4Kl14K550HO++c6widKzmNLuMHjjCzrwdeMbN/SLo9rdG5vNKgK9CVK0O/OCNGwPz5IcFffHG4uj/kkOwE7JxrkFQS/0eSbgL+Gl8PBj7KXEgul1LutnnqVLj33tD18YYNcPTRcNNNYVxa7/J4m3nxj8ukVFruDgLaAePi4xtxmitCdTaHX7cuXN0fdliodjl2LPzgBzB7NkyZAhdc4Ek/DYq9NW6pdTGRj+pN/Gb2bzO7yswOiY+rzOzf2QjOZV/SWiYLFsA118Cee4ZEX1EB99wT6uAPHw4HHpjjqItLMfdFU+xfaoWi3qIeSfsB17D10IvHZy4sl2m1FSVUN4d/dv4zDP6oLUf85A/wz3+GgcdPPx1+9CM49livmZNBxdwatxS7mMhHqZTxPwbcB/wJH3qxKNRZjv/llwx4/kMG/H4SzJsX6t8PGxZq5+yxR07jLhXF3BdNMX+pFZJUEv9GM/tDxiNxWZP0qmuH3qH4ZsSIUA+/T5/Q9/3ZZ0NZWY4jLj3F2hq3mL/UCkkq9fiHEVrujgM2VE/PZjm/1+NPr8Qr/qM/acboJX3p8Myrof/700+Hn/4UvvlNL85xrsBtSz3+C+PfnyVMM6BzOgJz2Tdg3+8xudWVtLlvJF3eXQ6tZsCPfxwe+2StQbZzLkdS6aTNM0Gx2LAhdKVwxx0cNm9eSPL/+7/wH/8BO2VtCGXnXI6lMvRiS0k3SRoRX+8r6XuZD82lzZo18LvfhRGtLrkk1LUfMya0tL3qqm1K+l4nu25+fFw+SqWo50FgOvDN+PpDQk2fpzIVlEuTTz+Fu+8OLWxXrYLjjw8NsE48MS3l9ym38i1Rfnxcvkql5W4XM7sdqAQwswpCL50uXy1ZAkOHwt57h6ELjz8+DE4+aRL075+2m7bF3NAItv1qvdiPjytcqST+ryS1YPPQi11IqN1TG0kPSPpU0pyEaW0kPStpfvy7S6Mjd1v74AO47DLo2jVUyxw8GObODV0rHH542jdXzH3Jp6OFaTEfH1fYUkn8/w38E9hL0ihgEvDzFN73F+A7NaZdB0wys33jeq5LPVRXq0WLQgOrrl3hL38JzxcuDP3hd+uWsc1W18m+4rAriq4YIx1X68V8fFxhq7ceP4CktsARhCKe183ss5RWLnUCnjKzA+PrecBxZrZcUntgspnVm5m8Hn8t3n8/FOWMHAnbbRcS/nXXNWiQcpdc3oxP7Nw22JZ6/ADHAkcTinvKCI25GmM3M1sen38M7FbbgpKGAEMAOnbs2MjNFanFi+GXv4SHHgp96Pzwh3DttaETNZcW3sLUFbNUWu4OB7oSxtwFOBdYaGZX1Lvyra/4V5lZ64T5n5tZveX8fsUfffIJ/PrX8Mc/hiv8yy+Hn/98iz50vB9351y1bbniPx44wOI3hKSRwDuNjOMTSe0Tino+beR6SsuqVXDnnXDXXaER1sUXw803b3WF79UHnXOpSOXm7gLCYOvV9orTGqOczV1AXAiMb+R6SkNFBdx+e2h49ZvfwIABoZbOH/+YtFjHqw8651KRSuJvBcyVNFnSC8C7wE6SyiXVWsdN0mjgNaCbpGWSLgZuA06UNB84Ib52NW3cGJJ7166h7P6II+Ctt2D0aNh331rf5tUHnXOpSKWo5+bGrNjMahue8duNWV8+Snt5ulkY9OTqq8OV/VFHha4Vjjkmpbf7DUnnXCpSrc65N7CvmT0XG3Ntb2ZrMh5dlI83d9Ne3W/27DC84cSJ4Ur/jjvgtNO8a2TnXKPVdnM3lU7aLgUeB/4YJ3UA/p7W6ApQ2srTP/4YhgyBXr1g6tTQW+Y778DAgZ70nXMZkUoZ/xXAUcAXAGY2H/hGJoMqBNtcnr5uXWh8te++oeO0K68Mg5pfdRU0bZqBiJ1zLkiljH+DmX2lePUpaXtivz2lbJvK0598MiT4RYvClf1vfwv77deoOPKt3n6+xeOc21oqif9FSTcALSSdCPwIeDKzYRWG6sRWXcxTb6JbsAB+8hOYMAEOOACeew6+3fh73flWbz/f4nHOJZdKUc91wApgNnAZ8DRwUyaDKhQp9+BYUQH/9V/Qowe8+GJojPX22w1K+sm6CM63evv5Fo9zLrl6E7+ZbSLczP2RmZ1lZvdbKlWBSkC9ic4Mxo2D7t1DVwtnnQXz5oXqmmVlKW+nti+YfKu3n2/xOOeSqzXxKxgm6TNgHjBP0gpJjarXX4zqTHRLlsCpp8IZZ0CrVjB5MowatUW/Oqmq7Qsm37r9zbd4nHPJ1VqPX9J/AicDQ8xsUZzWGfgD8E8zuytbQeZjPf5qW93MrKqCe+6BG28MV/y/+hX8+McNusJPto2abQYAv4nqnKtTbfX460r8M4ATa/a9L6kdMNHMDslIpEnkc+Lfwttvhz7xp06Fk0+G4cOhU6e0rDrxCwbwvuKdc/VqTAOusmQDrpjZCkKf/K7aunVhAJRDDw3DH44eHWrupCnpQyhGueeUexjQbYDfRHXObZO6Ev9XjZxXWl58EQ46KNTFv/DC0MfOeedltNWt30R1zm2LuurxHyzpiyTTBTTPUDyFo6ICbrgBfv976NIFnn8e+vXLyqa9Mzbn3LaoNfGbWZNsBlJQXn0VLroI5s8PN25vvRV22CGrIQzoNsATvnOuUVJpwOWqrV8PP/sZHH00VFaGq/y778560nfOuW1R0ok/WWvYWk2dCr17h1a3Q4bArFnQr1/D1uGcc3mgZBN/yt0tVFWFYQ+PPBLWrIFnnoH77oNWrVJfh3PO5ZGSTfwpVYlcuhSOPx5uugnOPjsMltK/f8PW4ZxzeaZkE3+9VSIfewx69gxj3Y4cCY88Aq1bN2wdzjmXh1IaejHXMtVyN2nf8WvXhkFRHnwQ+vYN/et06VJrP/Pe/7xzLl81uMuGfJK1LhveegvOPRcWLgx97dx8M5SVpX98Xeecy4JGj7lbEszCDdtvfjNU2Zw8OXSuFjtW87J851wx8cS/di2cfz788Ieh5e2MGfCtb22xiJflO+eKSSpDLxavOXNCbZ1//SsMlHL99bDd1t+F3kWCc66YlG7iHzkyXOXvtFMY+7aefna8iwTnXLEovaKeDRvgsstCXzt9+8LMmVnrXM055/JBaSX+5ctDg6wRI+Daa+HZZ2H33XMdlXPOZVXpFPW88UYY/3bVKhgzBs45J9cROedcTpTGFf+DD4aaOs2awWuv1Zn0vdM151yxK+7EX1kJQ4fCD34QEv/UqaEbhlp4p2vOuVJQ3Il/yBC49164+mr4xz+gbds6F/eGWs65UpCTxC9psaTZkmZKylxfDNdcE/raufNO2L7+2xneUMs5VwpyeXO3n5l9ltEt9OgRHinyhlrOuVJQOrV6UuQNtZxzxS5XZfwGTJQ0XdKQHMXgnHMlKVdX/Eeb2YeSvgE8K+k9M3spcYH4hTAEoGPHjrmI0TnnilJOrvjN7MP491NgHHB4kmVGmFkfM+vTrl27bIfonHNFK+uJX9IOklpVPwf6A3OyHYdzzpWqXBT17AaMk1S9/UfM7J85iMM550pS1hO/mb0PHJzt7TrnnAuKu+Wuc865rXjid865EuOJ3znnSownfuecKzGe+J1zrsR44nfOuRLjid8550qMJ37nnCsxnvidc67EeOJ3zrkS44nfOedKjCd+55wrMZ74nXOuxHjid865EuOJ3znnSownfuecKzGe+J1zrsR44nfOuRLjid8550qMJ37nnCsxRZ34y+eVM/TpoZTPK891KM45lzeKNvGXzytn0NhB3Dv1XgaNHeTJ3znnoqJN/BMXTqSisgKAisoKJi6cmOOInHMuPxRt4u/fpT8ty1oC0LKsJf279M9xRM45lx+2z3UAmTKg2wBGnzmaiQsn0r9LfwZ0G5DrkJxzLi8UbeKHkPw94Tvn3JaKtqjHOedccp74nXOuxHjid865EuOJ3znnSownfuecKzGe+J1zrsTIzHIdQ70krQA+aMRbdwU+S3M4uVRM+1NM+wLFtT/FtC9QXPvT0H3Z28za1ZxYEIm/sSRNM7M+uY4jXYppf4ppX6C49qeY9gWKa3/StS9e1OOccyXGE79zzpWYYk/8I3IdQJoV0/4U075Ace1PMe0LFNf+pGVfirqM3znn3NaK/YrfOedcDZ74nXOuxBRt4pf0HUnzJC2QdF2u42koSYslzZY0U9K0OK2NpGclzY9/d8l1nLWR9ICkTyXNSZiWNH4Fd8dzNUtS79xFnlwt+zNM0ofxHM2UdErCvOvj/syTdFJuok5O0l6SXpD0rqR3JF0Vpxfc+aljXwr13DSX9Kakt+P+/CJO30fSGzHuMZKaxunN4usFcX6nlDZkZkX3AJoAC4HOQFPgbaB7ruNq4D4sBnatMe124Lr4/Drgt7mOs474vwX0BubUFz9wCvAPQMARwBu5jj/F/RkGXJNk2e7xM9cM2Cd+Fpvkeh8S4msP9I7PWwH/ijEX3PmpY18K9dwI2DE+LwPeiMf8UeC8OP0+4Ifx+Y+A++Lz84AxqWynWK/4DwcWmNn7ZvYV8DfgtBzHlA6nASPj85HAwNyFUjczewn4d43JtcV/GvCQBa8DrSW1z0qgKaplf2pzGvA3M9tgZouABYTPZF4ws+Vm9lZ8vgaYC+xJAZ6fOvalNvl+bszM1saXZfFhwPHA43F6zXNTfc4eB74tSfVtp1gT/57A0oTXy6j7w5CPDJgoabqkIXHabma2PD7/GNgtN6E1Wm3xF/L5GhqLPx5IKHormP2JRQOHEK4sC/r81NgXKNBzI6mJpJnAp8CzhF8lq8xsY1wkMeav9yfOXw20rW8bxZr4i8HRZtYbOBm4QtK3Emda+G1XsHVxCz3+6A9AF6AXsBz4XU6jaSBJOwJjgZ+Y2ReJ8wrt/CTZl4I9N2ZWZWa9gA6EXyP7p3sbxZr4PwT2SnjdIU4rGGb2Yfz7KTCO8AH4pPondvz7ae4ibJTa4i/I82Vmn8R/0k3A/WwuMsj7/ZFURkiUo8zsiTi5IM9Psn0p5HNTzcxWAS8ARxKK16rHSE+M+ev9ifN3BlbWt+5iTfxTgX3jnfCmhJse5TmOKWWSdpDUqvo50B+YQ9iHC+NiFwLjcxNho9UWfzlwQaw9cgSwOqHIIW/VKOc+nXCOIOzPebHGxT7AvsCb2Y6vNrEM+M/AXDP7n4RZBXd+atuXAj437SS1js9bACcS7lu8AJwVF6t5bqrP2VnA8/HXWt1yfRc7Uw9CTYR/EcrHbsx1PA2MvTOh5sHbwDvV8RPK7iYB84HngDa5jrWOfRhN+IldSSiTvLi2+Ak1Ge6N52o20CfX8ae4Pw/HeGfFf8D2CcvfGPdnHnByruOvsS9HE4pxZgEz4+OUQjw/dexLoZ6bnsCMGPcc4OY4vTPhC2oB8BjQLE5vHl8viPM7p7Id77LBOedKTLEW9TjnnKuFJ37nnCsxnvidc67EeOJ3zrkS44nfOedKjCd+l1WS1ta/1BbLHyfpqUzFk8L2GxRvjfdeJGmPJNMvlDS6xrRdJa2Q1CzFdfeRdHcK27+nlnmN3i9X+DzxO5c5FwFbJX5CS+wTJbVMmHYW8KSZbahvpZK2N7NpZnZlesJ0pcYTv8uJeCU/WdLjkt6TNKq6V0GFsRTek/QWcEbCe3aIHW69KWmGpNPi9IskjY/rmy/pvxPec35cfqakP0pqEqevlfSb2O/565J2i9P3kfSawlgIv64R888kTY0df1X3k95J0lxJ9yv0nz5RUgtJZwF9gFFx2y2q12OhL5kXgVMTVn8eMFrSqQr9qs+Q9FxCXMMkPSzpFeDhxF9Ckg6PMc+Q9Kqkbgnr3SvZcalvv1yRy3VLNX+U1gNYG/8eR+hJsAPhAuQ1QivM5oTeBvcltBh9FHgqvucW4Pz4vDWhZfYOhCvr5YSWpy0ILR77AAcATwJl8T3DgQvicwNOjc9vB26Kz8sTlrkiId7+hIGuFeN9itBHfydgI9ArLvdoQoyTqaWVK+EKf1x8vgfwEWEciV3YPBb2JcDv4vNhwHSgRcLxqz4uOwHbx+cnAGPj86THpcZ5SLpfuf6c+COzj+pOf5zLhTfNbBmAQje0nYC1wCIzmx+n/xWo7pa6PzBA0jXxdXOgY3z+rJmtjO95gvAlshE4FJgaf0y0YHPHY18RkhyEhHpifH4UcGZ8/jDw24Rt9yc0pwfYkfDltCTGOzNhXZ1S2PcJwHBJOwHnEJJ1laQOwJjY10xTYFHCe8rNbF2Sde0MjJS0L+ELrSxhXrLjMi1hfm379VIK++AKlCd+l0uJ5dlV1P95FHCmmc3bYqLUl627ELa4/Egzuz7JuirNrPo9NbedrB8TAbea2R9rbLtTkv1oQT3MbJ2kfxI6EDsP+M846/+A/zGzcknHEa70q31Zy+p+BbxgZqfHeCbXsS81XyfdL1fcvIzf5Zv3gE6SusTXgxLmPQP8OOFewCEJ805UGDO2BWF0olcIHY6dJekbcfk2kvauZ/uvEBIxwOAa2/6BQr/vSNqzer11WEMYDrA2owkJfzdCUReEq/fqLncvTPamJBLfc1GNecmOS6LG7JcrcJ74XV4xs/WEop0J8eZu4pgDvyIUY8yS9E58Xe1NQp/sswjFJtPM7F3gJsJIZrMIoxnVN2TgVYSBb2aTMDKTmU0EHgFei/Mep+6kDvAX4L6aN3cTPEso3x+T8OtjGPCYpOnAZ/Wsv9rtwK2SZrD1r6atjkvizEbulytw3junK3iSLiLctBya61icKwR+xe+ccyXGr/idc67E+BW/c86VGE/8zjlXYjzxO+dcifHE75xzJcYTv3POlZj/D5rZ8MGWGtSrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the results\n",
    "plt.scatter(X_test, y_test, s=10, label='Testing Data', color='green')\n",
    "plt.plot(X_range, poly_model.predict(poly_features.transform(X_range)),color='red')\n",
    "plt.xlabel('Independent Variable')\n",
    "plt.ylabel('Dependent Variable')\n",
    "plt.title('Polynomial Regression with Train-Test Split')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpP5WF3MxCuV"
   },
   "source": [
    "- Now, call the function to get the scatter plot with a red line showing how the line fits the given data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5B97xf9nxCuV"
   },
   "source": [
    "__Observation:__\n",
    "\n",
    "- As you can see, the regression line is able to fit majority of the data points.\n",
    "- You can infer from the above implementation that non-linear inputs require non-linear models, such as the polynomial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J52SfT_C8J_b"
   },
   "source": [
    "## __3.7 Model Evaluation and Validation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1BRELYW_yxO"
   },
   "source": [
    "### **3.7.1 Performance Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3n6tcu5_yxO"
   },
   "source": [
    "- Evaluation metrics help in regression analysis as they provide quantitative measures of model performance, aiding in the assessment and selection of regression models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvZrTuXB_yxO"
   },
   "source": [
    "In regression analysis, several evaluation metrics are commonly used to assess the performance of a regression model. Some of the key evaluation metrics include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEh46Ts9RTIP"
   },
   "source": [
    "#### **1. Mean Squared Error (MSE):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKeXf4e2_yxO"
   },
   "source": [
    "\n",
    "It calculates the average of the squares of the errors, which are the differences between the actual and predicted values. A lower MSE indicates better model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt9YDaAuReJz"
   },
   "source": [
    "#### **2. Root Mean Squared Error (RMSE):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j7-dVfuQ21e"
   },
   "source": [
    "\n",
    "RMSE is the square root of the MSE, providing a measure of the average magnitude of the errors in the predicted values. Since the square root reverses the squaring operation of MSE, RMSE ends up having the same units as the original dependent variable, making it easier to interpret than MSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCl6qw42RNGF"
   },
   "source": [
    "#### **3.  Mean Absolute Error (MAE):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPXjQ-xgQ8hf"
   },
   "source": [
    "\n",
    "MAE calculates the average of the absolute errors between the actual and predicted values. It's less sensitive to outliers compared to MSE and RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc7exP-tRIxO"
   },
   "source": [
    "#### **4.  R-squared (R2):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrXe7NhWRFXt"
   },
   "source": [
    "\n",
    "R-squared explains how much of the variation in the dependent variable(y) can be attributed to the changes in the independent variable(x). R-squared values range from 0 to 1.\n",
    "\n",
    "* **0**: This indicates that the model explains none of the variance in the dependent variable. The independent variables have no explanatory power for the changes in y.\n",
    "\n",
    "* **1**: This represents a perfect fit. The model explains all of the variance in the dependent variable. The changes in y are perfectly captured by the changes in X.\n",
    "\n",
    "While a higher R-squared generally suggests a better model fit, it's not the only factor to consider. A very high R-squared might be achieved by a model that's simply overfitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6mx4Dpg6m3q"
   },
   "source": [
    "### __3.7.2 Cross Validation Techniques__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhZQnXbO68iX"
   },
   "source": [
    "Cross-validation is a machine learning technique that evaluates model performance on unseen data by dividing the data into multiple folds. In each iteration, one fold is used as a validation set and the remaining as training data. This process is repeated such that each fold serves as the validation set once. The results from all iterations are averaged to provide a robust estimate of model performance. Some of the common cross-validation techniques are:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rVJTxNaB49j"
   },
   "source": [
    "**1. K-Fold Cross-Validation**\n",
    "\n",
    "In K-Fold Cross validation, the dataset is divided into k equally sized folds. The model is trained on k-1 folds and tested on the remaining fold. This process is repeated k times, with each fold used exactly once as the test set. The results are averaged to produce a single performance estimate.\n",
    "* Pros: Provides a more accurate estimate of model performance.\n",
    "* Cons: Computationally intensive for large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_PhSCAdCFUa"
   },
   "source": [
    "**2. Stratified K-Fold Cross-Validation**\n",
    "\n",
    "Similar to K-Fold but ensures that each fold has the same proportion of different classes as the original dataset. This is especially useful for imbalanced datasets.\n",
    "* Pros: More reliable performance estimates for imbalanced datasets.\n",
    "* Cons: Still computationally intensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhWbSRE1IPAQ"
   },
   "source": [
    "**3. Holdout Method**\n",
    "\n",
    "In holdout method, the dataset is divided into two sets, a training set and a test set. The model is trained on the training set and evaluated on the test set.\n",
    "\n",
    "* Pros: Simple and fast.\n",
    "* Cons: The evaluation may be noisy due to the variability in the training/test split.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEPaQtIICHpx"
   },
   "source": [
    "**4. Leave-One-Out Cross-Validation (LOOCV)**\n",
    "\n",
    "A special case of k-fold cross-validation where k is equal to the number of data points in the dataset. Each observation is used once as a test set, and the model is trained on all remaining data points.\n",
    "* Pros: Maximizes the amount of training data used.\n",
    "* Cons: Extremely computationally expensive, especially for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goSOP67bDLtZ"
   },
   "source": [
    "**Now, let's build a linear regression model, perform analysis on it, and evaluate the model's performance:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ehPljYr3KaP"
   },
   "source": [
    "#### Step 1: Set up and Data Loading\n",
    "- Import the necessary libraries: numpy, pandas, matplotlib.pyplot from sklearn.datasets.\n",
    "- Load the housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "THDdUArEDNEW"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDJpo4KwBfef"
   },
   "source": [
    "#### Step 2: Initial Data Exploration\n",
    "- Explore the first few rows, generate statistical summaries, and check for missing values using __.head()__, __.describe()__, and __.isna().sum()__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "v5SFZvXEBfei"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "housing_data = pd.read_csv('housing_with_ocean_proximity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ighMjwF_YhR5",
    "outputId": "baf3536f-a88d-4670-abdd-9e49cd4a3795"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "69iSVsxx3jUI",
    "outputId": "62dc3b74-9031-445c-aeae-3930e5385941"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary statistics for the DataFrame 'housing_df'\n",
    "housing_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNx3tFfi3zQ5"
   },
   "source": [
    "__Observations:__\n",
    "- The house price lies mostly in the price bracket between 1.1 million and 2.6 million.\n",
    "-  Most houses are 18 to 37 years old.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFJBpgZe3rEK",
    "outputId": "4e6f34f0-dfe5-4b61-ab39-45b65e7c848f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "12M_ZF4DJCPe",
    "outputId": "746f82f1-7550-4345-ce93-a3f2d36b6bc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08_K0_m7E458"
   },
   "source": [
    "* Here `total_bedrooms` has null values which we have to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsQgcs0-4C9k"
   },
   "source": [
    "- It can be seen that `total_bedroom` is the only feature with **207** null values.\n",
    "- Since the null values makes up for only 1% of the total data, rows of the column/feature with missing values  will be removed\n",
    "\n",
    "- ocean_proximity is a categorial variable for which we need to craete dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "A7T-GBjxwZei"
   },
   "outputs": [],
   "source": [
    "# Remove all the rows with null values:\n",
    "housing_data = housing_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VamZE-UG4NRe",
    "outputId": "9e196df0-5fd5-4f78-efc4-47535386d090"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck for missing values in the DataFrame 'housing_df'\n",
    "housing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeEAxKZLJCPe"
   },
   "source": [
    "### Let's create dummy variables for ocean_proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCiyFlnVHDeR"
   },
   "source": [
    "- `housing_data`: This is the DataFrame containing your housing data.\n",
    "\n",
    "- `pd.get_dummies`: This is the pandas function that performs the one-hot encoding. It converts categorical variables into a series of binary variables (0 or 1). Each category in the original variable is represented by a separate column.\n",
    "\n",
    "\n",
    "- `drop_first=True`: This parameter drops the first category for each variable. This is done to avoid the dummy variable trap, which is a situation where the dummy variables are highly collinear, causing issues in statistical models. By dropping the first category, you can reduce multicollinearity.\n",
    "\n",
    "- `dtype='int'`: This ensures that the resulting dummy variables are of integer type (0 or 1), which can save memory compared to the default float type.\n",
    "\n",
    "- `prefix='op'`: This parameter adds a prefix to the new dummy variable columns. Here, the prefix 'op' will be added to the beginning of each new column name created by the one-hot encoding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "309_6jQQJCPe"
   },
   "outputs": [],
   "source": [
    "housing_data = pd.get_dummies(housing_data, drop_first=True, dtype='int',prefix='op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zK912VMK5mw1"
   },
   "source": [
    "#### Step 3: Prepare the dataset\n",
    "\n",
    "**Steps to be followed:**\n",
    "\n",
    "- Prepare your features (X) and target (y) for modeling.\n",
    "   * The target feature, which is the feature we are trying to predict, is `median_house_value`. This is assigned to the variable y.\n",
    "   * The features used to predict the target are the independent variables(X).\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hai6a063E0zx"
   },
   "outputs": [],
   "source": [
    "#Assign values to X and y\n",
    "X = housing_data.drop(['median_house_value'], axis=1)\n",
    "y = housing_data['median_house_value']\n",
    "\n",
    "# Splitting the data into training and testing sets to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syooZB82LjjO"
   },
   "source": [
    "#### Step 4: Perform K Fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANTOgamuDW3X"
   },
   "source": [
    "**Key components**\n",
    "\n",
    "- KFold: Implements K-fold cross-validation.\n",
    "- n_splits=10: Divides the dataset into 10 folds.\n",
    "- random_state=42: Ensures reproducible shuffling.\n",
    "- shuffle=True: Shuffles the data before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rf_Clu2wDbFl"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "126rIXh8MsVH"
   },
   "source": [
    "#### Step 5: Initialize the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nGAP_uGiMpMD"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDzV7ZusDeu5"
   },
   "source": [
    "**Evaluate the model**\n",
    "\n",
    "- cross_val_score: Evaluates the model using cross-validation.\n",
    "- model: The machine learning model to evaluate.\n",
    "- X_train and y_train: Training features and target variables.\n",
    "- scoring='neg_mean_absolute_error': Uses negative MAE as the performance metric.\n",
    "- cv=kf: Cross-validation strategy (e.g., KFold).\n",
    "- n_jobs=-1: Utilizes all available processors for parallel computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1fqk5Iq9DiZ3"
   },
   "outputs": [],
   "source": [
    "k_fold_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyZHxiciOFRg"
   },
   "source": [
    "**Evaluating Cross-Validation Scores:**\n",
    "\n",
    "\n",
    "Calculate metrics (e.g., Mean Absolute Error, Mean Squared Error) from cross-validation scores to evaluate the model's performance.\n",
    "\n",
    "- np.abs(scores): Converts negative MAE values to positive MAE values.\n",
    "- np.mean(scores): Calculates the average MAE across all 10 cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abbHFi0BDq6d",
    "outputId": "5617130e-0148-44fa-c5d1-414b1a736292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49936.917814738656"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean\n",
    "np.mean(np.abs(k_fold_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ITN0FEd-kJ8"
   },
   "source": [
    "#### Step 6: Train the Model and Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRLHCUMlOiXM"
   },
   "source": [
    "**Now fit the model with train data and calculate MSE for test data.**\n",
    "- Train the model using the training data `X_train` and `y_train`.\n",
    "- Uses the trained model to make predictions on the test data `X_test`.\n",
    "- Calculates the Mean Squared Error (MSE) between the actual test target values `y_test` and the predicted values `y_test_pred`.\n",
    "- Print the calculated Test MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByLMPdOBDvfI",
    "outputId": "daf0db47-d022-440e-8514-c4ba183dc639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 4614164009.958682\n",
      "Test R-squared: 0.6538753735673436\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "\n",
    "# Calculate R-squared score\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test R-squared: {test_r2}\")\n",
    "\n",
    "# add the train score as well.\n",
    "# compute RMSE instead of MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRchOGpd_LBS"
   },
   "source": [
    "**Observation**\n",
    "- An MSE of `4614164009.958683` is quite large, indicating that on average, the squared prediction errors are large. This can be interpreted in the context of the units of the dependent variable (`median_house_value`), which are likely in dollars.\n",
    "\n",
    "- This can further be mitigated by Scaling the features. Feature scaling is critical in machine learning to ensure that all features contribute equally to the model’s prediction. We'll discuss about it in detail, further in the lesson\n",
    "\n",
    "- An R2 score of `0.65` means that approximately `64%` of the variance in `median_house_value` is explained by the model. This suggests that while the model captures a significant portion of the variability, there is still `35%` of the variance unexplained by the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNYZURcXN1Ku"
   },
   "source": [
    "**Repeat the process to demonstrate LOOCV:**\n",
    "\n",
    "* X_train, y_train  is same across all CV implementation\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sq8yImPN0I8",
    "outputId": "51f09357-9a5d-4f13-95b2-5e50ff800f25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49931.807859013"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform LOOCV\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Compute Cross-validation scores\n",
    "loocv_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=loo, n_jobs=-1)\n",
    "\n",
    "np.mean(np.abs(loocv_scores))\n",
    "\n",
    "# add the same for train test eval score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RNZfRnpYa-p"
   },
   "source": [
    "**Note: Stratified K-Fold is typically used for classification problems. For regression, standard K-Fold is preferred.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCw0nNvHVpgj"
   },
   "source": [
    "**Observation**\n",
    "\n",
    "Mean Absolute Error is quite high. To improve the model, more complex model can be considered which will be discussed in further lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eldlXGH_JTcY"
   },
   "source": [
    "## __3.8 Regularization__\n",
    "\n",
    "**Regularization in Regression**\n",
    "\n",
    "In linear regression, regularization encompasses a set of techniques employed to address the issue of overfitting.\n",
    "\n",
    "**Core Concept**\n",
    "\n",
    "Regularization techniques achieve their objective by introducing a penalty term to the model's objective function. This objective function, typically measured by mean squared error, is minimized during the training process. The penalty term discourages the model from attaining excessive complexity by penalizing the size of the model coefficients, thereby mitigating overfitting.\n",
    "\n",
    "**Regularization term** or `alpha`: is a hyperparameter that scales the penalty term. It controls the strength of regularization.\n",
    "- Higher `alpha`: Imposes a stronger penalty on the coefficients, leading to greater regularization. This tends to produce a simpler model that may underfit the training data but often generalizes better to unseen data.\n",
    "- Lower `alpha`: Imposes a weaker penalty, leading to a model that is less restricted by the regularization and more complex, potentially capturing more details in the data but at the risk of overfitting.\n",
    "\n",
    "**Benefits of Regularization**\n",
    "\n",
    "Enhanced Generalizability: By mitigating overfitting, regularization fosters models that perform well on unseen data.\n",
    "\n",
    "Reduced Model Complexity: It promotes interpretability and potentially reduces computational costs associated with training complex models.\n",
    "\n",
    "\n",
    "Common Regularization Techniques are:\n",
    "\n",
    "* Lasso Regression (L1 Regularization)\n",
    "* Ridge Regression (L2 Regularization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0Vhf1fTs9x2"
   },
   "source": [
    "### __3.8.1 Least Absolute Shrinkage and Selection Operator (Lasso) Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEEw4MYRs9x9"
   },
   "source": [
    "**Least Absolute Shrinkage and Selection Operator (Lasso) Regression** relies upon the linear regression model but additionaly performs a so called L1 regularization, which is a process of introducing additional information in order to prevent overfitting. As a consequence, we can fit a model containing all possible predictors and use lasso to perform variable selection by using a technique that regularizes the coefficient estimates (it shrinks the coefficient estimates towards zero).\n",
    "\n",
    "- It performs variable selection or feature selection.\n",
    "- It forces some of the coeﬃcient estimates to be exactly equal to zero with the help of a large tuning parameter λ.\n",
    "- It helps reduce the learning of more complex data and overfitting of the model.\n",
    "- It decreases the variance of the model without an increase in bias.\n",
    "  \n",
    "In particular, the minimization objective does not only include the residual sum of squares (RSS) - like in the OLS regression setting - but also the sum of the absolute value of coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsxDX7QZs9x9"
   },
   "source": [
    "**Residual Sum of Squares (RSS)**, which is the sum of square of difference between actual and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Sf0dcOY1xGX"
   },
   "source": [
    "$$ \\text{RSS} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "Where:\n",
    "\n",
    "$y_i$: represents the actual target value from the dataset\n",
    "\n",
    "​$\\hat{y}_i$: represents the predicted target values by the regression model.\n",
    "\n",
    "𝑛: is the number of observations.\n",
    "\n",
    "\n",
    "The predictions ​$\\hat{y}_i$ in a regression model are typically calculated using the linear regression equation. For multiple regression involving several predictor variable, the equation is:\n",
    "\n",
    "\n",
    " $ \\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_nx_ n $ predictor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0P-wUe51xGY"
   },
   "source": [
    "- $ x_1, x_2, \\ldots, x_n $ are the predictor variables,\n",
    "- $ \\beta_1, \\beta_2, \\ldots, \\beta_n $ are the coefficients for each predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txAeH5mJ1xGY"
   },
   "source": [
    "The RSS formula for multiple linear regression can also be written as:\n",
    "\n",
    "$$ \\text{RSS} = \\sum_{i=1}^n \\left( y_i - \\left( \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} \\right) \\right)^2 $$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $ y_i $ represents the actual value for the \\(i\\)-th observation.\n",
    "- $ \\beta_0 \\ $ is the intercept.\n",
    "- $ \\beta_j \\ $ are the coefficients for each predictor \\(j\\).\n",
    "- $ x_{ij} $ represents the \\(j\\)-th predictor variable for the \\(i\\)-th observation.\n",
    "- $ n $ is the total number of observations.\n",
    "- $ p $ is the number of predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VA5VjcUJ1xGY"
   },
   "source": [
    "In Lasso regression, the minimization objective becomes:\n",
    "\n",
    "$$ \\sum_{i=1}^n \\left( y_i - \\left( \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} \\right) \\right)^2 + \\alpha \\sum_{j=1}^p |\\beta_j| $$\n",
    "\n",
    "which equals:\n",
    "\n",
    "$$ \\text{RSS} + \\alpha \\sum_{j=1}^p |\\beta_j| $$\n",
    "\n",
    "Where $ \\alpha \\ $ (alpha) can take various values:\n",
    "- $ \\alpha = 0 \\ $: Same coefficients as least squares linear regression\n",
    "- $ \\alpha = \\infty $: All coefficients are zero\n",
    "- $ 0 < \\alpha < \\infty $: Coefficients are between 0 and that of least squares linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfrSjtdqs9x-"
   },
   "source": [
    "### Now, Let us implement lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPITJ55hs9x-"
   },
   "source": [
    "Import the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "cDUHko_6s9x-"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXYFKNeWs9x-"
   },
   "source": [
    "- You will now read the **Hitters.csv** dataset.\n",
    "- Let us now check the head of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phWuXJEi1xGY"
   },
   "source": [
    "**Description of the Dataset**\n",
    "\n",
    "A data frame with 322 observations of major league players on the following 20 variables (see more about the dataset in this [documentation](https://cran.r-project.org/web/packages/ISLR/ISLR.pdf))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mMY7FDM1xGY"
   },
   "source": [
    "**We want to predict a baseball player's salary based on various statistics associated with performance in the previous year.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "omeHwCDQs9x-",
    "outputId": "9b5c48b5-87fc-44f2-f44c-b74ee1a13031"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>...</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Andy Allanson</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Alan Ashby</td>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>...</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Alvin Davis</td>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Andre Dawson</td>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>...</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Andres Galarraga</td>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  \\\n",
       "0     -Andy Allanson    293    66      1    30   29     14      1     293   \n",
       "1        -Alan Ashby    315    81      7    24   38     39     14    3449   \n",
       "2       -Alvin Davis    479   130     18    66   72     76      3    1624   \n",
       "3      -Andre Dawson    496   141     20    65   78     37     11    5628   \n",
       "4  -Andres Galarraga    321    87     10    39   42     30      2     396   \n",
       "\n",
       "   CHits  ...  CRuns  CRBI  CWalks  League Division PutOuts  Assists  Errors  \\\n",
       "0     66  ...     30    29      14       A        E     446       33      20   \n",
       "1    835  ...    321   414     375       N        W     632       43      10   \n",
       "2    457  ...    224   266     263       A        W     880       82      14   \n",
       "3   1575  ...    828   838     354       N        E     200       11       3   \n",
       "4    101  ...     48    46      33       N        E     805       40       4   \n",
       "\n",
       "   Salary  NewLeague  \n",
       "0     NaN          A  \n",
       "1   475.0          N  \n",
       "2   480.0          A  \n",
       "3   500.0          N  \n",
       "4    91.5          N  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from a CSV file into a DataFrame and display 5 rows\n",
    "df = pd.read_csv('Hitters.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yF8WlmiTs9x-"
   },
   "source": [
    "**Observation**\n",
    "\n",
    "- The above output shows the head of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRG1wZ_-1xGZ",
    "outputId": "d1acce9d-6d5b-48f3-cf36-4b6f84f7f1e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years',\n",
       "       'CAtBat', 'CHits', 'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'League',\n",
       "       'Division', 'PutOuts', 'Assists', 'Errors', 'Salary', 'NewLeague'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "09EdT9VW1xGZ"
   },
   "outputs": [],
   "source": [
    "# Remove \"Unnamed: 0\" from the dataframe\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdL3Uc9ws9x-",
    "outputId": "4fd0c7da-3953-4d27-bb2f-ce44435a3495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 322 entries, 0 to 321\n",
      "Data columns (total 20 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   AtBat      322 non-null    int64  \n",
      " 1   Hits       322 non-null    int64  \n",
      " 2   HmRun      322 non-null    int64  \n",
      " 3   Runs       322 non-null    int64  \n",
      " 4   RBI        322 non-null    int64  \n",
      " 5   Walks      322 non-null    int64  \n",
      " 6   Years      322 non-null    int64  \n",
      " 7   CAtBat     322 non-null    int64  \n",
      " 8   CHits      322 non-null    int64  \n",
      " 9   CHmRun     322 non-null    int64  \n",
      " 10  CRuns      322 non-null    int64  \n",
      " 11  CRBI       322 non-null    int64  \n",
      " 12  CWalks     322 non-null    int64  \n",
      " 13  League     322 non-null    object \n",
      " 14  Division   322 non-null    object \n",
      " 15  PutOuts    322 non-null    int64  \n",
      " 16  Assists    322 non-null    int64  \n",
      " 17  Errors     322 non-null    int64  \n",
      " 18  Salary     263 non-null    float64\n",
      " 19  NewLeague  322 non-null    object \n",
      "dtypes: float64(1), int64(16), object(3)\n",
      "memory usage: 50.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3U6UtdPTs9x_"
   },
   "source": [
    "**Observations**\n",
    "- Overall, it includes 322 observations and 21 columns.\n",
    "- As seen, the **Salary** field has null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zr4513vJ1xGZ",
    "outputId": "56412b97-20d0-4783-e5c8-507bca288274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'Salary': 59\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values in 'Salary':\", len(df[df['Salary'].isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDJSqrb21xGa"
   },
   "source": [
    "There are 59 rows out 322 observations with null values corresponding to column `Salary`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAw7Z8bg1xGa"
   },
   "source": [
    "Since we will use the lasso algorithm from scikit learn, we need to encode our categorical features as one-hot numeric features (dummy variables):\n",
    "\n",
    "**Note: Lasso regression assumes that the features are numeric and continuous, and does not work well with categorical variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhR4u4EM1xGa",
    "outputId": "805529f7-26aa-4b39-8b27-355d65d8a45c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 322 entries, 0 to 321\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   League_A     322 non-null    int64\n",
      " 1   League_N     322 non-null    int64\n",
      " 2   Division_E   322 non-null    int64\n",
      " 3   Division_W   322 non-null    int64\n",
      " 4   NewLeague_A  322 non-null    int64\n",
      " 5   NewLeague_N  322 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 15.2 KB\n"
     ]
    }
   ],
   "source": [
    "# creating dummies for all the variable of object type\n",
    "dummies = pd.get_dummies(df[['League', 'Division','NewLeague']])\n",
    "# Convert boolean True/False to integer 1/0\n",
    "dummies = dummies.astype(int)\n",
    "dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vNJUrIcT9mIp",
    "outputId": "9a1cbf54-87e8-4c52-b2a7-59d7c9a95714"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>League_A</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_E</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_A</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   League_A  League_N  Division_E  Division_W  NewLeague_A  NewLeague_N\n",
       "0         1         0           1           0            1            0\n",
       "1         0         1           0           1            0            1\n",
       "2         1         0           0           1            1            0\n",
       "3         0         1           1           0            0            1\n",
       "4         0         1           1           0            0            1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYSjY-u91xGa",
    "outputId": "61c7395c-04a7-4f36-fa63-bff7a524a296"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years', 'CAtBat',\n",
       "       'CHits', 'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'PutOuts', 'Assists',\n",
       "       'Errors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create label X and y\n",
    "y = df['Salary']\n",
    "\n",
    "# drop the column with the outcome variable (Salary), and categorical columns for which dummy variables is already created:\n",
    "X_numerical = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "\n",
    "#list of all numerical columns in X_numericals\n",
    "list_numerical = X_numerical.columns\n",
    "list_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByZ210xN1xGa"
   },
   "source": [
    "Concatenate the dummy variable dataframe and X_numerical to create X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1k5R-OGnsFx"
   },
   "source": [
    "Creating dummy variables for `League`, `Division`, and `NewLeague` allows us to convert categorical data into a numerical format suitable for machine learning models, while avoiding multicollinearity by dropping one category. This ensures that the models can interpret and leverage these categorical distinctions effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lAoXlXZorDH"
   },
   "source": [
    "**Data Description**\n",
    "* **League (A or N):** American League (A) or National League (N) as of the end of 1986.\n",
    "* **Division (E or W):** Eastern Division (E) or Western Division (W) as of the end of 1986.\n",
    "* **NewLeague (A or N):** American League (A) or National League (N) as of the beginning of 1987."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwwTik1MnUSA"
   },
   "source": [
    "`League_N`: 1 if the league is National League (N), 0 otherwise.\n",
    "\n",
    "`Division_W`: 1 if the division is Western Division (W), 0 otherwise.\n",
    "\n",
    "`NewLeague_N`: 1 if the new league is National League (N), 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAC_nzyX1xGa",
    "outputId": "dd333f1a-152b-4ede-de6d-a57d56073076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 322 entries, 0 to 321\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   AtBat        322 non-null    float64\n",
      " 1   Hits         322 non-null    float64\n",
      " 2   HmRun        322 non-null    float64\n",
      " 3   Runs         322 non-null    float64\n",
      " 4   RBI          322 non-null    float64\n",
      " 5   Walks        322 non-null    float64\n",
      " 6   Years        322 non-null    float64\n",
      " 7   CAtBat       322 non-null    float64\n",
      " 8   CHits        322 non-null    float64\n",
      " 9   CHmRun       322 non-null    float64\n",
      " 10  CRuns        322 non-null    float64\n",
      " 11  CRBI         322 non-null    float64\n",
      " 12  CWalks       322 non-null    float64\n",
      " 13  PutOuts      322 non-null    float64\n",
      " 14  Assists      322 non-null    float64\n",
      " 15  Errors       322 non-null    float64\n",
      " 16  League_N     322 non-null    int64  \n",
      " 17  Division_W   322 non-null    int64  \n",
      " 18  NewLeague_N  322 non-null    int64  \n",
      "dtypes: float64(16), int64(3)\n",
      "memory usage: 47.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Create X with dummy variables and numerical variables\n",
    "X = pd.concat([X_numerical, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "CJlyvYdQ1xGb"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets before handling missing values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW4S8b5Z3RCf"
   },
   "source": [
    "- Lasso performs best when all numerical features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n",
    "- This means it is important to standardize our features. We do this by subtracting the mean from our observations and then dividing the difference by the standard deviation\n",
    "\n",
    "- To avoid data leakage, the standardization of numerical features should always be performed after data splitting and only from training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wQaqoeF83ml"
   },
   "source": [
    "**Data leakage** occurs when information from outside the training dataset is used to create the model. This can happen if data that would not be available at the time of prediction is included in the training process. Data leakage can lead to optimistic performance estimates and models that fail to generalize well to new, unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB6ATM24QWdm"
   },
   "source": [
    "**Standard Scaler:**\n",
    "\n",
    "We use standardization to ensure that numerical features have a mean of 0 and a standard deviation of 1, which improves model performance, accelerates convergence, and ensures consistent feature impact in machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5LhBFEyPWhf"
   },
   "source": [
    "- **`StandardScaler()`**: Creates an instance of the StandardScaler.\n",
    "\n",
    "- **`.fit(X_train[list_numerical])`**: Computes the mean and standard deviation for each feature in the `X_train[list_numerical]` dataset. `X_train` is your training dataset, and list_numerical is a list of column names corresponding to the numerical features. This step calculates the parameters needed for scaling but does not yet apply the scaling.\n",
    "\n",
    "- **`scaler.transform(X_train[list_numerical])`**: Applies the standardization to the training data. This transforms each feature in the training dataset to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "- **`X_train[list_numerical]`**: The transformed numerical features are assigned back to the `X_train` DataFrame, effectively replacing the original values.\n",
    "\n",
    "- **`scaler.transform(X_test[list_numerical])`**: Applies the same standardization parameters (mean and standard deviation) computed from the training data to the test data. This ensures that the test data is scaled in the same way as the training data.\n",
    "\n",
    "- **`X_test[list_numerical]`**: The transformed numerical features are assigned back to the `X_test` DataFrame, replacing the original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "fhIAkBuB2hfV"
   },
   "outputs": [],
   "source": [
    "# Perform Standardization on numerical features.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train[list_numerical])\n",
    "X_train[list_numerical] = scaler.transform(X_train[list_numerical])\n",
    "X_test[list_numerical] = scaler.transform(X_test[list_numerical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYIWYiNiRDPL"
   },
   "source": [
    "Here we are fitting a StandardScaler to the numerical features in `X_train` to compute their mean and standard deviation, then using this scaler to standardize the same numerical columns in both `X_train` and `X_test`, ensuring they have a mean of 0 and a standard deviation of 1. After standardizing, we replace the original values in `X_train` and `X_test` with the new standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "RESuTWcL9Z-6",
    "outputId": "8e7878a2-b4ae-4b03-8e2a-45b18a69b1bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.397522</td>\n",
       "      <td>-0.564851</td>\n",
       "      <td>-0.670974</td>\n",
       "      <td>-1.052955</td>\n",
       "      <td>-0.393382</td>\n",
       "      <td>-1.060741</td>\n",
       "      <td>-0.684910</td>\n",
       "      <td>-0.924502</td>\n",
       "      <td>-0.910332</td>\n",
       "      <td>-0.729716</td>\n",
       "      <td>-0.936501</td>\n",
       "      <td>-0.847742</td>\n",
       "      <td>-0.856822</td>\n",
       "      <td>-0.210356</td>\n",
       "      <td>-0.654364</td>\n",
       "      <td>-0.777869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.780435</td>\n",
       "      <td>0.791703</td>\n",
       "      <td>-0.437296</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>-0.355490</td>\n",
       "      <td>-0.584603</td>\n",
       "      <td>0.768478</td>\n",
       "      <td>0.560523</td>\n",
       "      <td>0.571824</td>\n",
       "      <td>-0.332183</td>\n",
       "      <td>0.302385</td>\n",
       "      <td>0.145025</td>\n",
       "      <td>-0.052093</td>\n",
       "      <td>0.071044</td>\n",
       "      <td>1.831723</td>\n",
       "      <td>0.315685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1.291745</td>\n",
       "      <td>1.459214</td>\n",
       "      <td>-0.320458</td>\n",
       "      <td>1.509906</td>\n",
       "      <td>0.061319</td>\n",
       "      <td>0.891425</td>\n",
       "      <td>-0.684910</td>\n",
       "      <td>-0.763020</td>\n",
       "      <td>-0.718487</td>\n",
       "      <td>-0.577718</td>\n",
       "      <td>-0.653843</td>\n",
       "      <td>-0.733311</td>\n",
       "      <td>-0.664141</td>\n",
       "      <td>0.147789</td>\n",
       "      <td>-0.676829</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1.265856</td>\n",
       "      <td>1.136225</td>\n",
       "      <td>0.847928</td>\n",
       "      <td>2.131206</td>\n",
       "      <td>0.061319</td>\n",
       "      <td>1.272336</td>\n",
       "      <td>-1.100164</td>\n",
       "      <td>-0.695302</td>\n",
       "      <td>-0.692186</td>\n",
       "      <td>-0.378952</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>-0.708569</td>\n",
       "      <td>-0.581023</td>\n",
       "      <td>0.147789</td>\n",
       "      <td>-0.669341</td>\n",
       "      <td>-0.777869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.398569</td>\n",
       "      <td>0.081127</td>\n",
       "      <td>-1.021489</td>\n",
       "      <td>0.577957</td>\n",
       "      <td>-0.582840</td>\n",
       "      <td>1.558019</td>\n",
       "      <td>-1.100164</td>\n",
       "      <td>-0.928843</td>\n",
       "      <td>-0.918067</td>\n",
       "      <td>-0.776484</td>\n",
       "      <td>-0.849298</td>\n",
       "      <td>-0.891040</td>\n",
       "      <td>-0.694365</td>\n",
       "      <td>-0.031284</td>\n",
       "      <td>-0.714270</td>\n",
       "      <td>0.159463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AtBat      Hits     HmRun      Runs       RBI     Walks     Years  \\\n",
       "168 -0.397522 -0.564851 -0.670974 -1.052955 -0.393382 -1.060741 -0.684910   \n",
       "148  0.780435  0.791703 -0.437296  0.306138 -0.355490 -0.584603  0.768478   \n",
       "221  1.291745  1.459214 -0.320458  1.509906  0.061319  0.891425 -0.684910   \n",
       "227  1.265856  1.136225  0.847928  2.131206  0.061319  1.272336 -1.100164   \n",
       "139  0.398569  0.081127 -1.021489  0.577957 -0.582840  1.558019 -1.100164   \n",
       "\n",
       "       CAtBat     CHits    CHmRun     CRuns      CRBI    CWalks   PutOuts  \\\n",
       "168 -0.924502 -0.910332 -0.729716 -0.936501 -0.847742 -0.856822 -0.210356   \n",
       "148  0.560523  0.571824 -0.332183  0.302385  0.145025 -0.052093  0.071044   \n",
       "221 -0.763020 -0.718487 -0.577718 -0.653843 -0.733311 -0.664141  0.147789   \n",
       "227 -0.695302 -0.692186 -0.378952 -0.545591 -0.708569 -0.581023  0.147789   \n",
       "139 -0.928843 -0.918067 -0.776484 -0.849298 -0.891040 -0.694365 -0.031284   \n",
       "\n",
       "      Assists    Errors  League_N  Division_W  NewLeague_N  \n",
       "168 -0.654364 -0.777869         0           1            0  \n",
       "148  1.831723  0.315685         0           0            0  \n",
       "221 -0.676829  0.003241         1           0            1  \n",
       "227 -0.669341 -0.777869         0           1            0  \n",
       "139 -0.714270  0.159463         0           1            1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O28mlhQ11xGb"
   },
   "source": [
    "- Filling in the missing value by taking the median of elements in `y_train`.\n",
    "-  `y` is a series with values from the target variable `Salary`, and not a dataframe, hence directly computing the median.\n",
    "  \n",
    "\n",
    "According to standard machine learning practices, filling missing values in the test set with statistics (like median) calculated from the training set does not constitute Data leakage. This method ensures that no information from the test set influences the training process, thus maintaining the integrity of the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WW72SkZjs9x_"
   },
   "outputs": [],
   "source": [
    "# Imputing the values NA values in the series with the median\n",
    "median_salary = y_train.median(skipna=True)\n",
    "y_train = y_train.fillna(median_salary)\n",
    "y_test = y_test.fillna(median_salary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYMBa4pFs9x_"
   },
   "source": [
    "### Create a Lasso Model.\n",
    "\n",
    "First, we apply lasso regression on the training set with regularization parameter `alpha`=1\n",
    "\n",
    "`alpha = 1`: This value is commonly used as default and provides a good balance between maintaining model complexity and reducing overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8x8ejYE1xGb",
    "outputId": "20b6d605-533f-4d83-bad0-9790d022882a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso intercept: 552.1437963555315\n",
      "Lasso coefficients: [-310.80528552  264.55074813   24.16085059    0.           -0.\n",
      "   98.27501652  -71.92938903 -154.88026267  115.47642309    0.\n",
      "  274.32490369  222.99944567 -217.31294449   50.42773172   41.83950725\n",
      "  -22.76889619   23.87540404 -118.63107582   -0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the Lasso regression model to the training data\n",
    "lasso_model = Lasso(alpha=1, max_iter=10000).fit(X_train, y_train)\n",
    "print(\"Lasso intercept:\", lasso_model.intercept_)\n",
    "\n",
    "# Get the coefficients (weights) of the fitted Lasso regression model\n",
    "print(\"Lasso coefficients:\", lasso_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy9eb2Gc1xGc"
   },
   "source": [
    "**Observation**\n",
    "\n",
    "* Lasso Intercept: 552\n",
    "\n",
    "This is the intercept term of your Lasso regression model. It represents the expected mean value of the dependent variable when all independent variables are set to zero. In practical terms, it's the baseline prediction when no other information (from the variables) is provided.\n",
    "Lasso Coefficients:\n",
    "\n",
    "* Lasso coefficients: represent the relationship between each independent variable and the dependent variable.\n",
    "Each coefficient estimates the change in the dependent variable for a one unit change in the respective independent variable, holding all other variables constant.\n",
    "    - A positive coefficient indicates that as the independent variable increases, the dependent variable also increases.\n",
    "    - A negative coefficient indicates that as the independent variable increases, the dependent variable decreases.\n",
    "    - The magnitude of the coefficient shows the strength of the impact. A larger absolute value indicates a stronger effect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1028yMmc1xGc"
   },
   "source": [
    "\n",
    "* Lasso regression is known for its ability to perform feature selection by shrinking some coefficients to zero, thus effectively removing those variables from the equation.\n",
    "\n",
    "* In this model, however, it seems that none of the coefficients are exactly zero, suggesting that all included variables have some impact on the model, though some impacts are very small (e.g., coefficients close to zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxQKDYh2s9yA"
   },
   "source": [
    "- Test the lasso model and make predictions\n",
    "- Evaluate the RMSE and R2 scores for model performance.\n",
    "- Optimize the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V47ohMTQDKEP"
   },
   "source": [
    "**Model Evaluation on Lasso model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9Db3UuTB_AM",
    "outputId": "7fc047d7-c247-46cb-ba65-16c3c80c29b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training set 84531.03\n",
      "R squared training set 47.15\n",
      "---------------------------\n",
      "MSE test set 116175.54\n",
      "R squared test set 38.36\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "pred_train = lasso_model.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, pred_train)\n",
    "print('MSE training set', round(mse_train, 2))\n",
    "print('R squared training set', round(r2_score(y_train, pred_train)*100,2))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Test data\n",
    "pred_test = lasso_model.predict(X_test)\n",
    "mse_test =mean_squared_error(y_test, pred_test)\n",
    "print('MSE test set', round(mse_test, 2))\n",
    "print('R squared test set', round(r2_score(y_test, pred_test)*100,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpXwteBK1xGc"
   },
   "source": [
    "To better understand the role of `alpha`(regularization parameter), plot the lasso coefficients as a function of `alpha` (max_iter are the maximum number of iterations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "h0va9xvp1xGc",
    "outputId": "557d3a68-e532-4eb9-ecfb-e740fd88ee0b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = np.linspace(0.01,500,100)\n",
    "lasso = Lasso(max_iter=10000)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso coefficients as a function of alpha');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbJx08X11xGc"
   },
   "source": [
    "Moving from left to right in the plot, observe that at first the lasso models contains many predictors with high magnitudes of coefficient estimates. With increasing `alpha`, the coefficient estimates approximate towards zero.\n",
    "\n",
    "Next, we use cross-validation to find the best value for  `alpha`. Lasso regression comes with built-in cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "vTad7GQPs9yA"
   },
   "outputs": [],
   "source": [
    "# Create and fit the LassoCV model to the training data with cross-validation\n",
    "# Lasso with 10 fold cross-validation\n",
    "lasso_cv_model = LassoCV(alphas = np.random.randint(0, 1000, 100), cv =10, max_iter=10000, n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pdpdv83s9yA"
   },
   "source": [
    "Let's check the best alpha value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HQEk3aVs9yA",
    "outputId": "ac07a25f-bd51-4a81-a5c7-572d8a4f416f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best alpha (regularization strength) selected by cross-validation\n",
    "lasso_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CW5ZYd2gs9yB"
   },
   "source": [
    "Let's use the best alpha value, and see if you can tune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "uDUeMPmIs9yB"
   },
   "outputs": [],
   "source": [
    "# Create and fit the Lasso regression model using the best alpha found by cross-validation\n",
    "lasso_tuned = Lasso(alpha=lasso_cv_model.alpha_, max_iter=10000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JRWGCOrE2A-"
   },
   "source": [
    "**Model Evaluation on Lasso model with the best alpha**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDIm8s8pDsnm",
    "outputId": "1982bcbf-c119-444e-f4c2-10b800fe4940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training set post tuning 86559.92\n",
      "R squared training set post tuning 45.88\n",
      "---------------------------\n",
      "MSE test set post tuning 113899.49\n",
      "R squared test set post tuning 39.56\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "pred_train_tuned = lasso_tuned.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, pred_train_tuned)\n",
    "print('MSE training set post tuning', round(mse_train, 2))\n",
    "print('R squared training set post tuning', round(r2_score(y_train, pred_train_tuned)*100,2))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Test data\n",
    "pred_test_tuned = lasso_tuned.predict(X_test)\n",
    "mse_test =mean_squared_error(y_test, pred_test_tuned)\n",
    "print('MSE test set post tuning', round(mse_test, 2))\n",
    "print('R squared test set post tuning', round(r2_score(y_test, pred_test_tuned)*100,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvF3w-t4s9yB"
   },
   "source": [
    "Now, let's find the coefficient of the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZChGneRis9yB",
    "outputId": "3bb14a95-349c-439a-f0f9-f95b3146ff62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat         -239.109204\n",
       "Hits           224.372390\n",
       "HmRun           13.534463\n",
       "Runs             0.000000\n",
       "RBI              0.000000\n",
       "Walks           81.414283\n",
       "Years          -68.010940\n",
       "CAtBat          -0.000000\n",
       "CHits            7.563988\n",
       "CHmRun           0.000000\n",
       "CRuns          200.690747\n",
       "CRBI           199.298576\n",
       "CWalks        -170.114996\n",
       "PutOuts         47.958395\n",
       "Assists         24.190928\n",
       "Errors         -15.375836\n",
       "League_N        14.825837\n",
       "Division_W    -117.167767\n",
       "NewLeague_N      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas Series of the coefficients from the tuned Lasso regression model\n",
    "pd.Series(lasso_tuned.coef_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tj29zPks9yB"
   },
   "source": [
    "**Observations**\n",
    "- Zero Coefficients: Features like Runs, RBI, CAtBat, CHmRun, NewLeague_N, and several others have coefficients shrunk to zero. This indicates that Lasso has deemed these features less important or irrelevant for predicting the target variable in the presence of other features.\n",
    "\n",
    "- Non-Zero Coefficients: Features such as AtBat, Hits, Walks, CRuns, and CRBI have non-zero coefficients and are considered significant predictors in the model. The magnitude and sign of each coefficient indicate the strength and direction of the influence on the response variable:\n",
    "\n",
    "Positive Coefficients (e.g., Hits at 224.372390 and CRuns at 200.690747) suggest that an increase in these variables is associated with an increase in the target variable.\n",
    "\n",
    "Negative Coefficients (e.g., AtBat at -239.109204 and Years at -68.010940) suggest that an increase in these variables is associated with a decrease in the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03u3YnK3H_5I"
   },
   "source": [
    "### __3.8.2 Ridge Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TUgyjIXA6B6"
   },
   "source": [
    "**Ridge Regression** also known as L2 Regularization is a regularization technique used in linear regression to prevent overfitting. It is useful for handling multicollinear data, where two predictors/independent variables are highly correlated to each other.\n",
    "\n",
    "*Collinearity* refers to a situation where two or more predictor variables in a multiple regression model are highly correlated, meaning they have a linear relationship. This correlation makes it difficult to determine the individual effect of each predictor on the target variable, leading to unreliable and unstable estimates of regression coefficients.\n",
    "\n",
    "Ridge regression adds a regularization term to the loss function that penalizes large coefficients in the model and encourages the model to have smaller coefficients.\n",
    "It results in a simpler and more generalized model.\n",
    "\n",
    "Ridge Regression does shrink the coefficients, it does not force them to zero, meaning it does not perform feature selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhS4n-Df0GR4"
   },
   "source": [
    "Let's see how to implement Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZk4HeTy0Ktf"
   },
   "source": [
    "\n",
    "- First, import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "pSTb4I-30WW5"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vTcxaDR0cGp"
   },
   "source": [
    "- Starting the implementation using the train test data acquired from the Lasso implementation on **Hitters.csv** dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3tGn4Ue1128"
   },
   "source": [
    "- Let's fit the model and check what the intercept value is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOxpS1o_15Pp",
    "outputId": "afc6b35e-98ee-4e1e-a7b5-087ebbb63117"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552.2287554333541"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the Ridge regression model to the training data\n",
    "ridge_model = Ridge(alpha=1).fit(X_train, y_train)\n",
    "ridge_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8J7WrIH1_6z"
   },
   "source": [
    "__Observation:__\n",
    "- The intercept value for the Ridge model is 552."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83qDs4Gc2DjI"
   },
   "source": [
    "**Model evaluation on Ridge model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxP67EMiFdFs",
    "outputId": "433d3db1-169c-431c-b7c3-b18b88412ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training set 84369.79\n",
      "R squared training set 47.25\n",
      "---------------------------\n",
      "MSE test set 116730.89\n",
      "R squared test set 38.06\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "pred_train = ridge_model.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, pred_train)\n",
    "print('MSE training set', round(mse_train, 2))\n",
    "print('R squared training set', round(r2_score(y_train, pred_train)*100,2))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Test data\n",
    "pred_test = ridge_model.predict(X_test)\n",
    "mse_test =mean_squared_error(y_test, pred_test)\n",
    "print('MSE test set', round(mse_test, 2))\n",
    "print('R squared test set', round(r2_score(y_test, pred_test)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNevyi4-2MRO"
   },
   "source": [
    "Let's check the coefficient of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqQrinwY2PM6",
    "outputId": "d9ff5c47-5127-4a0e-c976-c0635bc136cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-299.44680072,  247.15463531,   26.09749437,    8.12950685,\n",
       "         -4.59947678,   98.24018695,  -73.56921813, -208.11549116,\n",
       "        220.72992894,   24.79168215,  231.91705884,  188.99248475,\n",
       "       -212.18547418,   51.11247316,   46.6903119 ,  -27.64614616,\n",
       "         43.01303452, -120.28167205,  -17.53721078])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the coefficients (weights) of the fitted Ridge regression model\n",
    "ridge_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qp1GJ451xGf"
   },
   "source": [
    "Next, we use cross-validation to find the best value for  `alpha`. Ridge regression just like lasso, comes with built-in cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVM1MZDN1xGg",
    "outputId": "b2e59f87-dd39-4e77-def7-de654d6ab9ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv_model = RidgeCV(alphas= np.random.randint(0, 1000, 100), cv=10).fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha (regularization strength) selected by cross-validation\n",
    "ridge_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "hO8QzbEHHngm"
   },
   "outputs": [],
   "source": [
    "# Create and fit the ridge regression model using the best alpha found by cross-validation\n",
    "ridge_tuned = Ridge(alpha=ridge_cv_model.alpha_, max_iter=10000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8w21SamIEQR"
   },
   "source": [
    "**Model evaluation on tuned Ridge model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFz03YA1Hush",
    "outputId": "c653127d-e54f-45b3-e03e-9f807d2d1866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training set 103038.59\n",
      "R squared training set 35.58\n",
      "---------------------------\n",
      "MSE test set 117485.78\n",
      "R squared test set 37.66\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "pred_train_tuned = ridge_tuned.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, pred_train_tuned)\n",
    "print('MSE training set', round(mse_train, 2))\n",
    "print('R squared training set', round(r2_score(y_train, pred_train_tuned)*100,2))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Test data\n",
    "pred_test_tuned = ridge_tuned.predict(X_test)\n",
    "mse_test =mean_squared_error(y_test, pred_test_tuned)\n",
    "print('MSE test set', round(mse_test, 2))\n",
    "print('R squared test set', round(r2_score(y_test, pred_test_tuned)*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOXnqJ3g1xGg",
    "outputId": "d613ddf9-119a-488e-924e-53245b796472"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat           4.588470\n",
       "Hits           26.832244\n",
       "HmRun           6.648931\n",
       "Runs           18.144108\n",
       "RBI            22.388322\n",
       "Walks          21.727614\n",
       "Years           4.460880\n",
       "CAtBat         21.645244\n",
       "CHits          32.591972\n",
       "CHmRun         28.376577\n",
       "CRuns          29.996470\n",
       "CRBI           34.840119\n",
       "CWalks          6.056188\n",
       "PutOuts        28.765362\n",
       "Assists         4.154674\n",
       "Errors         -6.322113\n",
       "League_N        8.835053\n",
       "Division_W    -30.822714\n",
       "NewLeague_N     4.325775\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas Series of the coefficients from the tuned Ridge regression model\n",
    "pd.Series(ridge_tuned.coef_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2poRl82vI7FR"
   },
   "source": [
    "**Observation**\n",
    "\n",
    "- The coefficients with the highest values suggest that cumulative career statistics like total runs batted in, total hits, and total runs scored historically have the most significant positive influence on the target variable.\n",
    "\n",
    "- Division_W: The only feature with a notably high negative coefficient is Division_W, which indicates that being in the Western division is associated with a negative effect on the target variable. This could reflect divisional performance differences or disparities in competitive levels.\n",
    "\n",
    "- Years, Assists, and NewLeague_N: These features have smaller positive coefficients, suggesting a modest but positive influence on the model’s predictions. This indicates that experience and being in a new league might have a slight positive impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuLh3jIcJoA0"
   },
   "source": [
    "This analysis helps in understanding the relative importance and influence of different aspects of a baseball player's statistics on the predicted target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzZVWOVwTT08"
   },
   "source": [
    "### __3.8.3 Elastic Net Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFd1ufbkTZqr"
   },
   "source": [
    "Elastic Net regression is a regularization technique that linearly combines the penalties of Lasso (L1) and Ridge (L2) methods. It is particularly useful when dealing with highly collinear data, where ordinary least squares might not perform well.\n",
    "\n",
    "*Ordinary Least Squares (OLS)* is a method for estimating the parameters in a linear regression model. OLS aims to find the line (or hyperplane in higher dimensions) that minimizes the sum of the squared differences (residuals) between the observed values and the values predicted by the linear model. While OLS works well under many circumstances, it can become problematic when predictor variables are highly collinear making the model unstable and less interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-r8iGEKTnDk"
   },
   "source": [
    "The Elastic Net method is defined as minimizing the following loss function:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = \\frac{1}{2n} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij})^2 + \\lambda_1 \\sum_{j=1}^{p} |\\beta_j| + \\lambda_2 \\sum_{j=1}^{p} \\beta_j^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwrcbjCKU9r6"
   },
   "source": [
    "\n",
    "\n",
    "Where:\n",
    "- $\\frac{1}{2n} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij})^2$ is the residual sum of squares.\n",
    "- $\\lambda_1 \\sum_{j=1}^{p} |\\beta_j|$ is the L1 penalty (Lasso).\n",
    "- $\\lambda_2 \\sum_{j=1}^{p} \\beta_j^2$ is the L2 penalty (Ridge).\n",
    "\n",
    "- $\\lambda_1$ and $\\lambda_2$ are regularization parameters that control the balance between fitting the model well to the data and keeping the model parameters small to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLjHWAWsVN-d"
   },
   "source": [
    "Let's see how to implement Elastic net regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueZizM9rVN-l"
   },
   "source": [
    "\n",
    "- First, import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Vfj5sfrvVvaq"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PIy0L88V8iy"
   },
   "source": [
    "- Starting the implementation using the train test data acquired from the Lasso implementation on **Hitters.csv** dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GWH12ZFV8iz"
   },
   "source": [
    "- Let's fit the model and check what the intercept value is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZI4Z4vu0WAJO",
    "outputId": "a3e865a0-3627-4e68-cce8-b20579e1bca2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518.1732769716566"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing and fitting the ElasticNet model\n",
    "elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5)  # alpha is the regularization parameter\n",
    "elastic_net.fit(X_train, y_train)\n",
    "elastic_net.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwDfSiDqXYFK"
   },
   "source": [
    "__Observation:__\n",
    "- The intercept value for the ElasticNet model is 518."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AqecmjxXYFS"
   },
   "source": [
    "- The following code calculates the root mean squared error (RMSE) of the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8roaE0hgXnCM",
    "outputId": "dd871491-c33c-451e-f583-46c2eed011c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error(RMSE):  339.827814119469\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set using the fitted Ridge regression model\n",
    "y_pred = elastic_net.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Root mean Squared Error(RMSE): \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdz0U8IWXnCS"
   },
   "source": [
    "__Observation:__\n",
    "- The MSE value is 115482.\n",
    "- Root mean Squared Error(RMSE):  339.827814119469"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucILltfMXnCT"
   },
   "source": [
    "Let's check the coefficient of the model and the R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Np7Qk0FUXnCT",
    "outputId": "0fc8ee73-8d3a-495a-b942-17961ebe9887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.32444269,  32.30474803,   2.9866463 ,  19.29717715,\n",
       "        24.37757748,  24.03646085,  -1.75094796,  21.18106091,\n",
       "        38.83116968,  31.91940944,  34.58738415,  41.51340678,\n",
       "        -1.10580746,  34.27606622,   5.57111951,  -9.40358356,\n",
       "        11.97939869, -44.3230192 ,   4.71404392])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the coefficients (weights) of the fitted Ridge regression model\n",
    "elastic_net.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW-HcbHgXnCT",
    "outputId": "57e5616d-b9e2-420f-d2db-1f44dbe26c73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38723248495497564"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvE6NoO3ZNer"
   },
   "source": [
    "__Observation:__\n",
    "- The r2 score is 0.38."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tm6EBc9h4fp"
   },
   "source": [
    "In Elastic Net regression,\n",
    "- `alpha` controls the overall strength of regularization, with higher values leading to more shrinkage of the coefficients to reduce overfitting.  It's better to use a log scale or more systematic approach to ensure that the alphas tested cover a suitable range, especially since very small or very large values might not be appropriate:\n",
    "\n",
    "- `l1_ratio` determines the mix of L1 (Lasso) and L2 (Ridge) regularization, ranging from 0 (pure Ridge) to 1 (pure Lasso). Intermediate values blend the two, leveraging Lasso's sparsity and Ridge's ability to handle multicollinearity. Ensure l1_ratio ranges from a small positive number to 1 (but not including 0 if you wish to avoid pure Ridge regression). This parameter is the mix ratio that controls the combination of L1 and L2 regularization\n",
    "\n",
    "Tuning these parameters allows Elastic Net to balance model performance and interpretability effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "fD4nPUTjMWzp"
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid for alpha and l1_ratio\n",
    "alphas = np.logspace(-2, 2, 100)\n",
    "\n",
    "# start from 0.01 to include L1 regularization\n",
    "l1_ratios = np.linspace(0.01, 1, 100)\n",
    "\n",
    "# Create and fit the Elastic Net CV model, using 10-fold cross-validation\n",
    "elastic_cv_model = ElasticNetCV(alphas=alphas, l1_ratio=l1_ratios, cv=10, max_iter=10000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i22M4jOf-6y",
    "outputId": "d84ddf27-b05b-4a3c-85d9-f697b6c7028a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.01747528400007684\n",
      "Best l1_ratio: 0.060000000000000005\n"
     ]
    }
   ],
   "source": [
    "best_alpha = elastic_cv_model.alpha_\n",
    "best_l1_ratio = elastic_cv_model.l1_ratio_\n",
    "# Print the best alpha and l1_ratio found\n",
    "print('Best alpha:', best_alpha)\n",
    "print('Best l1_ratio:', best_l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ldM3So2qg_KQ"
   },
   "outputs": [],
   "source": [
    "# Create and fit the Elastic Net regression model using the best alpha and l1_ratio found by cross-validation\n",
    "elastic_tuned = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the tuned Elastic Net regression model\n",
    "y_pred_tuned = elastic_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRzOTQPShFOr",
    "outputId": "a25059fd-55f0-4060-b275-31d640cb4db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 338.2351631943696\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the root mean squared error (RMSE) of the predictions\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_tuned))\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abrKl6pshR2q",
    "outputId": "978829b9-4f63-4758-80b5-c821ed4d91e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtBat         -227.585549\n",
      "Hits           178.391331\n",
      "HmRun            6.397823\n",
      "Runs            24.394902\n",
      "RBI             16.613592\n",
      "Walks           78.937465\n",
      "Years          -78.409075\n",
      "CAtBat         -62.728112\n",
      "CHits          158.845697\n",
      "CHmRun          42.906875\n",
      "CRuns          147.262779\n",
      "CRBI           134.439319\n",
      "CWalks        -168.253409\n",
      "PutOuts         50.994891\n",
      "Assists         38.654512\n",
      "Errors         -29.305492\n",
      "League_N        37.137138\n",
      "Division_W    -119.854355\n",
      "NewLeague_N    -11.958422\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas Series of the coefficients from the tuned Elastic Net regression model\n",
    "coefficients = pd.Series(elastic_tuned.coef_, index=X_train.columns)\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GFx61GihgCO",
    "outputId": "8905aab8-5dbe-49a8-b1d1-5247724a084b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set: 46.16\n",
      "R squared test set: 39.3\n"
     ]
    }
   ],
   "source": [
    "# Print R-squared scores for the training and test sets\n",
    "print('R squared training set:', round(elastic_tuned.score(X_train, y_train) * 100, 2))\n",
    "print('R squared test set:', round(elastic_tuned.score(X_test, y_test) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyZOMCY2Qc2x"
   },
   "source": [
    "\n",
    "## __3.9 Model Optimization__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "II-sO6PMp_Ag"
   },
   "source": [
    "### __3.9.1 Hyperparameter tuning__\n",
    "\n",
    "- Hyperparameter tuning is the process of finding the best settings for the parameters in a machine-learning model.\n",
    "- Hyperparameters are settings that are not learned during training but are set before the training process begins.\n",
    "- Hyperparameter tuning involves trying different combinations of hyperparameters and evaluating the model's performance using validation techniques.\n",
    "\n",
    "Some common techniques for Hyperparameter tuning are:\n",
    "\n",
    "1. **Grid Search**: It systematically works through multiple combinations of hyperparameters. It performs an exhaustive search on a specified parameter grid.\n",
    "\n",
    "\n",
    "  * **How it works:**\n",
    "    * Define a Parameter Grid: Specify a set of hyperparameters and their possible values.\n",
    "    * Combination Evaluation: The algorithm evaluates all possible combinations of these hyperparameters.\n",
    "    * Model Training: For each combination, the model is trained and evaluated using cross-validation.\n",
    "    * Optimal Parameters: The combination yielding the best performance (e.g., highest accuracy) is chosen as the optimal set.\n",
    "\n",
    "2. **Random Search:** It explores hyperparameter space by sampling a fixed number of parameter settings from the specified distributions.\n",
    "\n",
    "* **How it works:**\n",
    "  * Define Parameter Distributions: Specify distributions or ranges for the hyperparameters.\n",
    "  * Random Sampling: Randomly sample combinations of hyperparameters from these distributions.\n",
    "  * Model Training: For each sampled combination, the model is trained and evaluated using cross-validation.\n",
    "  * Optimal Parameters: The combination yielding the best performance is chosen as the optimal set.\n",
    "\n",
    "### Implementation of Gridsearch Cross validation technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86UAaDQ02Wpo",
    "outputId": "279f0252-ee6a-4b4f-c406-bf2584b11921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -238.285\n",
      "Config: {'alpha': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary classes from scikit-learn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a repeated K-fold cross-validator\n",
    "cv = RepeatedKFold(n_splits =10, n_repeats =3, random_state =1)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "grid = dict()\n",
    "grid['alpha'] = np.arange(0,1,0.1)\n",
    "# Create an instance of the Ridge regression model\n",
    "model = Ridge()\n",
    "# Create the GridSearchCV object\n",
    "search = GridSearchCV(model, grid, scoring = 'neg_mean_absolute_error',cv = cv, n_jobs= -1)\n",
    "# Fit the GridSearchCV object to the training data\n",
    "results = search.fit(X_train, y_train)\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RBzrRZs2lnx"
   },
   "source": [
    "__Observation:__\n",
    "\n",
    "- As you can see from the output, the Mean Absolute Error, and the configuration fusion alpha is **0.9**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4HQ3wAO2pQF"
   },
   "source": [
    "- Let's try this with alpha points and predict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t15x-HlZ1xGh",
    "outputId": "24dd0da9-4428-44a8-8149-c29b3f083c46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the value from the key value pair in the dictionary, results\n",
    "results.best_params_.get('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIlZePAk2uqN",
    "outputId": "3668b278-76fc-4288-a4bb-4a25cfd728ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341.87636396607627"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit the Ridge regression model to the training data with the optimal alpha\n",
    "ridge_model_after_gridcv = Ridge(alpha = results.best_params_.get('alpha')).fit(X_train, y_train)\n",
    "y_pred_after_gridcv = ridge_model_after_gridcv.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred_after_gridcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kpfJROH25BR",
    "outputId": "b05bc665-815b-45e2-f51e-e31fa2196192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37982244787022845"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the r2 score\n",
    "r2_score(y_test,y_pred_after_gridcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BT2VYAba2-Zl"
   },
   "source": [
    "__Observation:__\n",
    "- The r2 score is 0.38. It suggests a moderate fit. The model captures some of the variability in the data but not a large portion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJIgHdrb3B5k"
   },
   "source": [
    "- Let's check the coefficient of the ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbjpwKgd3GZp",
    "outputId": "bc3e97e9-77d7-4a23-fdca-e0c2e9f7bb53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat         -301.940590\n",
       "Hits           250.000657\n",
       "HmRun           27.368934\n",
       "Runs             7.101426\n",
       "RBI             -6.000930\n",
       "Walks           99.030120\n",
       "Years          -72.603088\n",
       "CAtBat        -221.067417\n",
       "CHits          225.900021\n",
       "CHmRun          22.855480\n",
       "CRuns          237.607797\n",
       "CRBI           193.577140\n",
       "CWalks        -213.804271\n",
       "PutOuts         51.080832\n",
       "Assists         47.120753\n",
       "Errors         -27.541072\n",
       "League_N        43.413579\n",
       "Division_W    -120.095472\n",
       "NewLeague_N    -17.822759\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas Series of the coefficients from the fitted Ridge regression model\n",
    "pd.Series(ridge_model_after_gridcv.coef_, index = X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuGWJq-H3xRH"
   },
   "source": [
    "__Observation:__\n",
    "\n",
    "- Penalization has occurred, as you can see in the negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q788pGwAJCPp"
   },
   "source": [
    "### __Sklearn Pipelines__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u8IENfkJCPp"
   },
   "source": [
    "#### __Why sklearn pipelines?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXsPrWcaJCPp"
   },
   "source": [
    "**Pipelines provide an organized approach to managing your data preprocessing and modeling code. They combine preprocessing and modeling steps into a single, streamlined process.**\n",
    "\n",
    " - **Cleaner Code**: Pipelines eliminate the need to manually manage training and validation data at each preprocessing step, reducing clutter and complexity.\n",
    "\n",
    " - **Fewer Bugs**: By bundling steps together, pipelines minimize the risk of misapplying or forgetting a preprocessing step.\n",
    "\n",
    " - **Easier to Productionize**: Pipelines simplify the transition from a prototype model to a scalable, deployable solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddQRwBIUJCPp"
   },
   "source": [
    "**Syntax**:\n",
    "```python\n",
    "class sklearn.pipeline.Pipeline(steps, *, memory=None, verbose=False)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu7-ItBuJCPp"
   },
   "source": [
    "**Before we start the application, let's pay attention to the following important points**:\n",
    "\n",
    " - A pipeline is a sequence of data transformers that can include a final predictor.\n",
    "\n",
    " - It lets you apply multiple preprocessing steps to your data in order, and optionally end with a predictor for modeling.\n",
    "\n",
    " - Each intermediate step in the pipeline must have fit and transform methods, while the final step only needs fit.\n",
    "\n",
    " - You can cache these transformers using the memory argument.\n",
    "\n",
    " - The pipeline's main goal is to combine multiple steps that can be cross-validated together and have their parameters adjusted.\n",
    "\n",
    " - You can set parameters for any step by using its name followed by a double underscore(__) and the parameter name.\n",
    "\n",
    " - You can replace any step's estimator with another estimator or remove a transformer by setting it to 'passthrough' or None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PN4_6toJCPp"
   },
   "source": [
    "#### Lets look at the housing data with `Ocean proximity` feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "uHc7WIJsJCPp"
   },
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv(\"housing_with_ocean_proximity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "dY929xeLJCPp",
    "outputId": "7f8eda64-4444-4f40-ae4e-9763a1f0aff8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "aFxYo8Pw5JrC"
   },
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "# Assuming 'median_house_value' is the target variable in your dataset\n",
    "X = housing_data.drop('median_house_value', axis=1)\n",
    "y = housing_data['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "i0H6lIExJCPp"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "PmeWXusI5JrC",
    "outputId": "c5a47564-f778-4cec-bf5b-e7ed72820fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14448 entries, 4722 to 7816\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           14448 non-null  float64\n",
      " 1   latitude            14448 non-null  float64\n",
      " 2   housing_median_age  14448 non-null  float64\n",
      " 3   total_rooms         14448 non-null  float64\n",
      " 4   total_bedrooms      14286 non-null  float64\n",
      " 5   population          14448 non-null  float64\n",
      " 6   households          14448 non-null  float64\n",
      " 7   median_income       14448 non-null  float64\n",
      " 8   ocean_proximity     14448 non-null  object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "longitude               0\n",
      "latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        162\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "ocean_proximity         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print info to check the structure of the training data\n",
    "print(X_train.info())\n",
    "print(X_train.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKqV5G9sJCPp"
   },
   "source": [
    "#### Implementation for sklearn pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tuxhnoYJCPp"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_03/Sklearn_pipeline_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_nY3QOuJCPp"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_03/Sklearn_pipeline_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdtR51LVJCPp"
   },
   "source": [
    "#### We need to perform following preprocessing steps before building the model\n",
    "\n",
    "1. Missing value treatment - 162 missing values in total_bedrooms(a numeric column)\n",
    "2. Dummy variable creation for categorical data\n",
    "3. Standardization of numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "6XnT3bUdJCPq"
   },
   "outputs": [],
   "source": [
    "# import StandardScaler for standardization and OneHotEncoder for creating dummy variables\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# import SimpleImputer for missing value treatment\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# importing pipeline class. The Pipeline class is used to create a sequence of data processing steps.\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# importing ColumnTransformer class to apply different preprocessing steps to different subsets of features in your dataset.\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjXlZ3znJCPq"
   },
   "source": [
    "**A note about ColumnTransformer**\n",
    "\n",
    "* ColumnTransformer class allows you to apply different preprocessing steps to different subsets of features in your dataset.\n",
    "* This is particularly useful when you have a mix of numerical and categorical data that require different types of preprocessing.\n",
    "* ColumnTransformer ensures that each column or group of columns gets the appropriate transformation before combining the results for further processing or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLpxNEFaJCPq"
   },
   "source": [
    "### __Data preprocessing starts here:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBrCwrleJCPq"
   },
   "source": [
    "#### Steps to perform:\n",
    "    \n",
    "#### Step 1: Let's store the names of numeric and object type variables separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "e6jD0wYsJCPq"
   },
   "outputs": [],
   "source": [
    "# Set up preprocessing steps for numeric and categorical data\n",
    "housing_cat = X_train.select_dtypes(include='object').columns\n",
    "housing_num = X_train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkgemfJ-JCPq"
   },
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyDCfq3lJCPq"
   },
   "source": [
    "#### Step 2: Set-up sklearn pipeline for numeric variables. We need to perform missing value imputation and then standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "KudVlvB3JCPq"
   },
   "outputs": [],
   "source": [
    "# Numeric variables pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Bj7McC2JCPq"
   },
   "source": [
    "The num_pipeline is a pipeline that preprocesses numerical data in two steps:\n",
    "\n",
    "- Imputation: Fills missing values using the median value of each column (SimpleImputer(strategy='median')).\n",
    " - Standardization: Scales the data to have a mean of 0 and a standard deviation of 1 (StandardScaler()).\n",
    "\n",
    "This pipeline ensures consistent and streamlined preprocessing of numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-ch2NFiJCPq"
   },
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TuFRTCkJCPq"
   },
   "source": [
    "#### Step 3: Unified Data Preprocessing with Pipelines and ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "aQR14gk_JCPq"
   },
   "outputs": [],
   "source": [
    "# Unified preprocessing for both numeric and categorical data\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('num', num_pipeline, housing_num),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), housing_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-A3phf1JCPq"
   },
   "source": [
    "The preprocessing step uses ColumnTransformer to apply different preprocessing pipelines to different types of data in the dataset:\n",
    "\n",
    " - Numerical Data: Applies num_pipeline to columns in housing_num, performing imputation and standardization.\n",
    " - Categorical Data: Applies OneHotEncoder to columns in housing_cat, converting categorical variables into a one-hot encoded format, ignoring unknown categories.\n",
    "\n",
    "This ensures that both numerical and categorical data are preprocessed appropriately within a single, unified framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaI1Qty4JCPq"
   },
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQ0EBrXVJCPq"
   },
   "source": [
    "#### Let's check how the pipeline we have created works with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "rX9c4geYJCPq"
   },
   "outputs": [],
   "source": [
    "# applying preprocessing pipeline to train data\n",
    "check_train = preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "9t80hzsdJCPq",
    "outputId": "9eca293f-8b46-4968-b031-3b7ce1d59733"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.604388</td>\n",
       "      <td>-0.741523</td>\n",
       "      <td>1.536729</td>\n",
       "      <td>-0.620001</td>\n",
       "      <td>-0.716387</td>\n",
       "      <td>-0.790880</td>\n",
       "      <td>-0.721514</td>\n",
       "      <td>0.072853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798753</td>\n",
       "      <td>-0.862998</td>\n",
       "      <td>0.501005</td>\n",
       "      <td>-0.119890</td>\n",
       "      <td>-0.131442</td>\n",
       "      <td>0.218924</td>\n",
       "      <td>-0.043175</td>\n",
       "      <td>0.129574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.845868</td>\n",
       "      <td>1.445014</td>\n",
       "      <td>-1.809456</td>\n",
       "      <td>0.736722</td>\n",
       "      <td>0.333637</td>\n",
       "      <td>0.298266</td>\n",
       "      <td>0.353837</td>\n",
       "      <td>0.825943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.604388 -0.741523  1.536729 -0.620001 -0.716387 -0.790880 -0.721514   \n",
       "1  0.798753 -0.862998  0.501005 -0.119890 -0.131442  0.218924 -0.043175   \n",
       "2 -0.845868  1.445014 -1.809456  0.736722  0.333637  0.298266  0.353837   \n",
       "\n",
       "         7    8    9    10   11   12  \n",
       "0  0.072853  1.0  0.0  0.0  0.0  0.0  \n",
       "1  0.129574  1.0  0.0  0.0  0.0  0.0  \n",
       "2  0.825943  0.0  1.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting array to dataframe to have a better look at it\n",
    "check_train_df = pd.DataFrame(check_train)\n",
    "check_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "FCQZ6iNgJCPq",
    "outputId": "f5d2ea66-b060-4fb9-e684-c9aaf70f836e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkLLRW9-JCPq"
   },
   "source": [
    "#### __Observation:__\n",
    "\n",
    "1. Good to see all the missing values are treated\n",
    "2. numeric variables are standardised\n",
    "3. ocean_proximity is converted to dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_03hcT-RJCPr"
   },
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "156uciNUJCPr"
   },
   "source": [
    "#### Step 4: Building Linear regression model and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "XD6Lk-FQJCPr"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "eDKVzBGqJCPr"
   },
   "outputs": [],
   "source": [
    "# Create an instance of the Ridge regression model\n",
    "model = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Lk6a6jk1JCPr"
   },
   "outputs": [],
   "source": [
    "# Build a Ridge regression model within a complete pipeline\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('model_ridge', model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "rhILfy3zJCPr"
   },
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters to search\n",
    "\n",
    "# Note: You can set parameters for any step by using its name followed by a double underscore(__) and the parameter name.\n",
    "\n",
    "grid = dict()\n",
    "\n",
    "grid['model_ridge__alpha'] = np.arange(0.1,2.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "1MgpLeo3JCPr",
    "outputId": "3e9fb7b8-6fcb-4620-8ad8-e81ebdc39481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 49789.360\n",
      "Config: {'model_ridge__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "search = GridSearchCV(estimator = final_pipeline, param_grid = grid, scoring = 'neg_mean_absolute_error',cv = 5, n_jobs= -1)\n",
    "# Fit the GridSearchCV object to the training data\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "results = search.fit(X_train, y_train)\n",
    "print('MAE: %.3f' % -results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKlEIgQbJCPr"
   },
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lZXB7qZJCPr"
   },
   "source": [
    "#### Step 5: Using pipeline object to test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "PgGxvzFf5JrF",
    "outputId": "19a43b36-0267-4f6b-ec99-2b1f50e33880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 50091.26322372467\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set using the trained model\n",
    "y_pred = search.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idA1M_uVJCPr"
   },
   "source": [
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_03/sklearn_pipeline_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6f_0-kNH1yM"
   },
   "source": [
    "### __Conclusion__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvo7LQPeInrT"
   },
   "source": [
    "Regression analysis is an essential method for examining and predicting variable relationships. In this lesson, we've delved into core types of regression—simple linear, multiple linear, and polynomial regression.\n",
    "\n",
    "You've acquired skills to assess model performance using metrics like MSE, RMSE, and R-squared. Furthermore, we explored regularization techniques such as Lasso, Ridge, and ElasticNet to mitigate overfitting, and learned the importance of hyperparameter tuning for optimizing model parameters to enhance results.\n",
    "\n",
    "In conclusion, this lesson has provided a comprehensive exploration of regression through theoretical insights and hands-on applications."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
