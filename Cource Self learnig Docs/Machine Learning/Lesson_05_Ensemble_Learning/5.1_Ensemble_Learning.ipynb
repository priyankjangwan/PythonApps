{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHIG1d9_l34n"
   },
   "source": [
    "# __Ensemble Learning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Frqpzxjtl34r"
   },
   "source": [
    "## __Agenda__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuAtQRq_jrIR"
   },
   "source": [
    "- Introduction to ensemble learning\n",
    "    * Goals of ensemble learning\n",
    "    * Importance of ensemble learning\n",
    "    * Weak and Strong learners in Ensemble learning\n",
    "- Categories in ensemble learning\n",
    "    * Sequential ensemble technique\n",
    "    * Parallel ensemble technique\n",
    "- Simple techniques used in ensemble learning\n",
    "    * Voting\n",
    "        * Hard Voting\n",
    "        * Soft Voting\n",
    "    * Averaging\n",
    "    * Weighted Averaging\n",
    "- Advanced techniques used in ensemble learning\n",
    "    * Bagging (bootstrap aggregating)\n",
    "        * Bagging Techniques\n",
    "        * Advantages of bagging\n",
    "        * Disadvantages of bagging\n",
    "        * Out-of-bag (OOB) concept\n",
    "    * Boosting\n",
    "        * Boosting Techniques\n",
    "        * Advantages of boosting\n",
    "        * Disadvantages of boosting\n",
    "    * Stacking\n",
    "        * Advantages of stacking\n",
    "        * Disadvantages of stacking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATRhnmJrl34t"
   },
   "source": [
    "## __1. Introduction to Ensemble Learning__\n",
    "\n",
    "Ensemble learning combines multiple models to enhance the overall performance of machine learning algorithms. The fundamental principle of ensemble learning is combining predictions from multiple individual models to produce a more accurate and robust prediction than any single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4O1F-Znl34u"
   },
   "source": [
    "### __1.1 Goals of Ensemble Learning__\n",
    "\n",
    "- Enhance predictive accuracy by combining multiple models.\n",
    "- Improve model robustness and generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd6HSXdsl34u"
   },
   "source": [
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_07/ensemble_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHxacRO_l34v"
   },
   "source": [
    "__Example:__ Imagine you are deciding whether to go outside based on weather predictions. Instead of relying on just one weather forecast, you check multiple sources, like the weather app, a meteorologist's report, and a weather website. You then combine these predictions to make your decision.\n",
    "\n",
    "This process mirrors ensemble learning, where combining multiple models (or weather forecasts) results in a more accurate prediction (or decision) than any single model could offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHrOIMF5l34v"
   },
   "source": [
    " ### __1.2 Importance of Ensemble Learning__\n",
    "\n",
    "- Improves prediction accuracy by combining diverse models\n",
    "- Enhances model resilience and robustness against uncertainties\n",
    "- Mitigates biases and errors present in individual models\n",
    "- Captures a wide range of perspectives to achieve better performance\n",
    "- Provides reliable and robust forecasts across various domains, ensuring more dependable outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCHMABXNUmhm"
   },
   "source": [
    " ### __1.3 Weak and Strong learners in Ensemble Learning__\n",
    "- A **Weak learner** (WL) or **Base learner** is a learning algorithm\n",
    "capable of producing classifiers with probability of error strictly (but only slightly) less than that of random guessing (0.5, in the case of binary)\n",
    "\n",
    "- On the other hand, **Strong learner** (SL) is able (given enough training data) to yield classifiers with arbitrarily small error probability. It performs much better than random guessing.\n",
    "  \n",
    "An ensemble (or committee) of classifiers is a classifier build upon some\n",
    "combination of Weak learner. The strategy of boosting, and ensembles of classifiers, is to learn many weak classifiers and combine them, instead of trying to learn a single Strong learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GB1krYkml34w"
   },
   "source": [
    "## __2. Categories in Ensemble Learning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o09_VTdHl34w"
   },
   "source": [
    "Ensemble learning can be broadly classified into two categories:\n",
    "- Sequential ensemble technique\n",
    "- Parallel ensemble technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfV7RXRxl34x"
   },
   "source": [
    "### __2.1 Sequential Ensemble Technique__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCg-QnGCl34x"
   },
   "source": [
    "These techniques train models sequentially, with each model attempting to correct its predecessor's errors. This technique focuses on improving the overall performance of the ensemble by iteratively refining predictions. An example of this approach is boosting.\n",
    "\n",
    "__Note:__ It typically employs weak learners as base estimators because these learners initially have higher error rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNqTZ94Il34x"
   },
   "source": [
    "The steps involved in the sequential ensemble technique depend on the data structure and the requirements of the application. They are:\n",
    "1. __Base Model Selection__: Choose the initial model.\n",
    "2. __Sequential Training__: Train models one after the other.\n",
    "3. __Error Correction__: Each model learns from previous mistakes.\n",
    "4. __Prediction Refinement__: Iteratively refine predictions.\n",
    "5. __Combining Predictions__: Combine predictions from all models.\n",
    "6. __Evaluation__: Assess ensemble performance using metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJBhi5bil34x"
   },
   "source": [
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_07/Sequential_Ensemble_Technique.png)\n",
    "\n",
    "__Note:__ If all four base models are of the same type, it is considered to be a homogeneous ensemble. If they are different, it is considered heterogeneous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoJpKDGbl34y"
   },
   "source": [
    "The diagram above shows the training data divided into four samples, with each sample trained on a distinct base model. Insights gained from model M1 are passed to model M2 alongside sample S2. M2 then adjusts its weights and biases based on the outcomes of M1. This process repeats for models 2, 3, and 4. Finally, all the learners are combined using a weighted averaging strategy.\n",
    "\n",
    "The summation sign ($ ∑ $) indicates the function that adjusts the model to improve its overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8EehvwSl34y"
   },
   "source": [
    "__The sequential ensemble technique is employed when dealing with:__\n",
    "- Complex relationships between input features and the target variable\n",
    "- Diverse data types, including numerical, categorical, and textual data\n",
    "- Imbalanced datasets, where skewed class distributions pose classification challenges.\n",
    "- Incremental updates are needed to adapt models gradually to evolving data over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tea0RTkEl34y"
   },
   "source": [
    "### __2.2 Parallel Ensemble Technique__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bphih-2El34z"
   },
   "source": [
    "The parallel ensemble technique concurrently trains models. They combine the predictions from multiple models to improve the final output. Bagging and Random Forest algorithms are examples of parallel ensemble techniques.\n",
    "\n",
    "__Note:__  It employs stronger learners as base estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhDXNIQ4l34z"
   },
   "source": [
    "The steps involved in the parallel ensemble technique are:\n",
    "\n",
    "1. __Data Partitioning__: Divide the dataset into subsets\n",
    "2. __Model Training__: Train models concurrently on subsets\n",
    "3. __Prediction__: Models make independent predictions\n",
    "4. __Combining Predictions__: Aggregate predictions using techniques like voting or averaging\n",
    "5. __Evaluation__: Assess ensemble performance using metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdT_g1-5l34z"
   },
   "source": [
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_07/Parallel_Ensemble_Technique.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9AikuvHl34z"
   },
   "source": [
    "In the above diagram, the training data is divided into four samples, labeled S1 to S4, each trained on a distinct base model (M1 to M4). Unlike the sequential ensemble technique, the data in the base learners is independent. This independence of base learners significantly reduces the error due to the application of averages.\n",
    "\n",
    "The summation sign ($ ∑ $) indicates the aggregated model with improved performance, which has been learned from all independent base models, M1 to M4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiCFb0nJl34z"
   },
   "source": [
    "The parallel ensemble technique is used to:\n",
    "\n",
    "- Enhance scalability, allowing for the efficient processing of large volumes of data by distributing the workload\n",
    "-  Expedite training and prediction processes through parallel computation on multi-core systems.\n",
    "- Reduce susceptibility to noise and overfitting by averaging out individual model errors.\n",
    "- Capture diverse data patterns effectively by utilizing different models trained on varied data subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOekR2Bjl340"
   },
   "source": [
    "## __3. Simple Techniques used in Ensemble Learning__\n",
    "\n",
    "* Voting\n",
    "* Averaging\n",
    "* Weighted Averaging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozZMP5gkuTmE"
   },
   "source": [
    "## __3.1 Voting__\n",
    "\n",
    "Voting is one of the fundamental methods of ensemble learning. It involves aggregating the predictions from multiple models to arrive at a final prediction.\n",
    "Two common types of voting in ensemble learning are:\n",
    "* Majority voting/Hard voting\n",
    "* Weighted voting/Soft voting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrCsQihDl340"
   },
   "source": [
    "### __3.1.1 Majority Voting/Hard Voting__\n",
    "\n",
    "Majority Voting or Hard Voting is an ensemble learning classification technique. It involves multiple models, making predictions for each data point. Each model's prediction is considered a __vote__. The final prediction is determined by the majority vote among the models.\n",
    "\n",
    "__Example:__\n",
    "    \n",
    "- Majority Voting ensemble works on breast cancer classification by combining predictions from multiple individual classifiers, such as Logistic Regression, Decision Tree, and Support Vector Machine.\n",
    "- Each classifier provides its prediction for whether a given sample belongs to a certain class. The voting ensemble then aggregates these predictions using a voting mechanism.\n",
    "- The final prediction is determined based on the most commonly predicted class among all classifiers.\n",
    "- This approach leverages the collective wisdom of diverse models to improve overall prediction accuracy and robustness in breast cancer classification tasks.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_fZz1N0c4_P"
   },
   "source": [
    "Let's look at an implementation of majority voting using a breast cancer classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1720088164217,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "KJeXngLpl340"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zxSDrklgl342"
   },
   "outputs": [],
   "source": [
    "# Load the dataset from the specified URL and assign column names to the DataFrame\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mU2veRIVl343"
   },
   "outputs": [],
   "source": [
    "# Drop the 'Sample code' column as it's not required for prediction\n",
    "data.drop(['Sample code'], axis=1, inplace=True)\n",
    "\n",
    "# Replace '?' with nan to handle missing data, ensuring numerical analysis accuracy and preventing calculation errors.\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lzDD5TVz6nJ2"
   },
   "outputs": [],
   "source": [
    "# Convert the 'Bare Nuclei' column to an integer type to ensure a uniform data type across the column,\n",
    "# which is essential for consistent data manipulation and analysis.\n",
    "data['Bare Nuclei'] = pd.to_numeric(data['Bare Nuclei']).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1719998427977,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "uA5ULfR568qT",
    "outputId": "34fe6237-67a6-43be-fad6-d90021e75c67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "3                6                        8                         8   \n",
       "4                4                        1                         1   \n",
       "\n",
       "   Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "0                  1                            2            1   \n",
       "1                  5                            7           10   \n",
       "2                  1                            2            2   \n",
       "3                  1                            3            4   \n",
       "4                  3                            2            1   \n",
       "\n",
       "   Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0                3                1        1      2  \n",
       "1                3                2        1      2  \n",
       "2                3                1        1      2  \n",
       "3                3                7        1      2  \n",
       "4                3                1        1      2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4X5x9MlCASCC"
   },
   "outputs": [],
   "source": [
    "# Replace class values to be binary (2 for benign, 4 for malignant)\n",
    "data['Class'] = data['Class'].replace({2: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1719998445871,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "MWmtE5lAl343",
    "outputId": "0d4142c3-d4f0-4900-e857-5cced306539e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   Clump Thickness              699 non-null    int64\n",
      " 1   Uniformity of Cell Size      699 non-null    int64\n",
      " 2   Uniformity of Cell Shape     699 non-null    int64\n",
      " 3   Marginal Adhesion            699 non-null    int64\n",
      " 4   Single Epithelial Cell Size  699 non-null    int64\n",
      " 5   Bare Nuclei                  699 non-null    int64\n",
      " 6   Bland Chromatin              699 non-null    int64\n",
      " 7   Normal Nucleoli              699 non-null    int64\n",
      " 8   Mitoses                      699 non-null    int64\n",
      " 9   Class                        699 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 54.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Display information about the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AA6-poUv9bvs"
   },
   "outputs": [],
   "source": [
    "# Extract features (X) and target variable (y)\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]   # Last column as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bbOtJgWnSeR-"
   },
   "outputs": [],
   "source": [
    "# Perform a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wTbCHRumS-P9"
   },
   "outputs": [],
   "source": [
    "# Create an instance of SimpleImputer to fill in missing values with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3UKVcSVlTG4w"
   },
   "outputs": [],
   "source": [
    "# Create an instance of MinMaxScaler to scale features to a range of (0, 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Initialize list for base models\n",
    "estimators = [\n",
    "    ('logistic', LogisticRegression()),\n",
    "    ('cart', DecisionTreeClassifier()),\n",
    "    ('svm', SVC())\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1719998814099,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "QtqBWv8tTJp2",
    "outputId": "fe148643-2f68-4e06-b508-39facca3fc45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy of the ensemble model: 0.96\n",
      "Test accuracy of the ensemble model: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Create Voting Classifier ensemble with estimators\n",
    "ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
    "\n",
    "# Set up KFold cross-validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "\n",
    "# Evaluate ensemble model using cross-validation\n",
    "results = cross_val_score(ensemble, X_train_scaled, y_train, cv=kfold)\n",
    "\n",
    "# Print mean accuracy score of the ensemble model\n",
    "print(f\"Mean cross-validation accuracy of the ensemble model: {results.mean():.2f}\")\n",
    "\n",
    "# Fit the ensemble on the scaled training set and evaluate on the scaled test set\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "test_accuracy = ensemble.score(X_test_scaled, y_test)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy of the ensemble model: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ06Ormxl345"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "The majority voting ensemble's 96% accuracy rate demonstrates its remarkable effectiveness in predicting breast cancer classifications. By combining predictions from multiple individual classifiers, this ensemble leverages the collective insights of diverse models to achieve highly accurate results.\n",
    "\n",
    "Let us explore other performance evaluation metrics as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1720001182647,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "X-zHWomY9FlA",
    "outputId": "a02be097-df0b-41ab-ddd8-6cb76b93d35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Classification report--------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        91\n",
      "           1       0.94      0.96      0.95        49\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.96      0.96      0.96       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "-------Confusion matrix-------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEGCAYAAADGwUaDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAAd9UlEQVR4nO3debRdZZnn8e+PBEgYwpSYFYMYhhQBowSIQaSlwiCTtAGlGdTqqGik7FKR0hK7XYxWgVW2ERpYRQQltMwITRRkqBRZigZIQgJJCIiGKWEIFxOGMEny9B/7veZwuPfcfZJz9tl35/dZ66yzx3c/556bJ+99997PVkRgZmbF2KTTAZiZbUycdM3MCuSka2ZWICddM7MCOemamRVoYKcD6K+GDh0Uo0Zt3ekwrAnznul0BNaUVa8Qr72hDWniiCPeF11db+Tadt68rjsi4ogNOV4eTrrradSorZk791OdDsOaMODsTkdgzVh76U0b3EZX1xvMyfnvdBNNG7rBB8zBSdfMKq1styI46ZpZpZUs5zrpmll1Be7pmpkVaq2TrplZcUqWc510zazCwsMLZmaFCdzTNTMrlHu6ZmYFKlnOddI1s2rz1QtmZgXxdbpmZgUrWc510jWzanNP18ysQCXLuU66ZlZdEeU7keYnR5hZpUXke+Uh6ZuSFktaJOkaSYMk7SzpPkl/lHSdpM0ateGka2aV1qqkK2kk8HVgfESMBQYAJwI/AKZGxG7ASuDkRu046ZpZpUXOV04DgcGSBgJbAM8CBwM3pvXTgWMaNeCka2aV1X2dbit6uhGxHPgh8BRZsn0JmAesioi302bLgJGN2nHSNbNKa6KnO1TS3JrXlNp2JG0HTAJ2Bt4LbAk0/SBLX71gZpXWxNULXRExvsH6Q4HHI+IFAEk3AQcA20oamHq7OwLLGx3EPV0zq7QWjuk+BXxE0haSBBwCPAzcDRyXtpkM3NKoESddM6usvOO5Ocd07yM7YfYAsJAsf04DvgOcJumPwA7A5Y3a8fCCmVVaK++NiIgzgTPrFi8FJuRtw0nXzCrNtRfMzApUspzrpGtm1RWUr/aCk66ZVZqHF8zMClSynOuka2YV1kQFsaI46ZpZpZUs5zrpmll1+USamVnBPLxgZlagkuVcJ10zqzb3dM3MCtLkUyEK4aRrZpXmnq6ZWVFK+Ah2J10zq7SS5VwnXTOrru4HU5aJk66ZVVrJcq4f12Nm1daqx/VI2l3SgprXy5JOlbS9pLskPZbet2vUjpOumVVaqx5MGRGPRsS4iBgH7Au8BtwMnA7MjIjRwMw03ysnXTOrrADWrs33atIhwJ8i4klgEjA9LZ8OHNNoR4/pmlmlNTGmO1TS3Jr5aRExrZdtTwSuSdPDI+LZNP0cMLzRQZx0zay6mqun2xUR4/vaSNJmwCeB777rcBEhqeERPbxgZpXWqjHdGkcCD0TE82n+eUkjANL7ikY7O+maWaW1IemexLqhBYAZwOQ0PRm4pdHOTrpmVlndRczzvPKQtCXwceCmmsXnAx+X9BhwaJrvlcd0N3JTZ8Nl80HAB4fDzybB756Cb9+V/SJutRlccQzstn2nI7V6mw+AWV/I3gduAr9YAmfP6nRU5dPKO9IiYjWwQ92yF8muZsillD1dSWvSxccPSnpA0kc3oK1zJB3ayviqYvnLcOH9MPfLsOirsGYtXLsI/v5WuOpTsOAU+MwH4fu/6XSk1pM318Ch02GfS7PX4bvCfiM7HVX5tGF4YYOUtaf7eroAGUmHA+cBf7s+DUXEGS2Mq3LeXguvvw2bDoDX/gLv3RokePnNbP1Lb2TLrJxW/yV733ST7Dss2y2vZeDaC80bAqzsnpH0beB4YHPg5og4U9Io4NfAPcBHgeXApIh4XdIVwK8i4kZJRwE/AlYDvwN2iYijJZ0F7ATskt5/HBEXFvT5OmbkEPjW/rDTVBi8KRy2a/a67L/CUVfD4IEwZHO490udjtR6s4lgzpRs+OeSOXD/8k5HVC5lLGJeyuEFYHAaXngEuAw4F0DSYcBoYAIwDthX0oFpn9HAxRHxAWAV8OnaBiUNAi4FjoyIfYFhdcccAxye2j5T0qb1QUmaImmupLkvvPBGSz5oJ618HW55FB7/BjxzGqx+C37+EEy9F277DCw7Db4wDk67o9ORWm/WBux7Kez0I/jwe+ED9b/V1rLaC61S1qT7errHeQxwBHClJAGHpdd84AGyRDk67fN4RCxI0/OAUXVtjgGWRsTjaf6auvW3RsSbEdFFdp3du+4qiYhpETE+IsYPGzZogz5gGfzHUth5Wxi2Zfan6af2yE6iPfg87Ldjts0JY+H3T3c0TMvhpTdh1hNw+G6djqRkcl65UGSh87Im3b+KiNnAULKeqYDzuotORMRuEXF52vTNmt3W0PzQyYbu3+/stA3cuzwby42AmY/DnsOycdw/vJhtc9efYA/3nkpp6BawzebZ9KCBcOgu8GhXZ2MqI59Ia5KkMcAA4EXgDuBcSVdFxKuSRgJ/ydnUo8AukkZFxBPACW0JuB/Zb0c4bo/szPfATWDvETBlX9hxCHz6+my8cLtB8NNJnY7UejJiK/jZMTBgk+y7umEx3PpYp6MqFxcxz2+wpAVpWsDkiFgD3ClpD2B2NtrAq8DnyHqmDaWTal8Fbpe0GpjTlsj7mbMPyl61jt0je1m5LVwB43srx2J/VbKcW86kGxEDGqy7ALigh1Vja7b5Yc3052u2uTsixqTx4YuBuWmbs+qOMRYzq4Sy9XRLP6bbYl9OPejFwDZkVzOYWYV5TLeDImIqMLXTcZhZMbprL5TJRpV0zWzjU7bhBSddM6u0kuVcJ10zq7CC7zbLw0nXzCqtZDnXSdfMqquMJ9I2tkvGzGwj08qCN5K2lXSjpEckLZG0v6TtJd0l6bH0vl2jNpx0zazSWnyd7gXA7akY117AEuB0YGZEjAZmpvleOemaWaW1qqcraRvgQODyrN14KyJWAZOA6Wmz6cAxjdpx0jWzysrby005d2h3vez0mlLX3M7AC8DPJM2XdFl6UOXwiHg2bfMcPZSFreUTaWZWaU1cMtYVEeMbrB8I7AN8LSLuk3QBdUMJERGSGh7RPV0zq67WFjFfBiyLiPvS/I1kSfh5SSMA0vuKRo046ZpZpbVqTDcingOelrR7WnQI8DAwA5iclk0GbmnUjocXzKyy2lBB7GvAVZI2A5YCXyDrvF4v6WTgSbIH5/bKSdfMKq2VSTc9h7Gncd9D8rbhpGtmlebaC2ZmBSpZznXSNbPqKmPtBSddM6s0Dy+YmRWoZDnXSdfMKsxFzM3MilP0k37zcNI1s0rziTQzswJ5eMHMrEAly7m9J11J/4cG8UbE19sSkZlZiwT9q6c7t7AozMzapGQ5t/ekGxHTa+clbRERr7U/JDOz1ilbT7fPerrpaZcPA4+k+b0kXdL2yMzMNlRri5i3RJ4i5j8GDgdeBIiIB8kezmZmVmpNPiOtELmuXoiIpyXVLlrTnnDMzFqrbMMLeZLu05I+CoSkTYFvkD3r3cys9FqZcyU9AbxC1vF8OyLGS9oeuA4YBTwBHB8RK3trI8/wwinA/wBGAs8A49K8mVnpteoZaTUOiohxNU8OPh2YGRGjgZnUPSG4Xp893YjoAj7bVEhmZiVQUD3dScDEND0dmAV8p7eN81y9sIukX0p6QdIKSbdI2qUVkZqZtVsTJ9KGSppb85rSS3N3SppXs354RDybpp8DhjeKJ8+Y7tXAxcCxaf5E4Bpgvxz7mpl1VBNDB101Qwa9+S8RsVzSe4C7JD3yzmNFSGp4xDxjultExP+NiLfT6+fAoBz7mZl1XCsvGYuI5el9BXAzMAF4XtIIgPS+olEbvSZdSduns3K/lnS6pFGS3i/pn4DbcsZoZtY5OU+i5ekNS9pS0tbd08BhwCJgBjA5bTYZuKVRO42GF+ZlIdN9ge5X3vlR+G7fYZqZdU6LC94MB25O9ywMBK6OiNslzQGul3Qy8CRwfKNGGtVe2LlloZqZdUirrl6IiKXAXj0sfxE4JG87ue5IkzQW2JOasdyIuDLvQczMOqVkN6T1nXQlnUl2DdqeZGO5RwL3AE66ZlZ6ZUu6ea5eOI6s6/xcRHyBrHu9TVujMjNrge4x3RbfkbZB8gwvvB4RayW9LWkI2eUQ72tzXGZmLVG2nm6epDtX0rbAT8iuaHgVmN3OoMzMWqXfVRmLiK+myX+XdDswJCIeam9YZmYtUHCB8jwaPZhyn0brIuKB9oRkZtYaRRcoz6NRT/d/N1gXwMEtjqVfmfcM6KxOR2HN+OfcV1JaGVx8TWva6TfDCxFxUJGBmJm1Q8lybr6bI8zM+qt+09M1M+vvCipi3hQnXTOrtJLl3FxPjpCkz0k6I83vJGlC+0MzM9twZbsjLc9twJcA+wMnpflXyJ4kYWZWeq0sYt4KeYYX9ouIfSTNB4iIlZI2a3NcZmYbruBebB55ku5fJA0g/WcgaRiwtq1RmZm1QH+7OaLbhWTPAnqPpH8mqzr2vbZGZWbWIv3u6oWIuErSPLLyjgKOiYglbY/MzKwFWjm8kP7qnwssj4ijJe0MXAvsQFYQ7O8i4q1GbeS5emEn4DXgl2QPYFudlpmZlV6LT6R9A6jtdP4AmBoRuwErgZP7aiDP1Qu3Ar9K7zOBpcCv88doZtYZrSxiLmlH4BPAZWleZDVobkybTAeO6audPMMLH6w78D7AV3vZ3MysVJroxQ6VNLdmflpETKuZ/zHwT8DWaX4HYFVEvJ3mlwEj+zpI03ekRcQDkvZrdj8zs05oYky3KyLG97RC0tHAioiYJ2nihsST58GUp9XMbgLsAzyzIQc1MytE64qYHwB8UtJRZE9FHwJcAGwraWDq7e4ILO+roTxjulvXvDYnG9udtJ6Bm5kVJu9JtL7yckR8NyJ2jIhRwInAf0bEZ4G7yS6jBZgM3NJXTA17uunyiK0j4lt9NWRmVkZtviPtO8C1kr4PzAcu72uHRo/rGRgRb0s6oIUBmpkVqtVJNyJmAbPS9FKgqQJgjXq695ON3y6QNAO4AVhdc+CbmozVzKxwJbshLdfVC4OAF8muRwuyu9ICcNI1s1Lrb0XM35OuXFjEumTbrWQfw8ysZ2VLVo2S7gBgK96ZbLuV7XOYmfWoP5V2fDYiziksEjOzNihZzm2YdHvq4ZqZ9R/9rIj5IYVFYWbWBv2qiHlE/LnIQMzM2qE/Xb1gZtbv9afhBTOzfq9kOddJ18yqq7uIeZk46ZpZpZUs5zrpmlm1uadrZlaU1hUxbxknXTOrrH51na6ZWRWUbXghz+N6zMz6rVY8rgdA0iBJ90t6UNJiSWen5TtLuk/SHyVdJ2mzRu046ZpZpUXke+XwJnBwROwFjAOOkPQR4AfA1IjYDVgJnNyoESddM6us7iLmeV59tpV5Nc1uml5B9oCHG9Py6cAxjdpx0jWzSmtieGGopLk1ryn1bUkaIGkBsAK4C/gTsCo9gh1gGTCyUTw+kWZmldbEibSuiBjfuK1YA4yTtC1wMzCm2Xjc0zWzSmvVibR3tBmxCrgb2B/YVlJ3B3ZHYHmjfZ10zayy8p5Ey9MbljQs9XCRNBj4OLCELPkelzabDNzSqB0PL5hZpbXwMt0RwHRJA8g6rNdHxK8kPQxcK+n7wHzg8kaNOOmaWaW16jbgiHgI2LuH5UuBCXnbcdI1s0or2x1pTrpmVlmup2tmVrCS5VwnXTOrNvd0zcwKtLbTAdRx0jWzymqimE1hnHQNgB2HwJXHwvCtsl/SafPgwvs6HZX1ZG3AJXNgyObw3/fKvqs312TrVr+VfZef+1BnYyyTkuXc9iVdSQFcFRGfS/MDgWeB+yLi6Ab7TQS+FRFHS/oksGdEnN+uOOuOPQ54b0TcVsTxyuTttfCPd8L8Z2GrzWDeV+CupbDkhU5HZvV+/zQM2xLeTCVWpuy7bt3VC2GPoZ2Jq6zK1tNt523Aq4Gx6XY5yG6Za3hPcr2ImFFUwk3GAUcVeLzSeO7VLOECvPpWlmxHbt3ZmOzdXnoDHn0Rxo9497o33oY/rYQ9hhUfV5m1o/bChmh37YXbgE+k6ZOAa7pXSJogabak+ZJ+L2n3+p0lfV7SRWl6V0n3Sloo6fuSXk3LJ0qaJelGSY9IukqS0rozJM2RtEjStJrlsyT9IFWB/4Okj6Vq7+cAJ0haIOmEtv5kSuz928LeI+C+pv6LtCLc+hgcsStkv8nvtOQF2HU7GORBw3doYRHzlmh30r0WOFHSIOBDQO0o4SPAxyJib+AM4F/6aOsC4IKI+CBZzcpaewOnAnsCuwAHpOUXRcSHI2IsMBioHdYYGBET0n5nRsRbKY7rImJcRFxXH4CkKd21NnntjT7C7Z+23Ax+cTyceju88mano7Faj3Rl38/IIT2vf/B5+NDwYmMqu1YWMW+VtibddK/yKLJebv046TbADZIWAVOBD/TR3P7ADWn66rp190fEsohYCyxIxwQ4KD27aCFZdffaY9yU3ufVbN9QREyLiPERMZ4tBuXZpV8ZuEmWcK9aCDcv6XQ0Vu/Jl7LE+2+/h+sWw9KVcP3ibN3qt2DZy7D7Dp2NsYzKNrxQxB8iM4AfAhOB2l+Jc4G7I+JYSaOAWRtwjNo+2RpgYOpdXwKMj4inJZ0FDOphnzX4Kg4ALp8ES7pg6uxOR2I9OXzX7AVZwr3nKTg+dSMWvQBjhsKmAzoXXymV8JKxIurp/hQ4OyIW1i3fhnUn1j6fo517gU+n6RNzbN+dYLskbcW6epeNvAJslKePDtgpu/zo4J1h/inZ68jRnY7K8lrooYVebXQ93YhYBlzYw6p/JatN+T3g1hxNnQr8XNL/Am4HXurjuKsk/QRYBDwHzMlxjLuB09MzkM7raVy3qn73FOisTkdhee2yXfbq9qV9OhdLmW1UBW8iYqsels0iDSNExGzgb2pWf6+Hba4ArkjrlwMfiYiQdCKwe/32af4faqa/191uXRwTa6a7SGO6EfFn4MN5P6OZlV/Jcm6/GsvcF7goXfa1CvhiZ8Mxs/6gVVcmSHofcCUwnCyXT4uICyRtD1xH1nl7Ajg+Ilb21k6/SboR8Vtgr07HYWb9SwuHF94G/jEiHpC0NTBP0l1k56RmRsT5kk4HTge+01sjfjClmVVW3pNoefJyRDwbEQ+k6VfIHko5EpgETE+bTQeOadROv+npmpmtjyZ6ukMlza2ZnxYR03raMF3mujfZDV/DIyLdRM9zZMMPvXLSNbNKa2J0oSsixve1UboE9RfAqRHxsmruyU4n+hse0sMLZlZdOW8BznuyTdKmZAn3qojovqv1eUkj0voRwIpGbTjpmllldV+n24qCN+nKqcuBJRHxo5pVM4DJaXoycEujdjy8YGaV1sLrdA8A/g5YmG6gAvifwPnA9ZJOBp4Ejm/UiJOumVVaqy4Zi4h7gB6KagJwSN52nHTNrNJ8R5qZWYE2mtoLZmad1l3EvEycdM2s0kqWc510zazCSljE3EnXzCrNSdfMrCBFPxUiDyddM6s0J10zswL56gUzswJ5TNfMrCAe0zUzK5h7umZmBSpZznXSNbMKa6JAeVGcdM2ssrqLmJeJk66ZVVrJcq4f12Nm1dbCx/X8VNIKSYtqlm0v6S5Jj6X37fpqx0nXzCotcr5yuAI4om7Z6cDMiBgNzEzzDTnpmlmltaqnGxG/Af5ct3gSMD1NTweO6asdj+maWWUVUMR8eEQ8m6afA4b3tYOTrplVWhM5d6ikuTXz0yJiWu7jRISkPg/npGtm1dVcEfOuiBjf5BGelzQiIp6VNAJY0dcOHtM1s0pr4Ym0nswAJqfpycAtfe3gpGtmldV9c0SLLhm7BpgN7C5pmaSTgfOBj0t6DDg0zTfk4QUzq7RWnUeLiJN6WXVIM+046ZpZpbn2gplZgVx7wcysIC5ibmZWMPd0zcwKVLKc66RrZhXmIuZmZsVxEXMzs4KVLOc66ZpZtbmna2ZWoJLlXCddM6s293TNzApSQBHzpjnpmlmllSznOumaWYU1V8S8EE66ZlZpJcu5KMr230A/IekF4MlOx9EGQ4GuTgdhTanqd/b+iBi2IQ1Iup3s55NHV0TUP2K95Zx07R0kzV2P50RZB/k761/8uB4zswI56ZqZFchJ1+pN63QA1jR/Z/2Ix3TNzArknq6ZWYGcdM3MCuSkWzGS1khaIOlBSQ9I+ugGtHWOpENbGd/GSFJI+nnN/EBJL0j6VR/7TezeRtInJZ3e7lhrjj1O0lFFHW9j4jvSquf1iBgHIOlw4Dzgb9enoYg4o4VxbcxWA2MlDY6I14GPA8ubaSAiZgAz2hFcL8YB44HbCjzmRsE93WobAqzsnpH0bUlzJD0k6ey0bJSkJZJ+ImmxpDslDU7rrpB0XJo+StIjkuZJurCmB3aWpJ9KmiVpqaSvd+Bz9ge3AZ9I0ycB13SvkDRB0mxJ8yX9XtLu9TtL+ryki9L0rpLulbRQ0vclvZqWT0zfw43pu7pKktK6M9J3v0jStJrlsyT9QNL9kv4g6WOSNgPOAU5IfzWd0NafzEbGSbd6Bqd/KI8AlwHnAkg6DBgNTCDrxewr6cC0z2jg4oj4ALAK+HRtg5IGAZcCR0bEvkD9rZljgMNT22dK2rQNn6u/uxY4Mf0sPwTcV7PuEeBjEbE3cAbwL320dQFwQUR8EFhWt25v4FRgT2AX4IC0/KKI+HBEjAUGA0fX7DMwIiak/c6MiLdSHNdFxLiIuK6pT2oNOelWz+vpH8oY4AjgytSrOSy95gMPkCXK0WmfxyNiQZqeB4yqa3MMsDQiHk/z19StvzUi3oyILmAFMLyFn6cSIuIhsp/rSbz7T/ZtgBskLQKmAh/oo7n9gRvS9NV16+6PiGURsRZYwLrv8iBJ90laCBxcd4yb0ntP3721mMd0KywiZksaStYzFXBeRFxau42kUcCbNYvWkPWEmlG/v3+vejYD+CEwEdihZvm5wN0RcWz6PmZtwDHe9V2k3vUlwPiIeFrSWcCgHvbxd1cA93QrTNIYYADwInAH8EVJW6V1IyW9J2dTjwK7pIQA4DG+9fNT4OyIWFi3fBvWnVj7fI527mXdENCJObbvTrBd6fs/Lsc+rwBb59jOmuSkWz3dY7oLgOuAyRGxJiLuJPtTdHb6E/NGcv6jSmfcvwrcLmke2T/Il9oSfYWlP/sv7GHVvwLnSZpPvp7mqcBpkh4CdqOP7yIiVgE/ARaR/ec7J8cx7gb29Im01vNtwJaLpK0i4tU0Pnwx8FhETO10XBsjSVuQjd2HpBOBkyJiUqfjsnw8fmN5fVnSZGAzspNxl/axvbXPvsBF6T/AVcAXOxuONcM9XTOzAnlM18ysQE66ZmYFctI1MyuQk661RU21s0WSbkhn3Ne3rdoaEJdJ2rPBthPXp7KapCfSjSS5ltdt82qTxzpL0reajdGqwUnX2qX7duSxwFvAKbUrJa3XlTMR8aWIeLjBJhOB9S5nadZuTrpWhN8Cu6Ve6G8lzQAeljRA0r/VVD77CoAyF0l6VNJ/AH+9cy5VxRqfpo9QVjP4QUkz0x1zpwDfTL3sj0kaJukX6RhzJB2Q9t1BWUW1xZIuI7tNuiFJ/09ZlbXFkqbUrZuals+UNCwt21XS7Wmf36Y7BG0j5+t0ra1Sj/ZI4Pa0aB9gbEQ8nhLXSxHxYUmbA7+TdCdZpazdySplDQceJruFtrbdYWR3WR2Y2to+Iv4s6d+BVyPih2m7q4GpEXGPpJ3I7sjaAzgTuCcizpH0CeDkHB/ni+kYg4E5kn4RES8CWwJzI+Kbks5Ibf8D2QMjT4mIxyTtR1b/4OD1+DFahTjpWrsMTrciQ9bTvZzsz/77a6qVHQZ8qHu8lqwGwWjgQOCaiFgDPCPpP3to/yPAb7rbiog/9xLHoWS3s3bPD0n1Bw4EPpX2vVXSyl72r/V1Scem6felWF8E1pLdcg3wc+CmdIyPklUP695/8xzHsIpz0rV2+esTLLql5LO6dhHwtYi4o267Vj4mZhPgIxHxRg+x5CZpIlkC3z8iXpM0i3dW6qoV6bir6n8GZh7TtU66A/h7paLnkv5G0pbAb8ieWjBA0gjgoB72vRc4UNLOad/t0/L66lh3Al/rnpE0Lk3+BvhMWnYksF0fsW4DrEwJdwxZT7vbJqyr3PUZsmGLl4HHJf23dAxJ2quPY9hGwEnXOukysvHaB5QV8L6U7K+vm4HH0rorgdn1O0bEC8AUsj/lH2Tdn/e/BI7tPpEGfB0Yn07UPcy6qyjOJkvai8mGGZ7qI9bbyWrTLgHOJ0v63VYDE9JnOJjsUTcAnwVOTvEtBlyUxlx7wcysSO7pmpkVyEnXzKxATrpmZgVy0jUzK5CTrplZgZx0zcwK5KRrZlag/w+ZBGGbYGrP+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## evaluating model on test dataset\n",
    "y_pred = ensemble.predict(X_test_scaled)\n",
    "print('-------Classification report--------')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('-------Confusion matrix-------------')\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign','Malignant'])\n",
    "disp.plot(cmap=\"summer\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LuQmY93Lt6k"
   },
   "source": [
    "#### __Observation:__\n",
    "\n",
    "True Positives (TP): The model correctly predicted 47 instances as \"malignant\" when they were indeed malignant. This indicates that there were 41 true positive predictions.\n",
    "\n",
    "True Negatives (TN): The model correctly predicted 88 instances as \"benign\" when they were indeed benign. This shows 70 true negative predictions.\n",
    "\n",
    "False Positives (FP): The model incorrectly predicted 3 instance as \"malignant\" when it was actually benign. This is a false positive, also known as a Type I error.\n",
    "\n",
    "False Negatives (FN): The model incorrectly predicted 2 instances as \"benign\" when they were actually malignant. This is a false negative, also known as a Type II error.\n",
    "\n",
    "**Classification Report:**\n",
    "\n",
    "*Class 0 (Negative Class)*\n",
    "\n",
    "Precision: 0.98\n",
    "\n",
    "98% of the instances predicted as class 0 are actually class 0.\n",
    "\n",
    "Recall: 0.97\n",
    "\n",
    "97% of the actual class 0 instances are correctly predicted as class 0.\n",
    "\n",
    "F1-Score: 0.97\n",
    "\n",
    "The F1-score is the harmonic mean of precision and recall, providing a balance between the two metrics. Here, the F1-score is 0.97, indicating excellent performance.\n",
    "\n",
    "Support: 91\n",
    "\n",
    "There are 91 actual instances of class 0 in the test set.\n",
    "\n",
    "*Class 1 (Positive Class)*\n",
    "\n",
    "Precision: 0.94\n",
    "\n",
    "94% of the instances predicted as class 1 are actually class 1.\n",
    "\n",
    "Recall: 0.96\n",
    "\n",
    "96% of the actual class 1 instances are correctly predicted as class 1.\n",
    "\n",
    "F1-Score: 0.95\n",
    "\n",
    "The F1-score for class 1 is 0.95, indicating very good performance.\n",
    "\n",
    "Support: 49\n",
    "\n",
    "There are 49 actual instances of class 1 in the test set.\n",
    "\n",
    "*Overall Metrics*\n",
    "\n",
    "Accuracy: 0.96\n",
    "\n",
    "The overall accuracy of the model, indicating that 97% of the total instances are correctly classified.\n",
    "\n",
    "Macro Average\n",
    "\n",
    "Macro average calculates the metric independently for each class and then takes the average, treating all classes equally. It is useful when you have imbalanced classes.\n",
    "\n",
    "Precision: 0.96\n",
    "Recall: 0.96\n",
    "F1-Score: 0.96\n",
    "\n",
    "Weighted Average\n",
    "\n",
    "Weighted average takes into account the support (the number of true instances for each class) to calculate the average. It is more representative of the performance on imbalanced datasets.\n",
    "\n",
    "Precision: 0.96\n",
    "Recall: 0.96\n",
    "F1-Score: 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6NqpUwG2LRi"
   },
   "source": [
    "### __3.1.2 Weighted Voting/Soft Voting__\n",
    "\n",
    "Soft voting takes into account the probability estimates for each class provided by the models, assuming the models are capable of estimating these probabilities (i.e., they have a predict_proba method). The final prediction is determined by averaging these probabilities across all models, and the class with the highest average probability is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga3C9D1Q7vXK"
   },
   "source": [
    "### **Implementation of Hard and Soft Voting for comparison**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Q-PpkS86_30P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pPHiBm_8760O"
   },
   "outputs": [],
   "source": [
    "# Load the Wisconsin Breast Cancer dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "data = pd.read_csv(url, header=None, na_values='?')\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Pm7E8SmzAAuT"
   },
   "outputs": [],
   "source": [
    "# Replace class values to be binary (2 for benign, 4 for malignant)\n",
    "data['Class'] = data['Class'].replace({2: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "scCRrq8FBanb"
   },
   "outputs": [],
   "source": [
    "# Replace '?' with nan to handle missing data, ensuring numerical analysis accuracy and preventing calculation errors.\n",
    "data = data.replace('?', np.nan)\n",
    "\n",
    "# Convert object type column to numeric\n",
    "data['Bare Nuclei'] = pd.to_numeric(data['Bare Nuclei']).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Y-U4-zw7ALef"
   },
   "outputs": [],
   "source": [
    "# Features and target\n",
    "# `Sample code`(0th column) is exempted when creating X\n",
    "X = data.iloc[:, 1:-1]\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Qnk-csfgVJyg"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gZxUbeiBDTL"
   },
   "source": [
    "- `make_pipeline`: Construct a Pipeline from the given estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oYlHkovCAg4J"
   },
   "outputs": [],
   "source": [
    "# Imputation to handle missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Define the base models with standard scaling and imputation\n",
    "model1 = make_pipeline(imputer, StandardScaler(), LogisticRegression(random_state=1, max_iter=10000))\n",
    "model2 = make_pipeline(imputer, StandardScaler(), DecisionTreeClassifier(random_state=1))\n",
    "model3 = make_pipeline(imputer, StandardScaler(), SVC(probability=True, random_state=1))\n",
    "\n",
    "# Define k-fold cross-validation procedure\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Create an ensemble of models for hard voting\n",
    "hard_voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', model1), ('dt', model2), ('svc', model3)],\n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1720001965425,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "8Kl9BxHxkhG3",
    "outputId": "c4f0b9fb-d59d-417e-a4f7-a1cb6337ad00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting - Mean CV Accuracy: 0.9659\n",
      "Hard Voting - Test Accuracy: 0.9643\n",
      "Hard Voting - Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        91\n",
      "           1       0.94      0.96      0.95        49\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.96      0.96      0.96       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "Hard Voting - Confusion Matrix:-\n",
      "[[88  3]\n",
      " [ 2 47]]\n",
      "----------------------------------------------\n",
      "Soft Voting - Mean CV Accuracy: 0.9624\n",
      "Soft Voting - Test Accuracy: 0.9643\n",
      "Soft Voting - Classification Report:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        91\n",
      "           1       0.94      0.96      0.95        49\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.96      0.96      0.96       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "Soft Voting - Confusion Matrix\n",
      "[[88  3]\n",
      " [ 2 47]]\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation on the training data\n",
    "hard_cv_scores = cross_val_score(hard_voting_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(f\"Hard Voting - Mean CV Accuracy: {hard_cv_scores.mean():.4f}\")\n",
    "\n",
    "# Fit and evaluate on the test data\n",
    "hard_voting_classifier.fit(X_train, y_train)\n",
    "y_pred_hard = hard_voting_classifier.predict(X_test)\n",
    "hard_test_accuracy = hard_voting_classifier.score(X_test, y_test)\n",
    "print(f\"Hard Voting - Test Accuracy: {hard_test_accuracy:.4f}\")\n",
    "\n",
    "# Additional evaluation metrics for hard voting classifier\n",
    "print(\"Hard Voting - Classification Report\")\n",
    "print(classification_report(y_test, y_pred_hard))\n",
    "print(\"Hard Voting - Confusion Matrix:-\")\n",
    "print(confusion_matrix(y_test, y_pred_hard))\n",
    "print(\"----------------------------------------------\")\n",
    "# Create and evaluate a soft voting classifier\n",
    "soft_voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', model1), ('dt', model2), ('svc', model3)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Cross-validation on the training data\n",
    "soft_cv_scores = cross_val_score(soft_voting_classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "print(f\"Soft Voting - Mean CV Accuracy: {soft_cv_scores.mean():.4f}\")\n",
    "\n",
    "# Fit and evaluate on the test data\n",
    "soft_voting_classifier.fit(X_train, y_train)\n",
    "y_pred_soft = soft_voting_classifier.predict(X_test)\n",
    "soft_test_accuracy = soft_voting_classifier.score(X_test, y_test)\n",
    "print(f\"Soft Voting - Test Accuracy: {soft_test_accuracy:.4f}\")\n",
    "\n",
    "# Additional evaluation metrics for soft voting classifier\n",
    "print(\"Soft Voting - Classification Report:-\")\n",
    "print(classification_report(y_test, y_pred_soft))\n",
    "print(\"Soft Voting - Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred_soft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnF4ynEjl345"
   },
   "source": [
    "### __3.2 Averaging__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaY84EN0l345"
   },
   "source": [
    "The averaging technique is used mainly for regression problems. In this method, the predictions of multiple models are averaged to obtain the final prediction. This technique helps reduce variance and produces a more stable prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZAy-5jsl346"
   },
   "source": [
    "__Example:__\n",
    "\n",
    "- Averaging ensemble works by combining the predictions from multiple classifiers trained on the dataset.\n",
    "- These classifiers, such as Logistic Regression, Decision Tree, and Support Vector Machine, provide individual predictions for each data point.\n",
    "- Then it takes the average of these predictions to form a final prediction.\n",
    "- This approach helps to mitigate biases and uncertainties inherent in individual models, leading to a more accurate prediction of breast cancer classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW7uxYMyFLDK"
   },
   "source": [
    "**Note:** X and y from the previous dataset is  used for the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "e9HE_shWFXLA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "k56AH81zlUK0"
   },
   "outputs": [],
   "source": [
    "# Create an instance of SimpleImputer to fill in missing values with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Create an instance of MinMaxScaler to scale features to a range of (0, 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RtUQeQFCFc3z"
   },
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "LogReg_clf = LogisticRegression()\n",
    "Dtree_clf = DecisionTreeClassifier()\n",
    "svc_clf = SVC(probability=True)  # Enable probability for SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "560sVDcrFhTd"
   },
   "outputs": [],
   "source": [
    "# Train classifiers on the training dataset\n",
    "LogReg_clf.fit(X_train_scaled, y_train)\n",
    "Dtree_clf.fit(X_train_scaled, y_train)\n",
    "svc_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate probability predictions for the positive class from each classifier on the test set\n",
    "LogReg_prob = LogReg_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "Dtree_prob = Dtree_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "svc_prob = svc_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1718701427693,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "RAvpwd1YF1Td",
    "outputId": "2fa3edeb-241d-46d4-8553-b0da50ff3e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of averaged model predictions on test data: 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "# Average the probability predictions\n",
    "avg_probs = np.mean([LogReg_prob, Dtree_prob, svc_prob], axis=0)\n",
    "\n",
    "# Convert averaged probabilities to class predictions based on a threshold\n",
    "avg_preds = (avg_probs > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the accuracy of the averaged predictions on the test set\n",
    "accuracy = accuracy_score(y_test, avg_preds)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy of averaged model predictions on test data:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51-rIxwPl346"
   },
   "source": [
    "The averaging ensemble achieves an accuracy of 95%, slightly lower than the max voting ensemble. However, this accuracy rate still underscores the effectiveness of the averaging ensemble in breast cancer classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mW-AvUiAl35A"
   },
   "source": [
    "### __3.3 Weighted Averaging__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bybjyts-l35A"
   },
   "source": [
    "Weighted averaging assigns different weights to each model’s prediction, reflecting its importance or reliability. The final prediction is a weighted average, which can be more effective than simple averaging because it considers each model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3ErNIT4l35A"
   },
   "source": [
    "__Example:__\n",
    "\n",
    "- In medical diagnosis, weighted ensemble learning combines results from various diagnostic tests with different reliabilities.\n",
    "- Each test's result is weighted based on its importance. For instance, blood tests, imaging scans, and physical examinations' results are combined to determine a patient's diagnosis accurately and reliably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BWjyfVXl35B"
   },
   "source": [
    "By weighting and averaging results from multiple diagnostic tests, you can determine the final diagnosis, thereby enhancing diagnostic accuracy and reliability. This highlights the significance of weighted averaging for improving decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxrLwlAGl35B"
   },
   "source": [
    "## __4. Advanced Techniques for Ensemble Learning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_ckakMIl35B"
   },
   "source": [
    "These techniques use complex methods to merge predictions from many individual models. It aims for better predictive accuracy. They are employed for complex problems where high predictive accuracy is crucial, such as in financial forecasting, medical diagnosis, and natural language processing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBvNkoeOl35B"
   },
   "source": [
    "### __4.1 Bagging__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r3X3meZl35B"
   },
   "source": [
    "Bagging or Bootstrap Aggregating enhances the stability and accuracy of machine learning algorithms. This method creates multiple subsets from the original dataset, known as bootstrap samples, by selecting data points with replacement. Each subset trains a separate model.\n",
    "\n",
    "For final predictions, Bagging combines the individual models' outputs by using voting (for classification tasks) or averaging (for regression tasks). This approach effectively reduces variance and helps prevent overfitting.\n",
    "\n",
    "__Note:__ Random Forest is a popular algorithm that utilizes bagging by training multiple decision trees on different bootstrap samples and combining their predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxwKnzPJl35B"
   },
   "source": [
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/updated/Lesson_05/Ensembled_Learning_Bagging.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKjwuWTYl35C"
   },
   "source": [
    "__Note:__ The numbering shown in the above image outlines the specific workflow for bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5V1ZRLyil35C"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1720002218147,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "KJZNHKUJ5Dfz",
    "outputId": "e22a48ab-6d26-4750-9716-1307ba85e8a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima Indians Diabetes dataset using the given URL and assign the names\n",
    "\n",
    "url=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_csv(url, names=names)\n",
    "\n",
    "# Check the head of the data using the head() method\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_9gL8x8FqMg"
   },
   "source": [
    "Create a feature matrix X and a target vector y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CRSA67UoknYF"
   },
   "outputs": [],
   "source": [
    "# Assign all the rows up to the 8th column of the data to X\n",
    "X = data.iloc[:,0:8].values\n",
    "\n",
    "# Assign the 9th column of the same data to Y\n",
    "y = data[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "QE3bVPDbm9Rg"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9Y8_YHhzm4V1"
   },
   "outputs": [],
   "source": [
    "# Create an instance of SimpleImputer to fill in missing values with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Create an instance of MinMaxScaler to scale features to a range of (0, 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5uEtSPGI5Dfz"
   },
   "outputs": [],
   "source": [
    "# Set up the k-fold cross-validation with n_splits to 10\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Create a decision tree classifier named cart\n",
    "cart = DecisionTreeClassifier()\n",
    "\n",
    "# The estimator will be set to 100, which is equal to the number of trees\n",
    "num_trees = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpotA1lQG9cx"
   },
   "source": [
    "#### __Apply the bagging technique__\n",
    "\n",
    "* `oob_score`: This is a method of measuring the prediction error of random forests, bagging, and other ensemble methods that involve bootstrap aggregating\n",
    "\n",
    "We'll talk about it in detail below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9382,
     "status": "ok",
     "timestamp": 1720002532462,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "xY9AXU9k5Df0",
    "outputId": "f93e1165-3482-48ea-8eda-dfc7d6a79f8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79032258 0.67741935 0.75806452 0.70967742 0.86885246 0.78688525\n",
      " 0.63934426 0.7704918  0.73770492 0.72131148]\n"
     ]
    }
   ],
   "source": [
    "# Create a bagging classifier with the decision tree classifier (cart) as the base estimator\n",
    "# Ensure oob_score is enabled\n",
    "bagging_model = BaggingClassifier(estimator=cart, n_estimators=num_trees, random_state=12, oob_score=True)\n",
    "\n",
    "# Perform cross-validation using the model, feature matrix (X), target vector (y), and specified number of folds (cv)\n",
    "results = model_selection.cross_val_score(bagging_model, X_train_scaled, y_train, cv=kfold)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HHno_iHl35D"
   },
   "source": [
    "__Observations:__\n",
    "- The results array contains the cross-validation scores for each fold of the data.\n",
    "- The cross-validation scores indicate the performance of the BaggingClassifier model on different subsets of the data.\n",
    "- These scores can assess the generalization ability and performance stability of the BaggingClassifier model across multiple iterations of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1720002328544,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "U7IU5MPEl35D",
    "outputId": "09a2a227-2a62-4fc4-916e-d7e169c063b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Score: 0.7460074034902168\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Mean Cross-Validation Score using .mean() function\n",
    "mean_score = np.mean(results)\n",
    "\n",
    "print(\"Mean Cross-Validation Score:\", mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2p9AhRil35E"
   },
   "source": [
    "- The provided code illustrates a bagging implementation with a DecisionTreeClassifier base estimator. It employs KFold cross-validation with 10 folds and applies BaggingClassifier with 100 decision tree estimators to each fold.\n",
    "- The resultant mean cross-validation score of 0.75 demonstrates the ensemble's effectiveness in enhancing predictive performance compared to a single decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 1342,
     "status": "ok",
     "timestamp": 1720002632734,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "Kbg9G7XiInCU",
    "outputId": "ac035b2c-26fd-4b0a-daaa-72bc41cfc375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________Bagging Classifier_______________________\n",
      "\n",
      "# Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79        99\n",
      "           1       0.62      0.64      0.63        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.71      0.71       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "# Confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fitting  and evaluating Bagging classifier model in training and test dataset\n",
    "\n",
    "bagging_model.fit(X_train_scaled,y_train)\n",
    "print('___________________________Bagging Classifier_______________________')\n",
    "print()\n",
    "# evaluating model on test dataset\n",
    "y_pred = bagging_model.predict(X_test_scaled)\n",
    "print('# Classification report')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('# Confusion matrix')\n",
    "cmap = 'summer'\n",
    "display_labels=['Non diabetic','Diabetic']\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot(cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex5DqCXcl35E"
   },
   "source": [
    "### __4.1.1 Advantages of Bagging__\n",
    "\n",
    "- It reduces the risk of overfitting by training on various subsets of the data.\n",
    "- It improves the model's accuracy and stability.\n",
    "- It works well with complex models that tend to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hirnSNpl35E"
   },
   "source": [
    "### __4.1.2 Disadvantages of Bagging__\n",
    "\n",
    "- It increases computational complexity because it requires training multiple models.\n",
    "- It may not significantly improve performance if the base models are already biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krGmB1u6l35E"
   },
   "source": [
    "### __4.1.3  Out-Of-Bag (OOB) Concept__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgcmjoxDl35E"
   },
   "source": [
    "In bagging, __out-of-bag (OOB)__ data refers to instances not included in the bootstrap sample for training a specific base model. Since the process trains each model on a random subset of the original data, it naturally leaves out some instances.\n",
    "\n",
    "These OOB instances serve as a built-in validation set for each model, allowing for an assessment of the model's performance on unseen data points. You can compute the OOB error, which offers an efficient way to evaluate the model's generalization ability.\n",
    "\n",
    "This method eliminates the need for additional validation data or cross-validation procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eL60FStl35F"
   },
   "source": [
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/Lesson_07/Out_Of_Bag_Concept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_px6EWnll35F"
   },
   "source": [
    "In the above image, Sample 1 lacks Rat and Cow, whereas Sample 3 includes all animals from the primary training set. Data points were randomly chosen with replacement during sample creation, and those omitted from a particular sample are identified as out-of-bag (OOB) points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhwNg0aRqwEp"
   },
   "source": [
    " - The OOB score is an estimate of performance that mimics cross-validation. It uses out-of-bag samples to estimate the model's accuracy.\n",
    "\n",
    " - This means that for each tree in a bagging ensemble, only the data not seen by the tree (out-of-bag data) are used to assess that tree’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1720002754787,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "a7fm_bi5l35F",
    "outputId": "b295f46f-f98e-49a3-f8b4-3a79d2242abf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Bag Error: 0.23615635179153094\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation and compute OOB error\n",
    "oob_error = 1 - bagging_model.fit(X_train_scaled, y_train).oob_score_\n",
    "\n",
    "print(\"Out-of-Bag Error:\", oob_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCW9NEg2l35F"
   },
   "source": [
    "__Observations:__\n",
    "- The code computes the out-of-bag (OOB) error for a BaggingClassifier model using cross-validation.\n",
    "- It calculates the OOB error by subtracting the OOB score from 1.\n",
    "- The **OOB score** represents the model's accuracy on out-of-bag samples.\n",
    "- The OOB error provides insight into the model's performance on unseen data points, indicating the misclassification rate of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7-5z7M3l35F"
   },
   "source": [
    "### __4.2 Boosting__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayiM-qmal35F"
   },
   "source": [
    "Boosting is a sequential ensemble technique where each model corrects its predecessor's mistakes. The main idea is to train models sequentially, each trying to correct the errors of the previous model.\n",
    "\n",
    "The final prediction is a weighted sum of all the models' predictions. Boosting significantly reduces bias and variance, leading to more accurate models.\n",
    "\n",
    "__Note:__ Popular boosting algorithms include AdaBoost, Gradient Boosting Machines (GBM), and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs9TzCm5l35F"
   },
   "source": [
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/updated/Lesson_05/Ensembled_Learning_Boosting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnKPkH_Ll35G"
   },
   "source": [
    "__Note:__ The numbering shown in the above image specifically outlines the workflow for boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQ7Bf8CMCi0m"
   },
   "source": [
    "#### __4.2.1 Boosting Techniques__\n",
    "\n",
    "There are various meta-algorithms in boosting that differentiate how the base models are aggregated, such as:\n",
    "* Adaboost\n",
    "* Gradient Boost\n",
    "* XGBoost\n",
    "* CatBoost\n",
    "\n",
    "**Meta-algorithm** (or meta-learning) involves learning algorithms that are designed to learn how to combine the predictions of multiple machine learning models, often referred to as base models or learners, to improve overall performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYztPf_-C2_2"
   },
   "source": [
    "#### __4.2.2. AdaBoost Algorithm__\n",
    "\n",
    "AdaBoost, an abbreviation for adaptive boosting, stands as one of the leading boosting algorithms with widespread adoption. It focuses on classification problems, aiming to transform a collection of weak classifiers into a single strong classifier. It increases the weights of misclassified instances, directing subsequent classifiers to pay more attention to challenging cases.\n",
    "\n",
    "**The AdaBoost algorithm follows these steps:**\n",
    "1. Initially, the algorithm assigns equal weights to all observations in the dataset.\n",
    "2. A model is constructed using a subset of the data.\n",
    "3. Predictions are made on the entire dataset using this model.\n",
    "4. The algorithm computes errors by comparing these predictions to the actual values.\n",
    "5. In the subsequent model creation, the algorithm assigns higher weights to incorrectly predicted data points.\n",
    "6. Weights are determined based on error values, where higher errors result in heavier observation weights.\n",
    "7. This iterative process continues until the error function stabilizes or the algorithm reaches the maximum limit of estimators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1R4WJ0TEV-h"
   },
   "source": [
    "### **Implementation of Adaboost Classifier and Bagging classifier to compare the performance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1720088251739,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "JcA6Oy36Dzs_"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the dataset from the given URL and assign column names\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses','Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1720088258615,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "Qj1z1pofLuPp"
   },
   "outputs": [],
   "source": [
    "# Drop the 'Sample code' column as it's not required for prediction\n",
    "data.drop(['Sample code'], axis=1, inplace=True)\n",
    "\n",
    "# Replace '?' with nan to handle missing data, ensuring numerical analysis accuracy and preventing calculation errors.\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1720088269874,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "j7yde7n-P_vZ"
   },
   "outputs": [],
   "source": [
    "# Replace class values to be binary (2 for benign, 4 for malignant)\n",
    "data['Class'] = data['Class'].replace({2: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1720088272368,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "sa-dH2XyLuPq"
   },
   "outputs": [],
   "source": [
    "# Convert the 'Bare Nuclei' column to an integer type to ensure a uniform data type across the column,\n",
    "# which is essential for consistent data manipulation and analysis.\n",
    "data['Bare Nuclei'] = pd.to_numeric(data['Bare Nuclei']).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqCqVRN1E8K2"
   },
   "source": [
    "- A SimpleImputer handles missing values in a dataset by imputing (i.e., filling in) the missing values with a specified statistic, such as the mean, median, or most frequent value of the respective feature.\n",
    "- This is important because missing values can disrupt the analysis and modeling process, leading to biased results or errors in predictive models.\n",
    "- Imputation helps maintain the integrity and completeness of the dataset, ensuring that the analysis or modeling algorithms can effectively utilize the available data for accurate insights or predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1720088274852,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "KC8hoEV_E0dg"
   },
   "outputs": [],
   "source": [
    "# Split data into features (X) and target variable (y)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1720088280399,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "mhkCiWGuL_bq"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2761,
     "status": "ok",
     "timestamp": 1720088283837,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "O-ZSeeBGMDFn",
    "outputId": "fe80aceb-06c1-4d18-acb0-74a4b88b131f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier mean accuracy:  0.9642207792207792\n",
      "Adaboost Classifier test accuracy:  0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Define K-fold cross-validation\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "\n",
    "# Create a pipeline for AdaBoost classifier with Decision Tree base estimator\n",
    "adaboost_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "    ('classifier', AdaBoostClassifier(n_estimators=70, random_state=7))\n",
    "])\n",
    "\n",
    "# Evaluate the Adaboost Classifier pipeline using cross-validation on the training set\n",
    "adaboost_results = cross_val_score(adaboost_pipeline, X_train, y_train, cv=kfold)\n",
    "print(\"AdaBoost Classifier mean accuracy: \", adaboost_results.mean())\n",
    "\n",
    "\n",
    "# Fit the Adaboost Classifier pipeline on the training set and evaluate on the test set\n",
    "adaboost_pipeline.fit(X_train, y_train)\n",
    "adaboost_test_score = adaboost_pipeline.score(X_test, y_test)\n",
    "print(\"Adaboost Classifier test accuracy: \", adaboost_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1720088288006,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "kj75Zhg8PIwJ",
    "outputId": "ac187e56-9b3f-4b11-db51-10f122ba08c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________Adaboost Classifier_______________________\n",
      "\n",
      "# Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        91\n",
      "           1       0.96      0.96      0.96        49\n",
      "\n",
      "    accuracy                           0.97       140\n",
      "   macro avg       0.97      0.97      0.97       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n",
      "# Confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fitting  and evaluating Boosting classifier model in training and test dataset\n",
    "\n",
    "print('___________________________Adaboost Classifier_______________________')\n",
    "print()\n",
    "# evaluating model on test dataset\n",
    "y_pred = adaboost_pipeline.predict(X_test)\n",
    "print('# Classification report')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('# Confusion matrix')\n",
    "cmap = 'summer'\n",
    "display_labels=['Benign','Malignant']\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot(cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2dDrw4eFZnt"
   },
   "source": [
    "__Observations:__\n",
    "\n",
    "- This demonstrates the importance and effectiveness of AdaBoost in enhancing the predictive capability of weak learners, like decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrtF9-XNFelO"
   },
   "source": [
    "#### __4.2.3. Gradient Boosting Machine__\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKNYtSHlF6w_"
   },
   "source": [
    "Gradient boosting refers to a class of ensemble machine learning algorithms that can be used for classification or regression predictive modeling problems.\n",
    "\n",
    "Gradient boosting is also known as gradient tree boosting, stochastic gradient boosting (an extension), and gradient boosting machines, or GBM for short.\n",
    "\n",
    "Ensembles are constructed from decision tree models. Trees are added one at a time to the ensemble and fit to correct the prediction errors made by prior models\n",
    "\n",
    "**Gradient Boosting involves three main components:**\n",
    "\n",
    "* Loss Function: The choice of loss function depends on the type of problem being solved (e.g., regression, classification). The goal is to find a model that minimizes the loss function.\n",
    "\n",
    "* Weak Learners: Gradient Boosting uses decision trees as the default weak learner. These trees are usually of a fixed size and depth and are created one at a time.\n",
    "\n",
    "* Additive Model: Instead of adjusting the weights of data points like AdaBoost, Gradient Boosting fits new models to the residual errors made by previous models. Essentially, each new model is built on the errors of the whole ensemble so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6-zlpRIGURL"
   },
   "source": [
    "#### __4.2.4. XGBoost__\n",
    "\n",
    "XGBoost, or eXtreme Gradient Boosting, stands out as a premier machine learning framework, widely adopted for its proficiency in supervised learning tasks including classification, regression, and ranking. This advanced algorithm builds upon the principles of gradient boosting and is celebrated for its exceptional accuracy and scalability in handling complex predictive modeling challenges.\n",
    "\n",
    " **XGBoost offers many essential features that make it ideal for classification tasks. Some of the reasons include:**\n",
    "\n",
    "* High performance: As mentioned above, XGBoost is optimized for speed and efficiency, making it appropriate for large datasets and real-time applications.\n",
    "\n",
    "* Regularization methods: L1 (Lasso) and L2 (Ridge) regularisation terms are included in XGBoost to avoid overfitting and increase generalization.\n",
    "\n",
    "* Handle missing data: Moreover, XGBoost can handle missing data automatically, minimizing the need for preprocessing and imputation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZH5Jli4RE5Kq"
   },
   "source": [
    "#### __4.2.5. CatBoost__\n",
    "\n",
    "Catboost is a variant of gradient boosting that can handle both categorical and numerical features. It does not require any feature encodings techniques like One-Hot Encoder or Label Encoder to convert categorical features into numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owZskOIvHJ5R"
   },
   "source": [
    "### **Implementation of XGBoost, Gradient Boost and CatBoost Algorithm:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15925,
     "status": "ok",
     "timestamp": 1720088331053,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "GckeLdfKH19w",
    "outputId": "98c3f2f5-8000-47b6-9049-7193076dbe2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/site-packages (from catboost) (0.8.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (from catboost) (3.6.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from catboost) (1.9.3)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2022.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/site-packages (from plotly->catboost) (8.2.2)\n",
      "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: catboost\n",
      "Successfully installed catboost-1.2.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1720088365725,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "QItOj6EvN_oM"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Load the dataset from the given URL and assign column names\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses','Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1720088373077,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "RWqHZrLxN_oN"
   },
   "outputs": [],
   "source": [
    "# Drop the 'Sample code' column as it's not required for prediction\n",
    "data.drop(['Sample code'], axis=1, inplace=True)\n",
    "\n",
    "# Replace '?' with nan to handle missing data, ensuring numerical analysis accuracy and preventing calculation errors.\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1720088400527,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "IZKoN_FIQbL0"
   },
   "outputs": [],
   "source": [
    "# Replace class values to be binary (2 for benign, 4 for malignant)\n",
    "data['Class'] = data['Class'].replace({2: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1720088402986,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "vkRxuK9lN_oN"
   },
   "outputs": [],
   "source": [
    "# Convert the 'Bare Nuclei' column to an integer type to ensure a uniform data type across the column,\n",
    "# which is essential for consistent data manipulation and analysis.\n",
    "data['Bare Nuclei'] = pd.to_numeric(data['Bare Nuclei']).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1720088404895,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "qUS5ArjFG9W2"
   },
   "outputs": [],
   "source": [
    "# Split data into features (X) and target variable (y)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# Define K-fold cross-validation\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1566,
     "status": "ok",
     "timestamp": 1720088422736,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "V_vo60Z2OpIe",
    "outputId": "0a7562a8-57bd-404e-b974-ffb14b5d84f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier mean accuracy after cross validation:  0.9588961038961038\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gb_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=7))\n",
    "])\n",
    "\n",
    "# Evaluate the Gradient Boosting Classifier pipeline\n",
    "gb_results = cross_val_score(gb_pipeline, X_train, y_train, cv=kfold)\n",
    "print(\"Gradient Boosting Classifier mean accuracy after cross validation: \", gb_results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1720088427507,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "ctGIP3YfOrTA",
    "outputId": "13d39e3c-c07d-4b7f-fa3a-7e3345beb8b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier test accuracy:  0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "# Fit the Gradient boosting Classifier pipeline on the training set and evaluate on the test set\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "gb_boost_test_score = gb_pipeline.score(X_test, y_test)\n",
    "print(\"Gradient Boosting Classifier test accuracy: \", gb_boost_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1720088678464,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "eNHcB9z3RGoQ",
    "outputId": "2df454b0-41ef-4750-9277-b51a3cbf7e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________Gradient Boosting Classifier_______________________\n",
      "\n",
      "# Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        91\n",
      "           1       0.94      0.94      0.94        49\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.95      0.95      0.95       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "# Confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fitting  and evaluating Boosting classifier model in training and test dataset\n",
    "\n",
    "print('___________________________Gradient Boosting Classifier_______________________')\n",
    "print()\n",
    "# evaluating model on test dataset\n",
    "y_pred = gb_pipeline.predict(X_test)\n",
    "print('# Classification report')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('# Confusion matrix')\n",
    "cmap = 'summer'\n",
    "display_labels=['Benign','Malignant']\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot(cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NJBObmGH8AI"
   },
   "source": [
    "- In XGBoost, one-hot encoding is used for multi-class classification problems to transform the categorical target variables into a binary matrix format.\n",
    "\n",
    "- This conversion is crucial for applying gradient boosting techniques effectively, allowing each model iteration to focus on optimizing classification accuracy across potentially many different classes.\n",
    "\n",
    "- XGBoost, along with other gradient boosting methods, enhances model accuracy by optimizing specific loss functions. Logarithmic Loss (**LogLoss**), also known as Cross-Entropy Loss is  used as an evaluation metric for this classification problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1840,
     "status": "ok",
     "timestamp": 1720088609044,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "qGi8HrMaHkxo",
    "outputId": "da3051a3-eda0-4bba-961c-8704c75f4aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier mean accuracy:  0.9605844155844157\n",
      "XGBoost Classifier test accuracy:  0.95\n",
      "\n",
      "CatBoost Classifier CV mean accuracy:  0.9660389610389611\n",
      "CatBoost Classifier test accuracy:  0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "    ('classifier', XGBClassifier(n_estimators=100, random_state=7, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Evaluate the XGBoost Classifier pipeline\n",
    "xgb_results = cross_val_score(xgb_pipeline, X_train, y_train, cv=kfold, error_score=\"raise\")\n",
    "print(\"XGBoost Classifier mean accuracy: \", xgb_results.mean())\n",
    "\n",
    "# Fit the Gradient boosting Classifier pipeline on the training set and evaluate on the test set\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "xgb_test_score = xgb_pipeline.score(X_test, y_test)\n",
    "print(\"XGBoost Classifier test accuracy: \", xgb_test_score)\n",
    "print()\n",
    "# CatBoost Classifier\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "    ('classifier', CatBoostClassifier(n_estimators=100, random_state=7, verbose=0))\n",
    "])\n",
    "\n",
    "# Evaluate the CatBoost Classifier pipeline using cross-validation on the training set\n",
    "cat_cv_results = cross_val_score(cat_pipeline, X_train, y_train, cv=kfold)\n",
    "print(\"CatBoost Classifier CV mean accuracy: \", cat_cv_results.mean())\n",
    "\n",
    "# Fit the CatBoost Classifier pipeline on the training set and evaluate on the test set\n",
    "cat_pipeline.fit(X_train, y_train)\n",
    "cat_test_score = cat_pipeline.score(X_test, y_test)\n",
    "print(\"CatBoost Classifier test accuracy: \", cat_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1720088703531,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "K_o70u4NRVNS",
    "outputId": "e36c9d96-7416-4545-dd00-05e9d9c5f80f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________XGBoost Classifier_______________________\n",
      "\n",
      "# Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        91\n",
      "           1       0.94      0.92      0.93        49\n",
      "\n",
      "    accuracy                           0.95       140\n",
      "   macro avg       0.95      0.94      0.94       140\n",
      "weighted avg       0.95      0.95      0.95       140\n",
      "\n",
      "# Confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fitting  and evaluating Boosting classifier model in training and test dataset\n",
    "\n",
    "print('___________________________XGBoost Classifier_______________________')\n",
    "print()\n",
    "# evaluating model on test dataset\n",
    "y_pred = xgb_pipeline.predict(X_test)\n",
    "print('# Classification report')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('# Confusion matrix')\n",
    "cmap = 'summer'\n",
    "display_labels=['Benign','Malignant']\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot(cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1720088754343,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "QmMuGFwBRvAz",
    "outputId": "7fabbe56-d7b8-45bb-8b6c-405afe08e009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________CatBoost Classifier_______________________\n",
      "\n",
      "# Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        91\n",
      "           1       0.94      0.94      0.94        49\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.95      0.95      0.95       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n",
      "# Confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fitting  and evaluating Boosting classifier model in training and test dataset\n",
    "\n",
    "print('___________________________CatBoost Classifier_______________________')\n",
    "print()\n",
    "# evaluating model on test dataset\n",
    "y_pred = cat_pipeline.predict(X_test)\n",
    "print('# Classification report')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('# Confusion matrix')\n",
    "cmap = 'summer'\n",
    "display_labels=['Benign','Malignant']\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "disp.plot(cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBJvTzGCl35H"
   },
   "source": [
    "### __4.2.6 Advantages of Boosting__\n",
    "\n",
    "- It enhances accuracy by reducing both bias and variance significantly.\n",
    "- It is adaptable and compatible with various types of models.\n",
    "- It is efficient in complex scenarios where simple models struggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtTBAqj6l35H"
   },
   "source": [
    "### __4.2.7 Disadvantages of Boosting__\n",
    "\n",
    "- It is more susceptible to overfitting compared to bagging when dealing with noisy data.\n",
    "- It demands more computational resources as models are trained sequentially.\n",
    "- It requires careful parameter tuning to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISzmy1N4l35H"
   },
   "source": [
    "### __4.3 Stacking__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFdDShzal35I"
   },
   "source": [
    "Stacking combines multiple classification or regression models via a meta model which could be a meta-classifier or a meta-regressor. After training the base models on the complete dataset, the meta-model trains on the base models' outputs as features, to give final prediction.\n",
    "\n",
    "This technique leverages the strengths of each base model and can achieve higher accuracy.\n",
    "\n",
    "* In stacking, as opposed to bagging, a variety of models (not solely decision trees) are employed, all of which are trained on the same full dataset rather than on subsets.\n",
    "* Unlike boosting, in stacking, a single model is used to learn how to best combine the predictions from the contributing models (e.g. instead of a sequence of models that correct the predictions of prior models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c91jJx3ml35I"
   },
   "source": [
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ML/updated/Lesson_05/image7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tld9diA9l35I"
   },
   "source": [
    "__Note:__ The numbering shown in the above image specifically outlines the workflow for stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfLBZ8lTl35I"
   },
   "source": [
    "- Stacking aims to leverage the advantages of different base models by inputting their predictions into a meta-model.\n",
    "\n",
    "The structure of a stacking model consists of multiple base models, also known as level-0 models, alongside a meta-model that integrates their predictions, known as the level-1 model.\n",
    "\n",
    "* Level-0 Models (**Base Models**): These models are trained on the full training dataset, and their individual predictions are aggregated.\n",
    "* Level-1 Model (**Meta-Model**): This model is designed to optimally combine the predictions of multiple base models to generate the final prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9004,
     "status": "ok",
     "timestamp": 1718695911941,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "usaORpXSl35I",
    "outputId": "d478bcd9-6685-4336-ff3d-f67210c2a563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: vecstack in ./.local/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from vecstack) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from vecstack) (1.9.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/site-packages (from vecstack) (1.3.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=0.18->vecstack) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=0.18->vecstack) (3.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "# vecstack: is Python package for stacking\n",
    "!pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "TyQx0mmNTZ4h"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries like pandas, sklearn and vecstack\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from vecstack import stacking\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Define the URL of the dataset\n",
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "\n",
    "# Define column names for the dataset\n",
    "names = ['Class', 'Alcohol', 'Malic acid', 'Ash',\n",
    "         'Alkalinity of ash', 'Magnesium', 'Total phenols',\n",
    "         'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "         'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "         'Proline']\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(link, header=None, names=names)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Transform target variable y_train using LabelEncoder\n",
    "y = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPGCUEB-Qp3t"
   },
   "source": [
    "- `stacking` in `vecstack` allows for custom cross-validation strategies, including stratified k-fold cross-validation, shuffling, and setting random seeds for reproducibility.\n",
    "- This feature provides more control over model training and evaluation\n",
    "- `vecstack` explicitly generates out-of-fold predictions for the training data, which can be used as features for the meta-model. This process can help in preventing overfitting and providing a robust estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "MrXd18kITvw_"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models\n",
    "models = [KNeighborsClassifier(n_neighbors=5),\n",
    "          RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_x-axHZl35J"
   },
   "source": [
    "__Observation:__\n",
    "- The different classifiers such as KNN, Random forest and XGBoost classifier are set as the base models.\n",
    "- As the Meta model, Logistic Regression is chosen. Logistic Regression is a common choice for a meta-model in stacking because it is a simple and interpretable linear model that often performs well in combining the outputs of diverse base models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh9mmgV0l35J"
   },
   "source": [
    "__S Train__ refers to a subset of the original training data used for training base models in a stacking ensemble.\n",
    "\n",
    "__S Test__ is another subset used to generate base model predictions, serving as input for the meta-model. It is crucial for generating predictions from these base models, which then act as new features for the meta-model.\n",
    "\n",
    "This two-step approach allows the ensemble to capture and leverage the unique strengths of each base model, thus improving overall predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtiyyVxIl35J"
   },
   "source": [
    "- Let us do the S_train and S_tests, as you will be stacking the models by passing train of X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6389,
     "status": "ok",
     "timestamp": 1718710591604,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "uUAEPzcqUpxt",
    "outputId": "ec73ac7b-76ec-4b24-d888-84f12bcdeba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [3]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.82758621]\n",
      "    fold  1:  [0.65517241]\n",
      "    fold  2:  [0.64285714]\n",
      "    fold  3:  [0.64285714]\n",
      "    fold  4:  [0.75000000]\n",
      "    ----\n",
      "    MEAN:     [0.70369458] + [0.07382427]\n",
      "    FULL:     [0.70422535]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [1.00000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/vecstack/core.py:615: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  S_test[:, model_counter] = st.mode(S_test_temp, axis = 1)[0].ravel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.96551724]\n",
      "    fold  2:  [1.00000000]\n",
      "    fold  3:  [0.92857143]\n",
      "    fold  4:  [1.00000000]\n",
      "    ----\n",
      "    MEAN:     [0.97881773] + [0.02845227]\n",
      "    FULL:     [0.97887324]\n",
      "\n",
      "model  2:     [XGBClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/vecstack/core.py:615: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  S_test[:, model_counter] = st.mode(S_test_temp, axis = 1)[0].ravel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [1.00000000]\n",
      "    fold  1:  [0.89655172]\n",
      "    fold  2:  [0.92857143]\n",
      "    fold  3:  [0.89285714]\n",
      "    fold  4:  [1.00000000]\n",
      "    ----\n",
      "    MEAN:     [0.94359606] + [0.04769938]\n",
      "    FULL:     [0.94366197]\n",
      "\n",
      "Accuracy of the stacking ensemble with Logistic Regression as meta-model: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/vecstack/core.py:615: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  S_test[:, model_counter] = st.mode(S_test_temp, axis = 1)[0].ravel()\n"
     ]
    }
   ],
   "source": [
    "# Perform stacking\n",
    "S_train, S_test = stacking(models, X_train, y_train, X_test,\n",
    "                           regression=False, metric=accuracy_score,\n",
    "                           n_folds=5, stratified=True, shuffle=True,\n",
    "                           random_state=42, verbose=2)\n",
    "\n",
    "# Train the meta-model\n",
    "meta_model.fit(S_train, y_train)\n",
    "\n",
    "# Make predictions with the meta-model\n",
    "y_pred = meta_model.predict(S_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of the stacking ensemble with Logistic Regression as meta-model: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsDTQvjul35K"
   },
   "source": [
    "__Observations:__\n",
    "\n",
    " You can observe the accuracy score and other metrics for different base models:\n",
    "- For the k-nearest neighbor classifier, the mean accuracy is 70%.\n",
    "- For the random forest, the mean accuracy is 97%.\n",
    "- For the XGBoost classifier, the mean accuracy is 95%.\n",
    "\n",
    "**Accuracy of the stacking ensemble with Logistic regression as the Meta-model: 97%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpzS7tiBl35K"
   },
   "source": [
    "### __4.3.1 Advantages of Stacking__\n",
    "\n",
    "- Accomplishes greater accuracy than simplistic ensemble techniques\n",
    "- Enables diversity among models\n",
    "- Possesses the capability to rectify errors made by base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ByfVEgtl35K"
   },
   "source": [
    "### __4.3.2 Disadvantages of Stacking__\n",
    "\n",
    "- Is more challenging to implement and comprehend\n",
    "- Poses a risk of overfitting the meta-model\n",
    "- Requires careful selection of both base and meta-models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0a5ej7Ul35Q"
   },
   "source": [
    "## __Conclusion__\n",
    "\n",
    "This lesson explores various ensemble learning techniques and emphasizes their significance in enhancing the performance of machine learning models. Through examples and practical implementations, this lesson underscores the pivotal role of ensemble learning in achieving more reliable and accurate predictions across diverse applications.\n",
    "\n",
    "Specifically, these methods excel in transforming weaker classifiers into robust systems, thereby significantly increasing the performance in classification challenges."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
